# 深度学习

* [返回上层目录](../README.md)
* [深度学习概论](deep-learning-introduction/deep-learning-introduction.md)
* [ANN人工神经网络](artificial-neural-network/artificial-neural-network.md)
* [Hopfield神经网络](hopfield-neural-network/hopfield-neural-network.md)
* [知识点](tips/tips.md)
* [CNN卷积神经网络](convolutional-neural-network/convolutional-neural-network.md)
* [BNN贝叶斯神经网络](beyesian-neural-network/beyesian-neural-network.md)
* [RNN循环神经网络](recurrent-neural-network/recurrent-neural-network.md)
* [GNN图神经网络](graph-neural-networks/graph-neural-networks.md)
* [深度生成模型](deep-generative-models/deep-generative-models.md)
* [Few-shot Learning小样本学习](few-shot-learning/few-shot-learning.md)



===

在工作的时候，你完全可能会遇到一个相对陌生的模型，所以你需要具备快速把握一个模型的能力，这里推荐大家积累的具体能力有两个。一个是通过netron阅读模型的onnx能力。在你掌握上一段说的理论内容之后，你可以下载一个模型的onnx文件试着打开看看，刚开始也许还是蛮痛苦的，看过的应该都懂，但你应该积累出的能力是，打开一个陌生模型的onnx文件，很快能够看出这个模型大致包括哪些基本结构模块，进而理解优化要点有哪些。

[ai深度学习编译器工程师需要哪些技术栈？](https://www.zhihu.com/question/532768471/answer/2692111925)



[2024年，深度学习，你心目中的top10算法是什么？](https://www.zhihu.com/question/638660013/answer/3356924994)

从过去往最近回忆

1. word2vec，开山之作没的说，后面的bert，gpt都有他的影子
2. resnet，何恺明yyds
3. transformer，虽然attention不是transformer最先提出的，但动态权重影响深远
4. BERT，transformer的encoder
5. GPT，transformer的decoder，也别是gpt3直接开启大模型时代
6. CLIP，跨模态的超神之作
7. MoCo，对比学习
8. stable diffusion，文生图
9. ViT
10. RWKV，线性大模型，复兴RNN





