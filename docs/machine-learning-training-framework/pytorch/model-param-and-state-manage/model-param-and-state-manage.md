#  æ¨¡å‹å‚æ•°ä¸çŠ¶æ€ç®¡ç†

Model Parameter & State Management

* [è¿”å›ä¸Šå±‚ç›®å½•](../pytorch.md)
* [çœ‹å‚æ•°ï¼ˆParametersï¼‰](#çœ‹å‚æ•°ï¼ˆParametersï¼‰)
* [ç®¡å‚æ•°ï¼ˆä¼˜åŒ–å™¨åˆ†ç»„OptimizerGroupsï¼‰](#ç®¡å‚æ•°ï¼ˆä¼˜åŒ–å™¨åˆ†ç»„OptimizerGroupsï¼‰)
* [ç®¡éå‚æ•°çŠ¶æ€ï¼ˆRegisterBufferï¼‰](#ç®¡éå‚æ•°çŠ¶æ€ï¼ˆRegisterBufferï¼‰)
* [parametersä¸param_groupsåŒºåˆ«æ€»ç»“](#parametersä¸param_groupsåŒºåˆ«æ€»ç»“)

# çœ‹å‚æ•°ï¼ˆParametersï¼‰

æ¨¡å‹å‚æ•° (nn.Parameter)ï¼šéœ€è¦æ¢¯åº¦æ›´æ–°çš„å˜é‡ï¼ˆå¦‚æƒé‡ã€åç½®ï¼‰ã€‚

- model.parameters()ï¼šä»…è¿”å›å‚æ•°å¼ é‡ï¼Œç”¨äºä¼ ç»™ä¼˜åŒ–å™¨ã€‚

- model.named_parameters()ï¼šè¿”å› (åå­—, å¼ é‡) å¯¹ï¼Œç”¨äºè°ƒè¯•å’Œå†»ç»“å‚æ•°ã€‚

æˆ‘æ¥åˆ†åˆ«æ¼”ç¤ºä¸€ä¸‹ `model.parameters()`ã€`model.named_parameters()` å’Œ `optimizer.param_groups` çš„ç»“æ„å’Œæ‰“å°ç»“æœï¼Œè¿™æ ·ä½ ä¹‹åè°ƒè¯•ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡ã€å‚æ•°ç»„ã€å†»ç»“å‚æ•°ç­‰ä¼šæ›´æ¸…æ™°ï¼

æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•æ¨¡å‹æ¥åšæ¼”ç¤ºï¼š

```python
import torch
import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.base = nn.Linear(4, 8)
        self.actor = nn.Linear(8, 2)
        self.critic = nn.Linear(8, 1)

    def forward(self, x):
        x = self.base(x)
        return self.actor(x), self.critic(x)

model = MyModel()
```

**ï¼ˆ1ï¼‰`model.parameters()`**

è¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œä¼šè¿”å›æ‰€æœ‰å¯è®­ç»ƒçš„å‚æ•°ï¼ˆä¸å¸¦åå­—ï¼‰ï¼š

```python
for p in model.parameters():
    print(p)
```

è¾“å‡ºï¼ˆæ¯ä¸ªéƒ½æ˜¯ `torch.nn.Parameter`ï¼‰ï¼š

```css
Parameter containing:
tensor([[...]], requires_grad=True)
Parameter containing:
tensor([...], requires_grad=True)
... å…±6ä¸ªï¼šbase(æƒé‡+bias)ï¼Œactor(æƒé‡+bias)ï¼Œcritic(æƒé‡+bias)
```

**ï¼ˆ2ï¼‰`model.named_parameters()`**

è¿™ä¸ªç‰ˆæœ¬å¸¦åå­—ï¼ˆæ¯”å¦‚ `base.weight`, `actor.bias`ï¼‰ï¼Œæ–¹ä¾¿ä½ è°ƒè¯•ï¼š

```python
for name, p in model.named_parameters():
    print(name, p.shape)
```

è¾“å‡ºç¤ºä¾‹ï¼š

```css
base.weight torch.Size([8, 4])
base.bias torch.Size([8])
actor.weight torch.Size([2, 8])
actor.bias torch.Size([2])
critic.weight torch.Size([1, 8])
critic.bias torch.Size([1])
```

# ç®¡å‚æ•°ï¼ˆä¼˜åŒ–å™¨åˆ†ç»„OptimizerGroupsï¼‰

optimizer.param_groupsï¼šæŸ¥çœ‹å­¦ä¹ ç‡åˆ†ç»„ã€æƒé‡è¡°å‡ç­‰é…ç½®ã€‚

è¿™ä¸ªéå¸¸é‡è¦ï¼Œå’Œä½ åŠ¨æ€è°ƒèŠ‚å­¦ä¹ ç‡å¯†åˆ‡ç›¸å…³ã€‚æ¯ä¸ª param_group æ˜¯ä¸€ä¸ªå­—å…¸ï¼š

```python
optimizer = torch.optim.Adam([
    {"params": model.base.parameters(), "lr": 1e-3},
    {"params": model.actor.parameters(), "lr": 5e-4},
    {"params": model.critic.parameters(), "lr": 1e-4},
])

for i, group in enumerate(optimizer.param_groups):
    print(f"Group {i}: lr = {group['lr']}")
    for param in group["params"]:
        print(param.shape)
```

è¾“å‡ºç»“æ„ç±»ä¼¼ï¼š

```css
Group 0: lr = 0.001
torch.Size([8, 4])
torch.Size([8])
Group 1: lr = 0.0005
torch.Size([2, 8])
torch.Size([2])
Group 2: lr = 0.0001
torch.Size([1, 8])
torch.Size([1])
```

# ç®¡éå‚æ•°çŠ¶æ€ï¼ˆRegisterBufferï¼‰

æ¨¡å‹çŠ¶æ€ (register_buffer)ï¼šä¸éœ€è¦æ¢¯åº¦ä½†éœ€éšæ¨¡å‹ä¿å­˜/ç§»åŠ¨çš„å˜é‡ï¼ˆå¦‚ BN çš„å‡å€¼ã€RL çš„ç»Ÿè®¡é‡ï¼‰ã€‚

æ­¤å¤„æ’å…¥ä¹‹å‰è®¨è®ºçš„ register_buffer è¯¦è§£ã€å¯¹æ¯”è¡¨åŠä»£ç ç¤ºä¾‹ã€‚



åœ¨ model.named_parameters() ä¸­ï¼Œä½ åªèƒ½çœ‹åˆ°é‚£äº›éœ€è¦è¢«æ¢¯åº¦ä¸‹é™æ›´æ–°çš„å‚æ•°ï¼ˆWeights & Biasesï¼‰ã€‚

ä½†åœ¨å®é™…å·¥ç¨‹ä¸­ï¼ˆå¦‚ PPO çš„ Value Normalization æˆ– BatchNormï¼‰ï¼Œæˆ‘ä»¬éœ€è¦å­˜å‚¨ä¸€äº›â€œçŠ¶æ€å˜é‡â€ï¼š

1. éœ€è¦éšæ¨¡å‹ä¿å­˜/åŠ è½½ï¼ˆCheckpointï¼‰ã€‚

1. éœ€è¦éš model.to(device) ç§»åŠ¨ï¼ˆCPU -> GPUï¼‰ã€‚

1. ä½†ä¸éœ€è¦æ¢¯åº¦æ›´æ–°ï¼ˆé Parameterï¼‰ã€‚

è¿™æ—¶å€™ï¼Œåƒä¸‡ä¸è¦ç”¨ self.running_mean = ...ï¼Œè€Œè¦ç”¨ register_bufferã€‚

âŒ é”™è¯¯ç¤ºèŒƒï¼ˆæ™®é€šå±æ€§ï¼‰

```python
class WrongModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(10, 10)
        # æ™®é€šå±æ€§ï¼šPyTorch ä¸è®¤è¯†å®ƒï¼
        self.my_state = torch.zeros(1) 

model = WrongModel()
model.cuda() # æŠŠæ¨¡å‹ç§»åˆ° GPU

print(model.fc.weight.device)  # device='cuda:0' (æ­£ç¡®)
print(model.my_state.device)   # device='cpu'    (é”™è¯¯ï¼è¿˜åœ¨ CPU ä¸Š)
# åç»­è¿ç®—ä¼šæŠ¥é”™ï¼šExpected all tensors to be on the same device
```

âœ… æ­£ç¡®ç¤ºèŒƒï¼ˆBufferï¼‰

```python
class RightModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(10, 10)
        # æ³¨å†Œ Bufferï¼šPyTorch ä¼šæŠŠå®ƒå½“å¹²å„¿å­å…»
        self.register_buffer("my_state", torch.zeros(1))

model = RightModel()
model.cuda()

print(model.my_state.device)   # device='cuda:0' (æ­£ç¡®ï¼è‡ªåŠ¨è·Ÿè¿‡æ¥äº†)
print(model.state_dict().keys()) 
# è¾“å‡ºåŒ…å« 'my_state'ï¼Œè¯´æ˜å®ƒä¼šè¢«ä¿å­˜åˆ° checkpoint é‡Œ
```

é—®é¢˜ï¼š

> èƒ½ç”¨
>
> ```python
> self.mean = torch.zeros(shape)
> self.var = torch.ones(shape)
> self.count = torch.tensor(epsilon)
> ```
>
> ä»£æ›¿
>
> ```python
> self.register_buffer("mean", torch.zeros(shape))
> self.register_buffer("var", torch.ones(shape))
> self.register_buffer("count", torch.tensor(epsilon))
> ```
>
> å—ï¼Ÿ

å›ç­”ï¼š

è¿™æ˜¯ä¸€ä¸ªè§¦åŠ PyTorch æ¡†æ¶è®¾è®¡å“²å­¦çš„æ ¸å¿ƒé—®é¢˜ã€‚

ç®€çŸ­å›ç­”ï¼š

ä¸èƒ½ç®€å•æ›¿ä»£ã€‚è™½ç„¶å†™æˆ `self.mean = ...` ä»£ç èƒ½è·‘ï¼Œä½†è¿™ä¼šç ´å PyTorch çš„æ¨¡å‹ç®¡ç†æœºåˆ¶ï¼ˆä¿å­˜ã€åŠ è½½ã€è®¾å¤‡è¿ç§»ï¼‰ã€‚

`register_buffer` çš„ä½œç”¨å¯ä»¥æ¦‚æ‹¬ä¸ºï¼šâ€œæˆ‘æƒ³æŠŠè¿™ä¸ªå˜é‡å½“ä½œæ¨¡å‹çš„ä¸€éƒ¨åˆ†å­˜ä¸‹æ¥ï¼Œä½†æˆ‘ä¸å¸Œæœ›å®ƒæ˜¯å¯è®­ç»ƒçš„å‚æ•°ï¼ˆParameterï¼‰ã€‚â€

ä¸ºäº†è®©ä½ å½»åº•ç†è§£ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸‰ä¸ªç­‰çº§çš„å˜é‡ï¼š

1. æ™®é€šæˆå‘˜å˜é‡ `(self.x = ...)`

è¿™æ˜¯æœ€æ™®é€šçš„ Python å˜é‡ã€‚

- ç‰¹æ€§ï¼šPyTorch å®Œå…¨ä¸è®¤è¯†å®ƒï¼Œä¹Ÿä¸ç®¡å®ƒã€‚

- åæœï¼š

- å½“ä½ è°ƒç”¨ `model.to('cuda')` æ—¶ï¼Œè¿™ä¸ªå˜é‡ä¸ä¼šè‡ªåŠ¨è·Ÿç€å» GPUã€‚å®ƒè¿˜ç•™åœ¨ CPU ä¸Šï¼Œå¯¼è‡´åç»­è¿ç®—æŠ¥é”™ï¼ˆè®¾å¤‡ä¸åŒ¹é…ï¼‰ã€‚

- å½“ä½ è°ƒç”¨ `model.state_dict()` ä¿å­˜æ¨¡å‹æ—¶ï¼Œè¿™ä¸ªå˜é‡ä¸ä¼šè¢«ä¿å­˜è¿›å­—å…¸é‡Œã€‚ä¸‹æ¬¡åŠ è½½æ¨¡å‹ï¼Œå®ƒçš„å€¼å°±ä¸¢äº†ï¼ˆè¿™å°±å®Œäº†ï¼ŒRunningMeanStd è¾›è¾›è‹¦è‹¦ç»Ÿè®¡çš„å‡å€¼æ–¹å·®å…¨æ²¡äº†ï¼‰ã€‚

2. æ¨¡å‹å‚æ•° (`self.x = nn.Parameter(...)`)

è¿™æ˜¯ç¥ç»ç½‘ç»œçš„æƒé‡ï¼ˆWeightï¼‰å’Œåç½®ï¼ˆBiasï¼‰ã€‚

- ç‰¹æ€§ï¼šPyTorch æŠŠå®ƒå½“äº²å„¿å­ã€‚

- åæœï¼š

  - `model.to('cuda')`ï¼šä¼šè‡ªåŠ¨å» GPUã€‚âœ…

  - `state_dict()`ï¼šä¼šè¢«ä¿å­˜ã€‚âœ…

  - å…³é”®åŒºåˆ«ï¼šå®ƒä¼šè¢«ä¼˜åŒ–å™¨ï¼ˆOptimizerï¼‰æ›´æ–°ï¼ optimizer.step() ä¼šè¯•å›¾è®¡ç®—å®ƒçš„æ¢¯åº¦å¹¶ä¿®æ”¹å®ƒã€‚

  - ä½†æˆ‘ä»¬çš„ `mean` å’Œ `var` æ˜¯ç»Ÿè®¡å‡ºæ¥çš„ï¼Œä¸æ˜¯æ¢¯åº¦ä¸‹é™ç®—å‡ºæ¥çš„ã€‚å¦‚æœä½ æŠŠå®ƒè®¾ä¸º Parameterï¼Œä¼˜åŒ–å™¨ä¼šçæ”¹å®ƒï¼Œè¿™å°±ä¹±å¥—äº†ã€‚

3. Buffer (`register_buffer('x', ...)`) â€”â€” æˆ‘ä»¬ç”¨çš„è¿™ä¸ª

è¿™æ˜¯â€œéå‚æ•°çš„çŠ¶æ€å˜é‡â€ï¼ˆNon-parameter Stateï¼‰ã€‚

- ç‰¹æ€§ï¼šPyTorch æŠŠå®ƒå½“å¹²å„¿å­ã€‚

- åæœï¼š

  - `model.to('cuda')`ï¼šä¼šè‡ªåŠ¨å» GPUã€‚âœ…ï¼ˆå®Œç¾è§£å†³è®¾å¤‡é—®é¢˜ï¼‰

  - `state_dict()`ï¼šä¼šè¢«ä¿å­˜ã€‚âœ…ï¼ˆå®Œç¾è§£å†³å­˜æ¡£é—®é¢˜ï¼‰

  - å…³é”®åŒºåˆ«ï¼šå®ƒä¸ä¼šè¢«ä¼˜åŒ–å™¨æ›´æ–°ï¼ ä¼˜åŒ–å™¨ä¼šå¿½ç•¥å®ƒï¼Œåªæœ‰ä½ çš„ä»£ç é€»è¾‘ï¼ˆupdate å‡½æ•°ï¼‰èƒ½ä¿®æ”¹å®ƒã€‚âœ…

æ€»ç»“å›¾è°±

| å˜é‡ç±»å‹               | æ™®é€šå˜é‡ self.x  | å‚æ•° nn.Parameter | Buffer register_buffer |
| :--------------------- | :--------------- | :---------------- | :--------------------- |
| éš model.to() ç§»åŠ¨è®¾å¤‡ | âŒ å¦             | âœ… æ˜¯              | âœ… æ˜¯                   |
| éš state_dict() ä¿å­˜   | âŒ å¦             | âœ… æ˜¯              | âœ… æ˜¯                   |
| è¢« optimizer æ›´æ–°      | âŒ å¦             | âœ… æ˜¯              | âŒ å¦                   |
| é€‚ç”¨åœºæ™¯               | ä¸´æ—¶å˜é‡ã€è¶…å‚æ•° | æƒé‡ã€åç½®        | å‡å€¼ã€æ–¹å·®ã€æ­¥æ•°ç»Ÿè®¡   |

ç»“è®º

å¦‚æœä½ åªå†™ï¼š

```python
self.mean = torch.zeros(shape)
```

ä½ ä¼šé‡åˆ°ä¸¤ä¸ªè‡´å‘½ Bugï¼š

1. å´©æºƒï¼šå½“ä½ æŠŠ Learner æ”¾åˆ° GPU ä¸Šè®­ç»ƒæ—¶ï¼Œ`self.mean` è¿˜åœ¨ CPU ä¸Šï¼Œä¸€åšåŠ å‡æ³•ç¨‹åºå°±æŒ‚äº†ã€‚

1. ç™½ç»ƒï¼šå½“ä½ ä¿å­˜ Checkpoint å†åŠ è½½æ—¶ï¼Œ`self.mean` å˜æˆäº†åˆå§‹çš„ 0ï¼Œä¹‹å‰è®­ç»ƒå¾—åˆ°çš„ç»Ÿè®¡é‡å…¨ä¸¢äº†ï¼ŒCritic åˆè¦é‡æ–°é€‚åº”ã€‚

æ‰€ä»¥ï¼Œå¿…é¡»ç”¨ `register_buffer`ã€‚å®ƒæ˜¯ PyTorch ä¸ºè¿™ç§â€œRunning Mean/Stdâ€è¿™ç±»éœ€æ±‚é‡èº«å®šåšçš„æœºåˆ¶ã€‚

æ€»ç»“å¯¹æ¯”è¡¨

| å˜é‡ç±»å‹             | æ™®é€šå˜é‡ self.x | å‚æ•° nn.Parameter | Buffer register_buffer |
| :------------------- | :-------------- | :---------------- | :--------------------- |
| éš model.to() ç§»åŠ¨   | âŒ å¦            | âœ… æ˜¯              | âœ… æ˜¯                   |
| éš state_dict() ä¿å­˜ | âŒ å¦            | âœ… æ˜¯              | âœ… æ˜¯                   |
| è¢« optimizer æ›´æ–°    | âŒ å¦            | âœ… æ˜¯              | âŒ å¦                   |
| é€‚ç”¨åœºæ™¯             | ä¸´æ—¶å˜é‡        | æƒé‡ã€åç½®        | å‡å€¼ã€æ–¹å·®ã€æ­¥æ•°ç»Ÿè®¡   |

- Parameter vs Buffer çš„å¯¹æ¯”è¡¨ï¼ˆå€Ÿç”¨æˆ‘åˆšæ‰å‘çš„é‚£ä¸ªè¡¨æ ¼ï¼‰ã€‚

- Parameter = äº²å„¿å­ï¼ˆè¦è®­ç»ƒï¼Œè¦ä¿å­˜ï¼Œè¦ç§»åŠ¨ï¼‰ã€‚

- Buffer = å¹²å„¿å­ï¼ˆä¸è®­ç»ƒï¼Œè¦ä¿å­˜ï¼Œè¦ç§»åŠ¨ï¼‰ã€‚

- æ™®é€šå±æ€§ = è·¯äººï¼ˆä¸ç®¡ï¼‰ã€‚

ğŸ› ï¸ å¦‚ä½•æŸ¥çœ‹æ‰€æœ‰ Bufferï¼Ÿ

å°±åƒ model.named_parameters() ä¸€æ ·ï¼ŒPyTorch ä¹Ÿæœ‰ model.named_buffers()ï¼š

```python
for name, buf in model.named_buffers():
    print(f"Buffer name: {name} | shape: {buf.shape}")
```

ä¸€å¥è¯ï¼šâ€œåªè¦æ˜¯ Tensor ä¸”å±äºæ¨¡å‹çŠ¶æ€ï¼Œä½†ä¸éœ€è¦æ¢¯åº¦ï¼Œå°±ç”¨å®ƒï¼â€

# parametersä¸param_groupsåŒºåˆ«æ€»ç»“

| æ–¹æ³•                       | è¿”å›å†…å®¹                            | æ˜¯å¦åŒ…å«å‚æ•°å          | ç”¨é€”                       |
| -------------------------- | ----------------------------------- | ----------------------- | -------------------------- |
| `model.parameters()`       | æ‰€æœ‰å‚æ•°ï¼ˆæŒ‰å®šä¹‰é¡ºåºï¼‰              | âŒ                       | ä¼˜åŒ–å™¨åˆå§‹åŒ–               |
| `model.named_parameters()` | å‚æ•° + åå­—                         | âœ…                       | è°ƒè¯•ã€å†»ç»“æŸäº›å‚æ•°ã€æ‰“å°ç­‰ |
| `optimizer.param_groups`   | åˆ†ç»„å­—å…¸ï¼Œæ¯ç»„æœ‰ lrã€paramsã€eps ç­‰ | âŒï¼ˆparamså†…éƒ¨æ²¡æœ‰åå­—ï¼‰ | å­¦ä¹ ç‡è°ƒèŠ‚ã€æƒé‡åˆ†ç»„è®¾ç½®ç­‰ |

------

å¦‚æœä½ æƒ³è¦ç»“åˆparam_groupçš„é¡ºåºå’Œåå­—ï¼Œå¯ä»¥ç”¨ä¸€ä¸ªåŠæ³•ï¼š**åœ¨è®¾ç½®optimizerä¹‹å‰ï¼Œæ‰‹åŠ¨æ‰“å°æ¯ä¸ªç»„çš„åå­—å’Œå¯¹åº”å‚æ•°ã€‚**

æˆ‘æ¥å¸®ä½ å°è£…ä¸€ä¸ªå¸¦åå­—å’Œç»„åˆ«çš„å¯è§†åŒ–å·¥å…·ï¼Œæ¯”å¦‚ä½ ä¼ å…¥modelå’Œoptimizerï¼Œå®ƒè‡ªåŠ¨æ‰“å°æ¯ç»„çš„å­¦ä¹ ç‡ã€ç»„åã€åŒ…å«å“ªäº›å±‚ã€‚è¿™æ ·æŸ¥bugç‰¹åˆ«èˆ’æœã€‚

é‚£æˆ‘æ¥ç»™ä½ å°è£…ä¸€ä¸ªå°å·¥å…·å‡½æ•°ï¼Œèƒ½æ¸…æ™°åœ°**å¯è§†åŒ–æ¯ä¸ªparam groupçš„ç»“æ„**ï¼ŒåŒ…æ‹¬ï¼š

- å­¦ä¹ ç‡ (`lr`)
- epsï¼ˆå¦‚æœæœ‰ï¼‰
- å‚æ•°å¼ é‡çš„å½¢çŠ¶
- å‚æ•°åï¼ˆå¯é€‰ï¼‰

```python
def visualize_optimizer_param_groups(model, optimizer):
    # è·å–å¸¦åå­—çš„å‚æ•°ï¼Œç”¨äºåŒ¹é… param group å†…çš„å‚æ•°
    name_map = {p: n for n, p in model.named_parameters()}

    for i, group in enumerate(optimizer.param_groups):
        print(f"\nğŸŸ¢ Param Group {i}:")
        print(f"  â†ª learning rate (lr): {group.get('lr', 'N/A')}")
        print(f"  â†ª epsilon (eps): {group.get('eps', 'N/A')}")
        print(f"  â†ª weight_decay: {group.get('weight_decay', 'N/A')}")
        print("  â†ª Parameters:")

        for param in group["params"]:
            name = name_map.get(param, "âš ï¸ unnamed")
            print(f"     - {name:30} | shape: {tuple(param.shape)}")
           
if __name__ == '__main__':
    import torch

    model_A = torch.nn.Linear(4, 3)
    model_B = torch.nn.Linear(3, 2)
    model_C = torch.nn.Linear(2, 1)
    model = torch.nn.Sequential(model_A, model_B, model_C)

    lr_A = 0.001
    lr_B = 0.002
    lr_C = 0.003

    optimizer = torch.optim.Adam([
        {"params": model_A.parameters(), "lr": lr_A, "eps": 1e-8},
        {"params": model_B.parameters(), "lr": lr_B, "eps": 1e-8},
        {"params": model_C.parameters(), "lr": lr_C, "eps": 1e-8},
    ])
    for i, group in enumerate(optimizer.param_groups):
        print(f"Param group {i} learning rate: {group['lr']}")

    # è®¾ç½®åŸºç¡€å­¦ä¹ ç‡
    scheduler = BatchSizeLRScheduler(
        optimizer,
        base_lrs=[lr_A, lr_B, lr_C],
        base_batch_size=64  # é»˜è®¤åŸºç¡€batch size
    )

    # æ¯è½®è®­ç»ƒåæ›´æ–°å­¦ä¹ ç‡
    for _ in range(1):
        current_batch_size = 128
        scheduler.step(current_batch_size)  # ä¼ å…¥å½“å‰å®é™…çš„batch size

    visualize_optimizer_param_groups(model, optimizer)
```

ä¼šæ˜¾ç¤ºï¼š

```
ğŸŸ¢ Param Group 0:
  â†ª learning rate (lr): 0.0014142135623730952
  â†ª epsilon (eps): 1e-08
  â†ª weight_decay: 0
  â†ª Parameters:
     - 0.weight                       | shape: (3, 4)
     - 0.bias                         | shape: (3,)

ğŸŸ¢ Param Group 1:
  â†ª learning rate (lr): 0.0028284271247461905
  â†ª epsilon (eps): 1e-08
  â†ª weight_decay: 0
  â†ª Parameters:
     - 1.weight                       | shape: (2, 3)
     - 1.bias                         | shape: (2,)

ğŸŸ¢ Param Group 2:
  â†ª learning rate (lr): 0.004242640687119286
  â†ª epsilon (eps): 1e-08
  â†ª weight_decay: 0
  â†ª Parameters:
     - 2.weight                       | shape: (1, 2)
     - 2.bias                         | shape: (1,)
```

