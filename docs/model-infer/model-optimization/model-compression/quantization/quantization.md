# é‡åŒ–quantization

- [è¿”å›ä¸Šå±‚ç›®å½•](../model-inference-optimization-deployment.md)



# é—®é¢˜

## é‡åŒ–int4/8ç›´æ¥æŠŠfloatå€¼å˜æˆæ•´æ•°å€¼äº†è¿˜èƒ½æ˜¯å¯¹çš„å—

> å°±æ˜¯æ··åˆç²¾åº¦æ¨ç†æŠŠfloat32å˜æˆfloat16æˆ‘è¿˜èƒ½ç†è§£ï¼Œæ¯•ç«Ÿéƒ½æ˜¯floatå€¼ï¼Œåªæ˜¯ç²¾åº¦ç•¥æœ‰é™ä½ï¼Œç”¨scaleç¼©æ”¾å°±å¯ä»¥è§£å†³äº†ï¼Œä½†æ˜¯é‡åŒ–int4/8ç›´æ¥æŠŠfloatå€¼å˜æˆæ•´æ•°å€¼äº†ï¼Œè¿™æ„Ÿè§‰ä¸€çœ¼çœ‹ä¸Šå»å°±æ˜¯é”™çš„å‘€

ä½ çš„æ„Ÿè§‰å¾ˆå¯¹ï¼Œå’±ä»¬å¯ä»¥æ›´ä»”ç»†åœ°åˆ†ä¸€ä¸‹æ€è€ƒï¼š

ğŸ”¹**æ··åˆç²¾åº¦æ¨ç†**ï¼ˆfloat32 â” float16ï¼‰

- æœ¬è´¨ï¼šéƒ½æ˜¯**æµ®ç‚¹æ•°**ï¼Œåªæ˜¯ç²¾åº¦é™ä½äº†ï¼ˆæ¯”å¦‚å°æ•°ç‚¹åä½æ•°å˜å°‘äº†ï¼‰ï¼Œä½†**æ•°å€¼æœ¬èº«å˜åŒ–ä¸å¤§**ã€‚
- é€šè¿‡ç¼©æ”¾ï¼ˆscalingï¼‰ç­‰æ‰‹æ®µï¼ŒåŸºæœ¬èƒ½ä¿ä½ä¿¡æ¯ï¼Œä¸ä¸¥é‡ç ´ååŸæ¥æ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›ã€‚
- æ‰€ä»¥ï¼Œfloat16å¯ä»¥åšåˆ°ï¼š**ç¨å¾®æ…¢ä¸€ç‚¹ç²¾åº¦ï¼Œæ¢æ¥å·¨å¤§åŠ é€Ÿï¼Œæ•ˆæœæŸå¤±å°**ã€‚

ğŸ”¹**æ¨¡å‹é‡åŒ–**ï¼ˆfloat32 â” int8 / int4ï¼‰

- æœ¬è´¨ï¼šæŠŠè¿ç»­çš„æµ®ç‚¹æ•°ï¼Œ**ç¡¬æŒ¤è¿›**ç¦»æ•£çš„æ•´æ•°è¡¨ç¤ºèŒƒå›´ã€‚
- è¿™ä¸æ˜¯ç®€å•ç²¾åº¦é™ä½äº†ï¼Œè€Œæ˜¯**å€¼æœ¬èº«éƒ½è¢«æ”¹äº†**ï¼ˆä¸¥é‡ä¿¡æ¯ä¸¢å¤±ï¼‰ã€‚
- ä¸¾ä¾‹ï¼š
  - float32é‡Œå¯èƒ½æœ‰ 0.2137ã€0.2189ã€0.2201 å¾ˆè¿‘çš„å€¼ã€‚
  - é‡åŒ–æˆint8ä»¥åï¼Œå¯èƒ½éƒ½å˜æˆäº†**åŒä¸€ä¸ªæ•´æ•°**ï¼Œæ¯”å¦‚ 22ã€‚
- æ‰€ä»¥é‡åŒ–éœ€è¦éå¸¸å¤æ‚çš„å¤„ç†ï¼Œæ¯”å¦‚ï¼š
  - æ‰¾ä¸€ä¸ªåˆé€‚çš„**ç¼©æ”¾å› å­ï¼ˆscaleï¼‰å’Œé›¶ç‚¹ï¼ˆzero pointï¼‰**ï¼Œè®© float å€¼æ˜ å°„åˆ°æ•´æ•°ã€‚
  - é‡åŒ–è®­ç»ƒï¼ˆQuantization-Aware Training, QATï¼‰ï¼šæå‰æ¨¡æ‹Ÿé‡åŒ–è¯¯å·®ï¼Œè¾¹è®­ç»ƒè¾¹é€‚åº”ã€‚
  - åè®­ç»ƒé‡åŒ–ï¼ˆPost-Training Quantization, PTQï¼‰ï¼šè®­ç»ƒå®Œä»¥åå†åšä¸€ç‚¹å¾®è°ƒã€‚
- **é‡åŒ–æŸå¤±æ¯”æ··åˆç²¾åº¦å¤§å¾—å¤š**ï¼Œä½†ä¹Ÿèƒ½è·å¾—æ›´å¤¸å¼ çš„é€Ÿåº¦å’Œå†…å­˜æå‡ã€‚

æ‰€ä»¥æ€»ç»“ä¸€å¥è¯å°±æ˜¯ï¼š

> æ··åˆç²¾åº¦æ›´åƒæ˜¯"å‹ç¼©å›¾ç‰‡"ï¼Œè€Œé‡åŒ–æ›´åƒæ˜¯"æŠŠå½©è‰²ç…§ç‰‡å˜æˆåƒç´ é©¬èµ›å…‹"ã€‚

ğŸŒŸ å¾ˆå¤šå…ˆè¿›çš„æ–¹æ³•ï¼Œæ¯”å¦‚ GPT-4ã€Gemini ä¹Ÿåœ¨ç”¨ int4/int8ï¼Œä½†éƒ½è¦ç»è¿‡ç‰¹åˆ«ä»”ç»†çš„é‡åŒ–è®­ç»ƒå’Œè¯¯å·®æ ¡å‡†ï¼Œä¸æ˜¯ç®€å•åœ° "é™¤ä¸€é™¤" å°±å®Œäº‹çš„ã€‚

è¦ä¸è¦æˆ‘ç»™ä½ ç”»ä¸€ä¸ª **float32 â” float16 â” int8çš„ç›´è§‚å¯¹æ¯”å°å›¾**ï¼Ÿ

![precision](pic/precision.png)







# å‚è€ƒèµ„æ–™

[ä¸ƒã€é‡åŒ–åŸç†](https://zhuanlan.zhihu.com/p/637609643)

[Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases](https://arxiv.org/abs/2301.12017)

## å¤§æ¨¡å‹

* [é‡åŒ–å’Œåé‡åŒ–](https://chatgpt.com/c/69396693-e570-8333-9e69-1eb752c4a677)



