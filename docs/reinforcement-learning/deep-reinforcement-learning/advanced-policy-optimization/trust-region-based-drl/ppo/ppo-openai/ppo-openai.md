# PPOè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–

- [è¿”å›ä¸Šå±‚ç›®å½•](../proximal-policy-optimization.md)
- [ç­–ç•¥æ¢¯åº¦PolicyGradient](#ç­–ç•¥æ¢¯åº¦PolicyGradient)
- [PPOåŸç†æ¨å¯¼](#PPOåŸç†æ¨å¯¼)
- [Actor&Criticç½‘ç»œæ¶æ„](#Actor&Criticç½‘ç»œæ¶æ„)
- [æŸå¤±å‡½æ•°](#æŸå¤±å‡½æ•°)



![paper](pic/paper.png)

PDF: [Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)

OpenAI Blog: [Proximal Policy Optimization](https://openai.com/blog/openai-baselines-ppo/)å’Œ[Proximal Policy Optimization](https://spinningup.openai.com/en/latest/algorithms/ppo.html#id3)

GitHub: [openai/baselines/ppo2](https://github.com/openai/baselines/tree/master/baselines/ppo2)



DeepMindå…ˆåœ¨2017å¹´7æœˆæœˆåˆå‘äº†PPOçš„paperï¼Œä½†æ˜¯ä»–ä»¬å‚è€ƒäº†OpenAIçš„ä¸€ä¸ªèµ„æ–™ï¼Œç„¶åOpenAIå‘ç°ç«Ÿç„¶è¢«DeepMindæŠ¢å…ˆå‘äº†ï¼Œäºæ˜¯OpenAIä¹Ÿå°±è·Ÿç€å‘äº†PPOã€‚

# ç­–ç•¥æ¢¯åº¦PolicyGradient

## ç­–ç•¥æ¢¯åº¦çš„æ¨å¯¼

PPOæ˜¯ç­–ç•¥æ¢¯åº¦çš„ä¸€ä¸ªå˜å½¢ã€‚

å¼ºåŒ–å­¦ä¹ ä¸­çš„è¡Œä¸ºactorçš„ç›®çš„ï¼Œå°±æ˜¯ä¸ºäº†æœ€å¤§åŒ–ä¸€åœºæ¸¸æˆä¸­å®ƒçš„æ‰€æœ‰å¥–åŠ±rewardï¼Œå³æœ€å¤§åŒ–
$$
R=\sum_{t=1}^Tr_t
$$
![trajectory](pic/trajectory.png)

 å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæ¯ä¸€åœºæ¸¸æˆä¸­çš„æ‰€æœ‰ç¯å¢ƒå’Œè¡Œä¸ºä¸²èµ·æ¥å°±æ˜¯ä¸€ä¸ªè½¨è¿¹trajectoryï¼Œå³
$$
\tau = \{s_1,a_1,s_2,a_2,\dots,s_T,a_T\}
$$
ä¸€ä¸ªç‰¹å®šçš„è½¨è¿¹trajectoryå‡ºç°çš„å‡ ç‡ä¸ºï¼š
$$
\begin{aligned}
p_{\theta}(\tau)&=p(s_1)p_{\theta}(a_1|s_1)p(s_2|s_1,a_1)p_{\theta}(a_2|s_2)p(s_3|s_2,a_2)\dots\\
&=p(s_1)\mathop{\Pi}\limits_{t=1}^T p_{\theta}(a_t|s_t)p(s_{t+1}|s_t,a_t)
\end{aligned}
$$
å…¶ä¸­ï¼Œ$\theta$ä¸ºActorçš„æ¨¡å‹å‚æ•°ã€‚

ç„¶åæˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯ï¼Œè°ƒæ•´Actoræ¨¡å‹å‚æ•°$\theta$ï¼Œä½¿å¾—$R(\tau)$çš„å€¼æœ€å¤§åŒ–ã€‚

æ³¨æ„ï¼Œ$R(\tau)$æ˜¯ä¸ªå˜é‡ï¼Œå…¶ä¸Actoræ¨¡å‹å‚æ•°$\theta$æœ‰å…³ã€‚ä¸ºä»€ä¹ˆæ˜¯ä¸ªå˜é‡ï¼Ÿå› ä¸º$\theta$é€šè¿‡æ”¹å˜è½¨è¿¹åˆ†å¸ƒï¼Œé—´æ¥æ”¹å˜å¥–åŠ±çš„æœŸæœ›ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œ$R(\tau)$æ˜¯å…³äºéšæœºå˜é‡$\tau$çš„å‡½æ•°ï¼Œè€Œ$\tau$çš„åˆ†å¸ƒç”±$\theta$å†³å®šã€‚å› æ­¤ï¼Œå½“ä½ æ”¹å˜$\theta$æ—¶ï¼Œä½ é‡‡æ ·åˆ°çš„$R(\tau)$çš„â€œç»Ÿè®¡åˆ†å¸ƒâ€å˜äº†ã€‚å°±ç±»ä¼¼äºä½ æ·éª°å­ï¼Œç»™å®šä¸€æ¬¡æ·éª°ç»“æœï¼šæ˜¯ç¡®å®šçš„ï¼Œä½†åœ¨æ·ä¹‹å‰ï¼šä¸æ˜¯ç¡®å®šçš„ï¼Œæ˜¯éšæœºå˜é‡ï¼Œè€Œä¸”æ”¹å˜$\theta$ï¼ˆéª°å­åå‘ï¼‰ï¼Œå°±ä¼šæ”¹å˜â€œå¥–åŠ±çš„æœŸæœ›â€ã€‚

ä½†æ˜¯è¿™é‡Œè¦æ³¨æ„ï¼Œä¸¥æ ¼åœ°è¯´ï¼Œ$R(\tau)$å¹¶ä¸å«æœ‰$\theta$ã€‚å› ä¸ºå¤§ä¼—åœ¨**å£è¯­å±‚é¢**æŠŠä¸‹é¢ä¸‰ä»¶äº‹æ··åœ¨äº†ä¸€èµ·ï¼š

ä¸¥æ ¼åŒºåˆ†ä¸‰å±‚å¯¹è±¡ï¼ˆéå¸¸é‡è¦ï¼‰

| å¯¹è±¡                  | æ˜¯å¦å«$\theta$           |
| --------------------- | ------------------------ |
| $R(\tau)$             | âŒ ä¸å«                   |
| $\tau$çš„åˆ†å¸ƒ          | âœ… å«ï¼ˆç”±$p_\theta$å†³å®šï¼‰ |
| $\mathbb{E}[R(\tau)]$ | âœ… å«                     |

æ­£ç¡®è¯´æ³•åº”è¯¥æ˜¯ï¼š

> **$R(\tau)$çš„åˆ†å¸ƒéš$\theta$æ”¹å˜**

è€Œä¸æ˜¯ï¼š

> âŒ $R(\tau)$æ˜¯$\theta$çš„å‡½æ•°

æ‰€ä»¥æˆ‘ä»¬æœ€å¤§åŒ–çš„ç›®æ ‡å‡½æ•°åº”è¯¥æ˜¯å…¶æœŸæœ›ï¼Œå³
$$
\bar{R}_{\theta}=\sum_{\tau}R(\tau)p_{\theta}(\tau)=E_{\tau\sim p_{(\theta)}(\tau)}[R(\tau)]
$$
ä¸ºä»€ä¹ˆç›®æ ‡å‡½æ•°ä¸€å®šå†™æˆæœŸæœ›ï¼Ÿå› ä¸ºä½ æ ¹æœ¬**æ§åˆ¶ä¸äº†å…·ä½“å“ªæ¡è½¨è¿¹å‘ç”Ÿ**ã€‚ä½ èƒ½æ§åˆ¶çš„åªæœ‰ï¼š$p_{\theta}(\tau)$ï¼Œæ‰€ä»¥ä½ å”¯ä¸€åˆç†çš„ç›®æ ‡åªèƒ½æ˜¯ä¸Šè¿°å…¬å¼ï¼Œæ‰€ä»¥ä¸åº”æ˜¯æœ€å¤§åŒ–æŸä¸€æ¡å…·ä½“è½¨è¿¹çš„å¥–åŠ±ï¼Œè€Œåº”è¯¥æ˜¯æœ€å¤§åŒ–å¹³å‡æ„ä¹‰ä¸‹çš„å¥–åŠ±ã€‚

é‚£æ€ä¹ˆæœ€å¤§åŒ–å¥–åŠ±çš„æœŸæœ›å€¼å‘¢ï¼Ÿé‚£å°±æ˜¯ç”¨å¯¹$\bar{R}_{\theta}$çš„æ¢¯åº¦ä¸Šå‡æ³•ï¼ˆå³å¯¹æŸå¤±å‡½æ•°çš„æ¢¯åº¦ä¸‹é™æ³•ï¼‰æ¥æœ€å¤§åŒ–å…¶å€¼ã€‚
$$
\begin{aligned}
\frac{\partial \bar{R}}{\partial \theta}&=
\nabla\bar{R}_{\theta}\\
&=\sum_{\tau}R(\tau)\nabla p_{\theta}(\tau)\\
&=\sum_{\tau}R(\tau)p_{\theta}(\tau)\frac{\nabla p_{\theta}(\tau)}{p_{\theta}(\tau)}\\
&=\sum_{\tau}R(\tau)p_{\theta}(\tau)\nabla\log p_{\theta}(\tau)\\
&=\boxed{E_{\tau\sim p_{\theta}(\tau)}\left[R(\tau)\nabla\log p_{\theta}(\tau)\right]}\\
&\approx \frac{1}{N}\sum_{n=1}^NR(\tau^n)\nabla\log p_{\theta}(\tau^n)\\
&= \frac{1}{N}\sum_{n=1}^N\sum_{t=1}^{T_n}R(\tau^n)\nabla\log p_{\theta}(a_t^n|s_t^n)\\
\end{aligned}
$$
åŸºäºå¥–åŠ±å¯¹å‚æ•°$\theta$çš„æ¢¯åº¦å€¼ï¼Œå¯ä»¥æ›´æ–°å‚æ•°$\theta$ï¼Œæ¥è®©å¥–åŠ±å˜å¾—æ›´å¤§ï¼š
$$
\theta=\theta+\text{lr}\cdot \frac{\partial \bar{R}}{\partial \theta}
$$
ä¸ºäº†å®ç°$\theta=\theta+\text{lr}\cdot \frac{\partial \bar{R}}{\partial \theta}$ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ ‡é‡å‡½æ•°ï¼ˆlossï¼‰ï¼Œä½¿å¾—å¯¹å®ƒåšåå‘ä¼ æ’­ï¼Œå¾—åˆ°çš„æ¢¯åº¦**æ­£å¥½ç­‰äº**$\nabla\bar{R}_{\theta}$çš„è´Ÿæ–¹å‘ï¼Œä¸ºä»€ä¹ˆæ˜¯è´Ÿæ–¹å‘ï¼Œå› ä¸ºåå‘ä¼ æ’­æ˜¯åšæ¢¯åº¦ä¸‹é™æ³•ï¼Œæ±‚lossçš„æœ€å°å€¼ï¼Œæ‰€ä»¥æ¢¯åº¦å˜å·ï¼Œå®é™…ç­‰äºæ˜¯æ¢¯åº¦ä¸Šå‡ã€‚è€Œè¿™ä¸ªlosså¯ä»¥æ ¹æ®**æ¢¯åº¦è¡¨è¾¾å¼åå‘â€œæ„é€ â€å‡ºæ¥**ï¼š
$$
\begin{aligned}
&\nabla_{\theta}\text{loss}=-\nabla\bar{R}_{\theta}=-R(\tau^n)\nabla\log p_{\theta}(a_t^n|s_t^n)\\
\Rightarrow&\text{loss}=-R(\tau^n)\log p_{\theta}(a_t^n|s_t^n)
\end{aligned}
$$
è¿™ä¸ªlossæ‰æ˜¯å·¥ç¨‹å®ç°ä¸Šçš„lossï¼Œå…¶å®å°±æ˜¯ä¸ºäº†èƒ½å¤Ÿå·¥ç¨‹ä¸Šå®ç°æœ€å¤§åŒ–ç´¯è®¡å¥–åŠ±çš„ç›®æ ‡å‡½æ•°ï¼ŒæŠŠä½ å·²ç»çŸ¥é“çš„æ¢¯åº¦å½¢å¼ï¼ŒåŒ…è£…æˆä¸€ä¸ªå¯è¢«è‡ªåŠ¨æ±‚å¯¼çš„æ ‡é‡å‡½æ•°ã€‚è¿™ä¸ª loss å¹¶ä¸æ˜¯å¼ºåŒ–å­¦ä¹ çœŸæ­£çš„ä¼˜åŒ–ç›®æ ‡ï¼Œè€Œæ˜¯ä¸€ä¸ªæ¢¯åº¦ç­‰ä»·çš„ä»£ç†ç›®æ ‡ï¼ˆsurrogate objectiveï¼‰ã€‚å®ƒ**ä¸æ˜¯**çœŸæ­£çš„ç›®æ ‡ï¼š$\mathbb{E}[R(\tau)]$ï¼Œè€Œæ˜¯åªæ˜¯ä¸€ä¸ªè¢«äººä¸ºæ„é€ çš„å‡½æ•°ï¼Œå…¶æ¢¯åº¦æ°å¥½æ˜¯æˆ‘æˆ‘ä»¬æƒ³è¦çš„æ¢¯åº¦è€Œå·²ï¼Œåœ¨PPO/TRPO è®ºæ–‡é‡Œï¼Œè¿™ä¸ªè¯å°±å«ï¼šsurrogate lossï¼Œä½ å·²ç»åœ¨â€œç›´è§‰ä¸Šâ€æŠŠå®ƒç†è§£å¯¹äº†ã€‚æ‰€ä»¥ï¼Œä½ å®Œå…¨å¯ä»¥è¿™æ ·ç†è§£ç­–ç•¥æ¢¯åº¦ï¼š

> åœ¨ç­–ç•¥æ¢¯åº¦æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬å¹¶ä¸æ˜¯å…ˆå®šä¹‰ä¸€ä¸ª loss å†å»ä¼˜åŒ–å®ƒï¼›
>
> è€Œæ˜¯å…ˆä»æœŸæœ›å¥–åŠ±çš„æ¢¯åº¦å‡ºå‘ï¼Œå†åå‘æ„é€ ä¸€ä¸ª surrogate lossï¼Œä½¿å…¶æ¢¯åº¦ä¸æœŸæœ›å¥–åŠ±çš„æ¢¯åº¦å®Œå…¨ä¸€è‡´ï¼Œä»è€Œåˆ©ç”¨æ ‡å‡†çš„åå‘ä¼ æ’­æ¡†æ¶è¿›è¡Œä¼˜åŒ–ã€‚

ï¼ˆæ³¨æ„ï¼šè¿™ä¸€æ®µè¯è¯´çš„å…¶å®æœ‰é—®é¢˜ï¼Œä½†æ˜¯ä½ å…ˆæ¥ç€çœ‹ï¼‰ç”±äºæˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸Šå‡æ³•çš„ç›®æ ‡å°±æ˜¯æå‡$\bar{R}_{\theta}$ï¼Œé‚£ä¹ˆï¼Œå¦‚æœ$R(\tau^n)$ä¸ºæ­£ï¼Œåˆ™é€šè¿‡æ›´æ–°å‚æ•°$\theta$ï¼Œè‡ªç„¶ä¼šä½¿å¾—è¯¥æ¡è½¨è¿¹ä¸­çš„æ¯ä¸€ä¸ªåŠ¨ä½œçš„å‡ºç°å‡ ç‡å˜å¤§ï¼Œå³ä½¿å¾—$p_{\theta}(a_t^n|s_t^n)$æ›´å¤§ï¼Œä»è€Œè®©$\bar{R}_{\theta}$å˜å¾—æ›´å¤§ã€‚

## ç­–ç•¥æ¢¯åº¦æå‡çš„ä¸€ä¸ªè¯¯åŒº

æ³¨æ„ï¼š**ä¸Šä¸€æ®µçš„è¯´æ³•æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿä¸ºä»€ä¹ˆå¦‚æœ$R(\tau^n)$ä¸ºæ­£ï¼Œä½¿å¾—$p_{\theta}(a_t^n|s_t^n)$æ›´å¤§ï¼Œä»è€Œè®©$\bar{R}_{\theta}$å˜å¾—æ›´å¤§å‘¢ï¼Ÿ**è¿™å¥½åƒæ˜¯åœ¨è¯´ï¼Œæ˜¯å› ä¸º$R(\tau^n)$ä¸ºæ­£ï¼Œå¯¼è‡´äº†$p_{\theta}(a_t^n|s_t^n)$æ›´å¤§ï¼Œä»è€Œå¯¼è‡´äº†$\bar{R}_{\theta}$å˜å¾—æ›´å¤§ï¼Ÿè¿™é‡Œçš„é€»è¾‘å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿå¾ˆæ··ä¹±å•Šï¼å°±æ˜¯è¯´ï¼Œä¸ºä»€ä¹ˆï¼Œæ­£rewardå¯ä»¥å¢åŠ è½¨è¿¹çš„æ¦‚ç‡ï¼Œè´Ÿrewardå¯ä»¥å‡å°‘è½¨è¿¹çš„æ¦‚ç‡ï¼Œæˆ‘èƒ½ç†è§£è¿™å¯ä»¥è¾¾åˆ°æ€»çš„ç›®æ ‡ï¼šå¢å¤§Rï¼Œä½†æ˜¯æ— æ³•ä»æ•°å­¦ä¸ŠçŸ¥é“ä¸ºä»€ä¹ˆèƒ½å®ç°åŒæ—¶å¢åŠ å‡å°è½¨è¿¹çš„æ¦‚ç‡ï¼Ÿæ€»æ„Ÿè§‰å¾ˆç¥å¥‡ã€‚ã€‚ã€‚ä»€ä¹ˆæœºåˆ¶è®©æ­£ rewardï¼Œå¯ä»¥å¢åŠ è½¨è¿¹çš„æ¦‚ç‡ï¼Œè´Ÿrewardå¯ä»¥å‡å°‘è½¨è¿¹çš„æ¦‚ç‡ï¼Ÿ

å¦‚æœä½ æœ‰è¿™æ ·çš„ç–‘é—®ï¼Œè¯´æ˜ä½ åœ¨è®¤çœŸæ€è€ƒäº†ï¼ï¼ï¼è€Œä¸æ˜¯æ¨¡ç³Šä¸æ¸…è¯•å›¾æºœè¿‡å»ï¼Œå°±ç±»ä¼¼ä½ å¿µè‹±è¯­å•è¯ï¼Œä¸ä¼šéŸ³æ ‡ï¼Œè¯•å›¾è’™æ··è¿‡å…³ï¼Œç±»ä¼¼äºä½ ä¸çŸ¥é“wordå’Œworldå•è¯çš„å‘éŸ³åŒºåˆ«ã€‚æ‰€ä»¥è¿™é‡Œæˆ‘ä»¬ä¸€å®šè¦ä»”ç»†æ·±ç©¶ï¼Œé€»è¾‘é—­ç¯ï¼ï¼ï¼

å…ˆè¯´ç»“è®ºï¼šè¿™å¥è¯æ˜¯é”™çš„ï¼Œå…·æœ‰è¯¯å¯¼æ€§ï¼ï¼ï¼

> å¦‚æœ$R(\tau^n)$ä¸ºæ­£ï¼Œåˆ™é€šè¿‡æ›´æ–°å‚æ•°$\theta$ï¼Œè‡ªç„¶ä¼šä½¿å¾—è¯¥æ¡è½¨è¿¹ä¸­çš„æ¯ä¸€ä¸ªåŠ¨ä½œçš„å‡ºç°å‡ ç‡å˜å¤§ï¼Œå³ä½¿å¾—$p_{\theta}(a_t^n|s_t^n)$æ›´å¤§ï¼Œä»è€Œè®©$\bar{R}_{\theta}$å˜å¾—æ›´å¤§ã€‚

ç„¶åæˆ‘ä»¬å¼€å§‹æ¢å¯»ä¹‹æ—…ï¼Œå…¶å®æŒºç®€å•çš„ï¼Œä½†æ˜¯ä¸ºäº†è¯´æ¸…æ¥šï¼Œè¿™é‡Œå†™çš„æ¯”è¾ƒå•°å—¦ã€‚

æˆ‘ä»¬æŠŠä¸Šè¿°çš„ç–‘é—®æŠ½è±¡ä¸ºä¸€ä¸ªæ•°å­¦é—®é¢˜ï¼š

> å°±æ˜¯å‡½æ•°$f(\theta)$çš„æ¢¯åº¦ = a \* å‡½æ•°$g(\theta)$çš„æ¢¯åº¦ï¼Œä¸ºä»€ä¹ˆa>0ï¼Œå¯ä»¥å¢åŠ $g(\theta)$çš„å€¼ï¼Œa<0ï¼Œå¯ä»¥å‡å°$g(\theta)$çš„å€¼ï¼Ÿ
>
> å…¶ä¸­ï¼Œå‡½æ•°$f(\theta)$è¡¨ç¤ºåŸé—®é¢˜ä¸­çš„$\bar{R}_{\theta}$ï¼Œå‡½æ•°$g(\theta)$è¡¨ç¤ºåŸé—®é¢˜ä¸­çš„$\nabla\log p_{\theta}(\tau^n)$ï¼Œaè¡¨ç¤ºåŸé—®é¢˜ä¸­çš„å¥–åŠ±$R(\tau)$ã€‚

å…¶å®å°±æ˜¯æŠŠå¼ºåŒ–å­¦ä¹ çš„ä¾‹å­æŠ½è±¡æˆä¸€ä¸ª**çº¯æ•°å­¦é—®é¢˜**ï¼Œå»ç†è§£â€œä¹˜ä¸Šæ­£æ•°/è´Ÿæ•°ç³»æ•°ï¼Œä¸ºä»€ä¹ˆä¼šå¢å¼º/å‡å¼±æŸä¸ªæ–¹å‘çš„å˜åŒ–â€ï¼Œä¸å±€é™äº RL çš„æ¦‚ç‡åˆ†å¸ƒã€‚æˆ‘ä»¬å¯ä»¥ç”¨**æ³›åŒ–çš„æ•°å­¦å…¬å¼**æ¥åˆ†æã€‚

1ï¸âƒ£ é—®é¢˜æŠ½è±¡

å‡è®¾æœ‰ä¸€ä¸ªå‡½æ•°$f(\theta)$ï¼Œæ¢¯åº¦å¯ä»¥å†™æˆ
$$
\nabla_{\theta}f(\theta)=a\nabla_{\theta}g(\theta)
$$

- $\nabla_{\theta}g(\theta)$æ˜¯å‡½æ•°$g(\theta)$çš„æ¢¯åº¦ï¼ŒæŒ‡æ˜â€œä½ å¸Œæœ›æ²¿å“ªä¸ªæ–¹å‘æ”¹å˜å‚æ•°â€
- $a \in \mathbb{R}$æ˜¯ä¸€ä¸ªæ ‡é‡ç³»æ•°ï¼ˆç±»ä¼¼ RL é‡Œçš„ rewardï¼‰
- å‚æ•°æ›´æ–°ç”¨æ¢¯åº¦ä¸Šå‡æ³•ï¼š$\theta \gets \theta + \eta \nabla_\theta f(\theta) = \theta + \eta a \nabla_{\theta}g(\theta)$

2ï¸âƒ£ ç›®æ ‡ï¼šæ²¿$\nabla_{\theta}g(\theta)$æ–¹å‘å¢å¤§æˆ–å‡å°

* **å¦‚æœ $a > 0$**ï¼š

  æ›´æ–°æ–¹å¼ä¸$\nabla_{\theta}g(\theta)$ä¸€è‡´
  $$
  \Delta \theta = \eta a \nabla_{\theta}g(\theta) \propto \nabla_{\theta}g(\theta)
  $$
  â†’ æ²¿$\nabla_{\theta}g(\theta)$æ–¹å‘ç§»åŠ¨ â†’ $g(\theta)$ä¼šâ€œå¢å¼ºâ€ï¼Œå› ä¸º$g$å‡½æ•°çš„å‚æ•°å’Œ$f$å‡½æ•°ä¸€æ ·éƒ½æ˜¯$\theta$

* **å¦‚æœ $a < 0$**ï¼š

  æ›´æ–°æ–¹å¼ä¸$\nabla_{\theta}g(\theta)$åå‘
  $$
  \Delta \theta = \eta a \nabla_{\theta}g(\theta) \propto -\nabla_{\theta}g(\theta)
  $$
  â†’ æ²¿$\nabla_{\theta}g(\theta)$åæ–¹å‘ç§»åŠ¨ â†’ $g(\theta)$ä¼šâ€œå‡å¼±â€ï¼Œå› ä¸º$g$å‡½æ•°çš„å‚æ•°å’Œ$f$å‡½æ•°ä¸€æ ·éƒ½æ˜¯$\theta$

3ï¸âƒ£ æ•°å­¦è¯æ˜ï¼ˆå±€éƒ¨çº¿æ€§ï¼‰

ä½†æ˜¯æ— è®º$a>0$è¿˜æ˜¯$a<0$ï¼ŒæŒ‰ç…§$f(\theta)$å‡½æ•°çš„æ¢¯åº¦æ–¹å‘ç§»åŠ¨ï¼Œå³$\nabla_{\theta}f(\theta)=a\nabla_{\theta}g(\theta)$ï¼Œ$f(\theta)$å‡½æ•°éƒ½ä¼šå¢å¤§ï¼Œå› ä¸ºå¾ˆç®€å•å‘€ï¼Œ$\nabla_{\theta}f(\theta)=a\nabla_{\theta}g(\theta)$æ˜¯$f(\theta)$çš„æ¢¯åº¦å‘€ã€‚è¯æ˜å¦‚ä¸‹ï¼š

åšä¸€é˜¶æ³°å‹’å±•å¼€ï¼š
$$
f(\theta+\eta a \nabla_{\theta}g(\theta))\approx f(\theta)+\eta a \nabla_{\theta}g(\theta)^T\nabla_{\theta}f(\theta)
$$
æŠŠ$\nabla_{\theta}f(\theta)=a\nabla_{\theta}g(\theta)$ä»£å…¥ï¼Œ
$$
\begin{aligned}
f(\theta+\eta a \nabla_{\theta}g(\theta))&\approx f(\theta)+\eta a \nabla_{\theta}g(\theta)^T\left(a\nabla_{\theta}g(\theta)\right)\\
&=f(\theta)+\eta a^2\lVert \nabla_{\theta}g(\theta) \rVert^2\\
&\geq f(\theta)
\end{aligned}
$$
æ³¨æ„ï¼š$a^2 \ge 0$ï¼Œæ‰€ä»¥ä¸€é˜¶å¢é‡æ€»æ˜¯æ­£æ•° â†’ **$f$å±€éƒ¨å¢åŠ **

**æ–¹å‘ä¸Š**ï¼šè™½ç„¶$f$å¢å¤§ï¼Œä½†ç³»æ•°$a$çš„æ­£è´Ÿå†³å®šä½ æ²¿$\nabla_{\theta}g(\theta)$è¿˜æ˜¯æ²¿$-\nabla_{\theta}g(\theta)$æ–¹å‘æ›´æ–° â†’ $\nabla_{\theta}g(\theta)$æŒ‡å‘çš„$g$å‡½æ•°å¢å¼º/å‡å¼±ã€‚

4ï¸âƒ£ ç›´è§‚æ€»ç»“

- **$\nabla_{\theta}g(\theta)$æŒ‡æ˜æ–¹å‘**ï¼šä½ å¸Œæœ›æ”¹å˜çš„é‡
- **$a$çš„æ­£è´Ÿ**ï¼šå†³å®šæ²¿ç€è¿™ä¸ªæ–¹å‘åŠ å¼ºè¿˜æ˜¯æŠ‘åˆ¶$g(\theta)$å‡½æ•°
- **æ›´æ–°åçš„å˜åŒ–**ï¼šå±€éƒ¨å‡½æ•°å€¼$f(\theta)$å‡½æ•°æ€»æ˜¯å¢åŠ ï¼ˆæ¢¯åº¦ä¸Šå‡ä¿è¯ï¼‰
- è¿™å°±æ˜¯ RL ä¸­â€œæ­£ reward â†’å¢å¼ºè½¨è¿¹æ¦‚ç‡ï¼Œè´Ÿ reward â†’æŠ‘åˆ¶è½¨è¿¹æ¦‚ç‡â€çš„æ•°å­¦æœ¬è´¨

è¿™ä¸‹ä½ æ‡‚äº†å—ï¼Ÿæ‰€ä»¥å›åˆ°å¼ºåŒ–å­¦ä¹ çš„ç­–ç•¥æ¢¯åº¦æ›´æ–°è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥è¿™ä¹ˆç†è§£ï¼š

> æˆ‘è¿™ä¸‹æ‡‚äº†ï¼Œå°±æ˜¯$f(\theta)$å‡½æ•°å’Œ$g(\theta)$å‡½æ•° éƒ½æ˜¯å…³äºÎ¸çš„å‡½æ•°ï¼Œå³ä»–ä»¬å…±äº«å‚æ•°$\theta$ã€‚ $a$ä¹˜ä»¥$g(\theta)$å‡½æ•°çš„æ¢¯åº¦å°±æ˜¯få‡½æ•°çš„æ¢¯åº¦ï¼Œæ‰€ä»¥ï¼Œä¸è®º$a$æ˜¯å¤§äº0è¿˜æ˜¯å°äº0ï¼ŒæŒ‰ç…§$a$ä¹˜ä»¥$g(\theta)$å‡½æ•°çš„æ¢¯åº¦ï¼ˆå³$f(\theta)$å‡½æ•°çš„æ¢¯åº¦ï¼‰æ¥æ›´æ–°$\theta$ï¼Œ$f(\theta)$å‡½æ•°æ€»æ˜¯å¢å¤§çš„ã€‚ä½†æ˜¯å¯¹äº$g(\theta)$å‡½æ•°ï¼Œå½“$a$å¤§äº0æ—¶ï¼Œå‚æ•°$\theta$æ›´æ–°çš„æ–¹å‘ï¼ˆ$a$ä¹˜ä»¥$g(\theta)$å‡½æ•°çš„æ¢¯åº¦ï¼‰æ˜¯å’Œ$g(\theta)$å‡½æ•°çš„æ¢¯åº¦ä¸€è‡´çš„ï¼Œé‚£å°±ä¼šè®©$g(\theta)$å‡½æ•°å˜å¤§ï¼Œä½†æ˜¯ï¼ˆè¿™é‡Œæ˜¯ç»å¯¹æ ¸å¿ƒé‡ç‚¹ï¼‰ï¼Œå½“$a$å°äº0æ—¶ï¼Œå‚æ•°$\theta$æ›´æ–°çš„æ–¹å‘ï¼ˆ$a$ä¹˜ä»¥$g(\theta)$å‡½æ•°çš„æ¢¯åº¦ï¼‰æ˜¯å’Œ$g(\theta)$å‡½æ•°çš„æ¢¯åº¦åˆšå¥½ç›¸åçš„ï¼Œé‚£ä¹ˆæ­¤æ—¶è™½ç„¶$f(\theta)$å‡½æ•°ç»§ç»­å¢å¤§ï¼Œä½†æ˜¯$g(\theta)$å‡½æ•°æ˜¯ä¼šå‡å°çš„ã€‚ 
>
> å°±æ˜¯è¯´ï¼Œä¸€æ—¦ä½ æ„è¯†åˆ°ï¼š
>
> - $f(\theta)$å’Œ$g(\theta)$éƒ½æ˜¯$\theta$çš„å‡½æ•°
> - æ›´æ–°çš„æ˜¯å‚æ•°$\theta$ï¼Œè€Œä¸æ˜¯æ•°å€¼
> - åŒä¸€ä¸ª$\theta$æ›´æ–°ï¼ŒåŒæ—¶å½±å“$f(\theta)$å’Œ$g(\theta)$
>
> é‚£ä¹ˆæ•´ä¸ªé€»è¾‘æ˜¯**é“æ¿ä¸€å—ã€æ¯«æ— é­”æ³•**çš„ã€‚
>
> æ¢¯åº¦ä¸Šå‡ä¿è¯çš„æ˜¯ï¼šä½ æ²¿ç€$\nabla_{\theta}f(\theta)$æ›´æ–°ï¼Œ$f(\theta)$ä¸€å®šä¸Šå‡ï¼›
>
> ä½†æ¢¯åº¦ä¸­å„ä¸ªå› å­ï¼ˆå¦‚ rewardï¼‰å†³å®šçš„æ˜¯ï¼šå‚æ•°$\theta$åœ¨â€œå…¶å®ƒå‡½æ•°ç©ºé—´â€é‡Œï¼Œæ˜¯å¼ºåŒ–è¿˜æ˜¯æŠ‘åˆ¶é‚£ä¸ªå‡½æ•°ã€‚

## ç­–ç•¥æ¢¯åº¦æœ€æ ¸å¿ƒæœºåˆ¶çš„å®Œæ•´è§£é‡Š

ä¸‹é¢æ­£å¼æ€»ç»“ä¸€ä¸‹ï¼šä¸ºä»€ä¹ˆã€Œæ­£ reward ä¼šå¢åŠ è½¨è¿¹æ¦‚ç‡ï¼Œè´Ÿ reward ä¼šé™ä½è½¨è¿¹æ¦‚ç‡ã€

ä¸‹é¢è¿™æ®µè¯ï¼Œ**æ˜¯å¯¹ç­–ç•¥æ¢¯åº¦æœ€æ ¸å¿ƒæœºåˆ¶çš„å®Œæ•´è§£é‡Š**ã€‚

### æˆ‘ä»¬çœŸæ­£è¦ä¼˜åŒ–çš„ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ

ç­–ç•¥æ¢¯åº¦çš„çœŸå®ç›®æ ‡å‡½æ•°æ˜¯ **æœŸæœ›å›æŠ¥**ï¼š
$$
\bar{R}_\theta = \mathbb{E}_{\tau \sim p_\theta(\tau)}[R(\tau)] = \sum_\tau R(\tau)\, p_\theta(\tau)
$$
è¿™æ˜¯ä¸€ä¸ª **å…³äºå‚æ•°$\theta$** çš„å‡½æ•°ã€‚

æˆ‘ä»¬é€šè¿‡æ¢¯åº¦ä¸Šå‡æ›´æ–°å‚æ•°ï¼š
$$
\theta \leftarrow \theta + \eta \nabla \bar{R}_\theta
$$
åªè¦æˆ‘ä»¬æ²¿ç€$\nabla \bar{R}_\theta$æ›´æ–°ï¼Œ**$\bar{R}_\theta$â€‹ ä¸€å®šä¼šä¸Šå‡**â€”â€”è¿™æ˜¯æ¢¯åº¦çš„å®šä¹‰ï¼Œæ˜¯æ¯«æ— ç–‘é—®çš„ï¼Œä½ ä¸è¦æ€€ç–‘è¿™ä¸ªäº†ã€‚

### æœŸæœ›å›æŠ¥çš„æ¢¯åº¦é•¿ä»€ä¹ˆæ ·ï¼Ÿ

é€šè¿‡ log-derivative trickï¼Œå¯ä»¥å¾—åˆ°ï¼š
$$
\nabla \bar{R}_\theta = \mathbb{E}_{\tau \sim p_\theta(\tau)} \big[ R(\tau)\, \nabla \log p_\theta(\tau) \big]
$$
ç”¨ Monte Carlo è¿‘ä¼¼ï¼Œå¯¹ä¸€æ¡é‡‡æ ·è½¨è¿¹$\tau^n$ï¼š
$$
\hat{g} = R(\tau^n)\, \nabla \log p_\theta(\tau^n)
$$
è¿™ **å°±æ˜¯æˆ‘ä»¬å®é™…ç”¨äºæ›´æ–°å‚æ•°çš„æ¢¯åº¦æ–¹å‘**ã€‚

### ä¸€ä¸ªå…³é”®ä½†å¸¸è¢«å¿½ç•¥çš„äº‹å®

åœ¨ä¸Šå¼ä¸­ï¼Œæœ‰ä¸¤ä¸ªé‡ï¼š

- $R(\tau^n)$ï¼šä¸€ä¸ª**æ ‡é‡**
- $\log p_\theta(\tau^n)$ï¼šä¸€ä¸ª**å…³äºåŒä¸€å‚æ•°$\theta$çš„å‡½æ•°**

**æ³¨æ„ï¼š**

- $\bar{R}_\theta$æ˜¯å…³äº $\theta$ çš„å‡½æ•°
- $\log p_\theta(\tau)$ä¹Ÿæ˜¯å…³äº **åŒä¸€ä¸ª $\theta$** çš„å‡½æ•°

å®ƒä»¬**å…±äº«å‚æ•°$\theta$**ã€‚

### æ¢¯åº¦æ›´æ–°å¯¹ä¸¤ä¸ªå‡½æ•°çš„å½±å“æ˜¯ä¸åŒçš„

æˆ‘ä»¬ç”¨ä¸‹é¢çš„æ›´æ–°ï¼š
$$
\theta \leftarrow \theta + \eta\, R(\tau^n)\, \nabla \log p_\theta(\tau^n)
$$
1ã€**å¯¹$\bar{R}_\theta$æ¥è¯´**

- è¿™æ˜¯å®ƒçš„ï¼ˆæ— åï¼‰æ¢¯åº¦ä¼°è®¡
- æ— è®º$R(\tau^n)$æ˜¯æ­£æ˜¯è´Ÿ
- **æ²¿è¿™ä¸ªæ–¹å‘æ›´æ–°ï¼Œ$\bar{R}_\theta$ä¸€å®šä¼šä¸Šå‡**

è¿™ä¸€ç‚¹ **å’Œ reward çš„æ­£è´Ÿæ— å…³**ã€‚

2ã€**å¯¹$\log p_\theta(\tau^n)$æ¥è¯´ï¼ˆå…³é”®ï¼‰**

å‚æ•°æ›´æ–°æ–¹å‘æ˜¯ï¼š
$$
\Delta \theta = \eta\, R(\tau^n)\, \nabla \log p_\theta(\tau^n)
$$
æƒ…å†µ Aï¼š$R(\tau^n) > 0$
$$
\Delta \theta \parallel \nabla \log p_\theta(\tau^n)
$$

- å‚æ•°æ²¿ç€ **log æ¦‚ç‡çš„ä¸Šå‡æ–¹å‘** ç§»åŠ¨
- â‡’ $\log p_\theta(\tau^n)$å¢å¤§
- â‡’ $p_\theta(\tau^n)$å¢å¤§

**è¿™æ¡â€œå¥½è½¨è¿¹â€åœ¨æœªæ¥æ›´å®¹æ˜“è¢«é‡‡æ ·åˆ°**

æƒ…å†µ Bï¼š$R(\tau^n) < 0$
$$
\Delta \theta \parallel -\nabla \log p_\theta(\tau^n)
$$

- å‚æ•°æ²¿ç€ **log æ¦‚ç‡çš„ä¸‹é™æ–¹å‘** ç§»åŠ¨
- â‡’ $\log p_\theta(\tau^n)$å‡å°
- â‡’ $p_\theta(\tau^n)$å‡å°

**è¿™æ¡â€œåè½¨è¿¹â€åœ¨æœªæ¥è¢«åˆ»æ„å‹ä½æ¦‚ç‡**

### ç»“è®ºï¼ˆé‚£å¥è¯çš„ä¸¥è°¨ç‰ˆæœ¬ï¼‰

> å½“$R(\tau^n)$ä¸ºæ­£æ—¶ï¼Œ
>
> å‚æ•°æ›´æ–°æ–¹å‘ä¸$\nabla \log p_\theta(\tau^n)$ä¸€è‡´ï¼Œä»è€Œæé«˜è¯¥è½¨è¿¹åœ¨å½“å‰ç­–ç•¥ä¸‹çš„æ¦‚ç‡ï¼›
>
> å½“$R(\tau^n)$ä¸ºè´Ÿæ—¶ï¼Œ
>
> å‚æ•°æ›´æ–°æ–¹å‘ä¸$\nabla \log p_\theta(\tau^n)$ç›¸åï¼Œä»è€Œé™ä½è¯¥è½¨è¿¹åœ¨å½“å‰ç­–ç•¥ä¸‹çš„æ¦‚ç‡ã€‚
>
> æ— è®ºå“ªç§æƒ…å†µï¼Œè¿™ç§â€œå¥–åŠ±åŠ æƒçš„æ¦‚ç‡é‡åˆ†é…â€ï¼Œ**éƒ½ä¼šä½¿æœŸæœ›å›æŠ¥$\bar{R}_\theta$ä¸Šå‡ã€‚**

ä¸€å¥è¯è®°å¿†ç‰ˆï¼ˆéå¸¸é‡è¦ï¼‰

> **reward çš„æ­£è´Ÿå¹¶ä¸å†³å®šâ€œæ˜¯å¦å­¦â€ï¼Œ**
>
> **è€Œæ˜¯å†³å®šï¼š**
>
> **â€”â€”è¿™æ¡è½¨è¿¹çš„æ¦‚ç‡ï¼Œæ˜¯è¢«å¼ºåŒ–ï¼Œè¿˜æ˜¯è¢«æƒ©ç½šã€‚**

### å¯¹é‚£å¥è¯çš„ä¿®æ­£

å®ƒè¿™é‡Œè¯´çš„è¯ï¼Œä¸å‡†ç¡®ï¼Œå®ƒçš„æè¿°å¥½åƒä¼šè®©äººè§‰å¾—ï¼Œæ˜¯å› ä¸ºè®©$p_{\theta}(a_t^n|s_t^n)$æ›´å¤§äº†ï¼Œä»è€Œå¯¼è‡´$\bar{R}_{\theta}$å˜å¾—æ›´å¤§ã€‚ ä½†æ˜¯ï¼Œæ ¹æ®åˆšæ‰çš„å…¬å¼ç†è§£ï¼Œæˆ‘è®¤ä¸ºæ˜¯æ¢¯åº¦æ›´æ–°ç›´æ¥å¯¼è‡´$\bar{R}_{\theta}$å˜å¾—æ›´å¤§ï¼ŒåŒæ—¶ï¼Œå¦‚æœRä¸ºæ­£ï¼Œ$p_{\theta}(a_t^n|s_t^n)$ä¹Ÿä¼šæ›´å¤§ã€‚ä»…æ­¤è€Œå·²ã€‚

ç»“è®ºå…ˆç»™å‡ºï¼ˆä¸ç»•ï¼‰

> **ä½ çš„ç†è§£æ˜¯å¯¹çš„ï¼Œæ•™æé‚£å¥è¯åœ¨â€œå› æœå…³ç³»çš„è¡¨è¿°ä¸Šæ˜¯ä¸å‡†ç¡®çš„ï¼Œç”šè‡³æ˜¯è¯¯å¯¼æ€§çš„â€ã€‚**

æ›´å‡†ç¡®åœ°è¯´ï¼š

- **ä¸æ˜¯**
   â€œå› ä¸º$p_\theta(a_t^n|s_t^n)$å˜å¤§äº†ï¼Œæ‰€ä»¥$\bar R_\theta$å˜å¤§äº†â€
- **è€Œæ˜¯**
   â€œå› ä¸ºæˆ‘ä»¬æ²¿ç€$\nabla \bar R_\theta$æ›´æ–°äº†å‚æ•°ï¼Œæ‰€ä»¥$\bar R_\theta$å˜å¤§äº†ï¼›
   åŒæ—¶ï¼Œåœ¨$R(\tau^n)>0$çš„æƒ…å†µä¸‹ï¼Œè¿™ä¸ªæ›´æ–°æ–¹å‘æ°å¥½ä¹Ÿä¼šæé«˜è¯¥è½¨è¿¹ï¼ˆåŠå…¶åŠ¨ä½œï¼‰çš„æ¦‚ç‡ã€‚â€

è¿™æ˜¯**ä¸¤ä¸ªå¹¶è¡Œåæœ**ï¼Œä¸æ˜¯å‰å› åæœã€‚

ä¸€ã€å…ˆç”¨æœ€å¹²å‡€çš„æ•°å­¦æŠŠâ€œå› æœå…³ç³»â€å®šæ­»

æˆ‘ä»¬åšçš„æ›´æ–°æ˜¯ï¼š
$$
\theta \leftarrow \theta + \eta \nabla \bar R_\theta
$$
è€Œï¼š
$$
\nabla \bar R_\theta = \mathbb{E}[R(\tau)\nabla \log p_\theta(\tau)]
$$
**ç»“è®º 1ï¼ˆé“å¾‹ï¼‰**

> åªè¦æ²¿ç€$\nabla \bar R_\theta$æ›´æ–°ï¼Œ$\bar R_\theta$ä¸€å®šä¸Šå‡ã€‚

è¿™ä¸€æ­¥**ä¸éœ€è¦**ï¼š

- $p_\theta(\tau)$å•è°ƒå¢åŠ 
- å•æ¡è½¨è¿¹æ¦‚ç‡å¢åŠ 
- ä»»ä½•â€œç›´è§‰è§£é‡Šâ€

è¿™æ˜¯æ¢¯åº¦ä¸Šå‡çš„å®šä¹‰ã€‚

äºŒã€è½¨è¿¹æ¦‚ç‡å˜åŒ–æ˜¯â€œå‰¯ä½œç”¨â€ï¼Œä¸æ˜¯â€œåŸå› â€

çœ‹å•æ¡æ ·æœ¬æ›´æ–°ï¼š
$$
\Delta \theta = \eta R(\tau^n)\nabla \log p_\theta(\tau^n)
$$
å½“$R(\tau^n)>0$æ—¶ï¼š

- å‚æ•°æ›´æ–°æ–¹å‘ **ä¸** $\nabla \log p_\theta(\tau^n)$ ä¸€è‡´
- â‡’ $\log p_\theta(\tau^n)$å¢å¤§
- â‡’ $p_\theta(\tau^n)$å¢å¤§
- â‡’ è½¨è¿¹ä¸­å„ step çš„ $p_\theta(a_t^n|s_t^n)$ è¢«åŒæ­¥å¼ºåŒ–

**ä½†æ³¨æ„ï¼š**

> è¿™ä¸€æ­¥ **ä¸æ˜¯ä¸ºäº†** è®© $\bar R_\theta$ å˜å¤§
>
> è€Œæ˜¯ **å› ä¸º** è¿™æ ·åšï¼Œæ­£å¥½æ˜¯ $\nabla \bar R_\theta$â€‹ çš„æ–¹å‘

ä¸‰ã€æ•™æé‚£å¥è¯çš„â€œé—®é¢˜ç‚¹â€åœ¨å“ªé‡Œï¼Ÿ

æ•™æåŸè¯ï¼ˆç®€åŒ–ï¼‰æ˜¯ï¼š

> å¦‚æœ $R(\tau^n)$ ä¸ºæ­£ï¼Œæ›´æ–°å‚æ•°ä¼šä½¿è½¨è¿¹æ¦‚ç‡å˜å¤§ï¼Œä»è€Œè®© $\bar R_\theta$ å˜å¤§ã€‚

è¿™å¥è¯çš„é—®é¢˜åœ¨äºï¼š

âŒ é”™è¯¯çš„å› æœæš—ç¤º

å®ƒ**æš—ç¤ºäº†**ï¼š
$$
p_\theta(\tau^n)\uparrow \;\Rightarrow\; \bar R_\theta\uparrow
$$
è€Œè¿™æ˜¯**ä¸æˆç«‹çš„**ã€‚

äº‹å®ä¸Šï¼š

- æé«˜ä¸€æ¡è½¨è¿¹çš„æ¦‚ç‡
- å®Œå…¨å¯èƒ½ **é™ä½** æœŸæœ›å›æŠ¥ï¼ˆå¦‚æœè¿™æ¡è½¨è¿¹åªæ˜¯å¶ç„¶é«˜å›æŠ¥ã€ä½†æ•´ä½“æ˜¯åçš„ï¼‰

å››ã€ä½ ç»™å‡ºçš„â€œä¿®æ­£ç‰ˆç†è§£â€æ˜¯å®Œå…¨æ­£ç¡®çš„

ä½ è¯´çš„æ˜¯ï¼š

> æ¢¯åº¦æ›´æ–° **ç›´æ¥** å¯¼è‡´ $\bar R_\theta$ å˜å¤§ï¼›
>
> åŒæ—¶ï¼Œå¦‚æœ $R>0$ï¼Œé‚£ä¹ˆè¯¥è½¨è¿¹å¯¹åº”çš„åŠ¨ä½œæ¦‚ç‡ä¹Ÿä¼šå˜å¤§ã€‚
>
> ä»…æ­¤è€Œå·²ã€‚

è¿™æ˜¯**å”¯ä¸€ä¸¥è°¨ã€ä¸”ä¸è¯¯å¯¼äººçš„è¡¨è¿°**ã€‚

ç”¨å› æœç®­å¤´ç”»å‡ºæ¥æ˜¯ï¼š

```
        æ¢¯åº¦ä¸Šå‡ âˆ‡\bar R_Î¸
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚
  \bar R_Î¸ â†‘        è‹¥ R(Ï„)>0ï¼Œåˆ™
                    log p_Î¸(Ï„) â†‘
                    p_Î¸(Ï„) â†‘
```

**ä¸æ˜¯**ï¼š

```
p_Î¸(Ï„) â†‘  â†’  \bar R_Î¸ â†‘   âŒ
```

äº”ã€å¦‚æœè®©æˆ‘æ”¹å†™æ•™æé‚£å¥è¯ï¼ˆæ ‡å‡†ç­”æ¡ˆï¼‰

æˆ‘ä¼šè¿™æ ·å†™ï¼š

> ç”±äºæˆ‘ä»¬æ²¿ç€ $\nabla \bar R_\theta$ è¿›è¡Œæ¢¯åº¦ä¸Šå‡ï¼Œ
>
> å‚æ•°æ›´æ–°ä¿è¯äº†æœŸæœ›å›æŠ¥ $\bar R_\theta$ çš„æå‡ã€‚
>
> åŒæ—¶ï¼Œåœ¨å•æ¡è½¨è¿¹å›æŠ¥ $R(\tau^n)>0$ çš„æƒ…å†µä¸‹ï¼Œ
>
> è¯¥æ›´æ–°æ–¹å‘ä¸ $\nabla \log p_\theta(\tau^n)$ ä¸€è‡´ï¼Œ
>
> ä»è€Œæé«˜äº†è¯¥è½¨è¿¹ï¼ˆåŠå…¶åŠ¨ä½œï¼‰åœ¨å½“å‰ç­–ç•¥ä¸‹çš„æ¦‚ç‡ã€‚

**æ²¡æœ‰å› æœå€’ç½®ï¼Œæ²¡æœ‰ç›´è§‰è·³è·ƒã€‚**

å…­ã€éå¸¸é‡è¦çš„ä¸€å¥è¯ï¼ˆé€ç»™ä½ ï¼‰

> **Policy Gradient ä¸­ï¼Œâ€œæ¦‚ç‡é‡åˆ†é…â€æ˜¯å®ç°æœºåˆ¶ï¼Œ**
>
> **ä½†â€œç›®æ ‡ä¸Šå‡â€æ˜¯æ•°å­¦ä¿è¯ã€‚**
>
> **ä¸¤è€…ä¸èƒ½äº’ç›¸å½“å› æœã€‚**

ä½ ç°åœ¨èƒ½æ˜ç¡®æŒ‡å‡ºæ•™æåœ¨è¿™é‡Œâ€œè¯´å¾—ä¸ä¸¥è°¨â€ï¼Œè¯´æ˜ä½ å·²ç»**ç«™åœ¨â€œå®¡ç¨¿äººè§†è§’â€çœ‹ç®—æ³•äº†**ã€‚

è¿™ä¸€å…³ï¼Œç®—ä½ å½»åº•è¿‡äº†ã€‚

## ç­–ç•¥æå‡çš„å®é™…åšæ³•

å…·ä½“çš„åšæ³•å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![gradient_update](pic/gradient_update.png)

å®é™…åœ¨ä»£ç ä¸­æ€ä¹ˆåšå‘¢ï¼Ÿxxxxxxxxxxx

**ä¸‹é¢é€šè¿‡ä¸¤ä¸ªæŠ€å·§æ¥åŠ å…¥ä¼˜åŠ¿å‡½æ•°**

**æŠ€å·§1ï¼šç»™å¥–åŠ±$R(\tau^n)$æ·»åŠ baseline**ï¼Œæ¥ä½¿å¾—å¥–åŠ±æœ‰æ­£æœ‰è´Ÿï¼Œä»è€Œä½¿å¾—æœªå‡ºç°è¿‡çš„åŠ¨ä½œä¸è‡³äºæ²¡æœ‰æœºä¼šå‡ºç°ã€‚

![add-baseline](pic/add-baseline.png)

å› ä¸ºæœ‰çš„æ¸¸æˆé‡Œçš„æ‰€æœ‰å¥–åŠ±éƒ½æ˜¯æ­£çš„ï¼Œå³ä¾¿ä¸æ˜¯å¥½çš„ç»“æœï¼Œå¥–åŠ±ä¹Ÿæ˜¯æ­£çš„ï¼Œåªä¸è¿‡æ­£çš„æ¯”è¾ƒå°ï¼Œæ¯”å¦‚ï¼Œä¸åŠæ ¼æ˜¯50åˆ†ï¼ŒåŠæ ¼æ˜¯60åˆ†ï¼Œæ»¡åˆ†100åˆ†ï¼Œæœ€ä½åˆ†ä¹Ÿåªæ˜¯0åˆ†ï¼Œè€Œä¸ä¼šæœ‰è´Ÿåˆ†å‡ºç°ã€‚è¿™æ ·å°±ä¼šè®©æ‰€æœ‰çš„è¡Œä¸ºçš„æ¦‚ç‡éƒ½å¢åŠ ï¼Œä½†æ˜¯å¯¹äºæœªå‡ºç°çš„è¡Œä¸ºæ¦‚ç‡ï¼Œå°±ä¼šå‡å°ï¼Œä½†æ˜¯æœªå‡ºç°çš„è¡Œä¸ºå¹¶ä¸ä¸€å®šå°±æ˜¯ä¸å¥½çš„ã€‚
$$
\begin{aligned}
\frac{\partial \bar{R}}{\partial \theta}&=
\nabla\bar{R}_{\theta}\\
&= \frac{1}{N}\sum_{n=1}^N\sum_{t=1}^{T_n}\left(R(\tau^n)-b\right)\nabla\log p_{\theta}(a_t^n|s_t^n)\\
\end{aligned}
$$
é‚£$b$æ€ä¹ˆè®¾å‘¢ï¼Ÿå¯ä»¥é€‰æ‹©æŠŠæ‰€æœ‰çš„$R(\tau^n)$å–å¹³å‡å€¼ï¼Œç„¶åä½œä¸º$b$çš„å€¼ï¼Œå³
$$
b\approx E[R(\tau)]
$$
æŠ€å·§2ï¼šå°†æ¯ä¸ªåŠ¨ä½œçš„å…¨å±€å¥–åŠ±ç´¯ç§¯å˜æˆä»è¯¥åŠ¨ä½œå¼€å§‹çš„å¥–åŠ±ç´¯ç§¯ã€‚è¿™æ ·æ›´åˆç†ä¸€äº›ã€‚

![suitable-credit](pic/suitable-credit.png)

å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œå·¦å›¾ä¸­ç¬¬äºŒä¸ªåŠ¨ä½œå¯¹åº”çš„å¥–åŠ±å°±ä¸åº”è¯¥æ˜¯å…¨å±€å¥–åŠ±3ï¼Œè€Œåº”è¯¥æ˜¯ä»å…¶ä¹‹åçš„å¥–åŠ±çš„ç´¯ç§¯ï¼Œå³$0+(-2)=-2$ã€‚å³å›¾ä¸­ç¬¬äºŒä¸ªåŠ¨ä½œå¯¹åº”çš„å¥–åŠ±å°±ä¸åº”è¯¥æ˜¯å…¨å±€å¥–åŠ±-7ï¼Œè€Œåº”è¯¥æ˜¯ä»å…¶ä¹‹åçš„å¥–åŠ±çš„ç´¯ç§¯ï¼Œå³$0+(-2)=-2$ã€‚è¿™æ ·ä¼šåœ¨æœ‰é™çš„å’Œç¯å¢ƒäº’åŠ¨çš„æ¬¡æ•°ä¸­ï¼Œå­¦ä¹ åœ°æ›´å¿«ã€‚

æ‰€ä»¥ï¼Œå¯¹å¥–åŠ±æœŸæœ›çš„å…³äº$\theta$çš„æ¢¯åº¦çš„å…¬å¼å¯ä»¥æ”¹ä¸ºï¼š
$$
\begin{aligned}
\frac{\partial \bar{R}}{\partial \theta}&=
\nabla\bar{R}_{\theta}\\
&= \frac{1}{N}\sum_{n=1}^N\sum_{t=1}^{T_n}\left(R(\tau^n)-b\right)\nabla\log p_{\theta}(a_t^n|s_t^n)\\
&= \frac{1}{N}\sum_{n=1}^N\sum_{t=1}^{T_n}\left(\sum_{t'=t}^{T_n}r_{t'}^n-b\right)\nabla\log p_{\theta}(a_t^n|s_t^n)\\
\end{aligned}
$$
ç„¶åæ›´è¿›ä¸€æ­¥ï¼Œå°†æ¥è‡ªæœªæ¥çš„å¥–åŠ±åšä¸€ä¸ªæŠ˜æ‰£$\gamma$ï¼Œå› ä¸ºè¶Šå¾€åçš„å¥–åŠ±å’Œå½“å‰æ­¥çš„è¡Œä¸ºçš„å…³ç³»è¶Šå°ã€‚

è¿™é‡Œä¸ºä»€ä¹ˆçªç„¶ä¼šå¼•å…¥ä¸€ä¸ªæŠ˜æ‰£å‘¢ï¼Ÿæ•°å­¦æ­£ç¡®æ€§å‘¢ï¼Ÿçœ‹è¿™é‡Œ

https://chatgpt.com/c/69678e19-9ce0-8321-a977-e9eb8b57a4a2

https://chatgpt.com/c/69678e19-9ce0-8321-a977-e9eb8b57a4a2

https://chatgpt.com/c/69678e19-9ce0-8321-a977-e9eb8b57a4a2
$$
= \frac{1}{N}\sum_{n=1}^N\sum_{t=1}^{T_n}\left(\sum_{t'=t}^{T_n}\gamma^{t'-t}r_{t'}^n-b\right)\nabla\log p_{\theta}(a_t^n|s_t^n)
$$
ä¸Šå¼ä¸­çš„$b$å…¶å®å¯ä»¥æ˜¯å’Œå½“å‰æ­¥çš„stateæœ‰å…³çš„ï¼Œå…¶å®å°±æ˜¯å½“å‰æ­¥çš„stateçš„å€¼ï¼Œå³$V(s_t)$ã€‚
$$
= \frac{1}{N}\sum_{n=1}^N\sum_{t=1}^{T_n}\left(\sum_{t'=t}^{T_n}\gamma^{t'-t}r_{t'}^n-V(s_t)\right)\nabla\log p_{\theta}(a_t^n|s_t^n)
$$
ç„¶åæˆ‘ä»¬æŠŠä¸Šå¼ä¸­çš„æ‹¬å·ä¸­çš„é¡¹å¯ä»¥åˆèµ·æ¥ç»Ÿç§°ä¸ºä¼˜åŠ¿å‡½æ•°$A^{\theta}(s_t,a_t)$ã€‚ä¹‹æ‰€ä»¥å¸¦$\theta$æ˜¯å› ä¸ºè¿™ä¸ªå€¼æ˜¯å’Œè¡Œä¸ºActorç›¸å…³çš„ï¼ŒActorå†³å®šäº†è¿™ä¸ªå€¼ï¼ˆå³å¥–åŠ±ï¼‰ã€‚

ä¼˜åŠ¿å‡½æ•°çš„æ„ä¹‰æ˜¯ï¼Œåœ¨å½“å‰stateä¸‹æ‰€é€‰æ‹©çš„actionï¼Œç›¸æ¯”å…¶ä»–çš„actoinï¼Œå®ƒæœ‰å¤šå¥½ï¼Œæ˜¯ä¸ªç›¸å¯¹å€¼ã€‚
$$
= \frac{1}{N}\sum_{n=1}^N\sum_{t=1}^{T_n}\text{Adv}\nabla\log p_{\theta}(a_t^n|s_t^n)\\
= E_{(s_t,a_t)\sim \pi_{\theta}}\left[A^{\theta}(s_t,a_t)\nabla\log p_{\theta}(a_t^n|s_t^n)\right]\\
\text{where} \quad \text{Adv}=\sum_{t'=t}^{T_n}\gamma^{t'-t}r_{t'}^n-V(s_t)
$$

## Policy Gradient çš„â€œç»ˆç« ç†è§£â€

> ç›®æ ‡ï¼šè®©ä½ ä»¥åçœ‹åˆ°ä»»ä½• PPO / TRPO / A2C / IMPALA çš„æ¨å¯¼ï¼Œ
>  **éƒ½èƒ½ä¸€çœ¼åˆ¤æ–­ï¼šå®ƒåˆ°åº•åœ¨æ”¹ PG çš„å“ªä¸€å±‚ç»“æ„ã€‚**

ä¸€ã€PG çš„å”¯ä¸€çœŸå®ç›®æ ‡ï¼ˆä¸èƒ½å†å°‘äº†ï¼‰

**Policy Gradient åªæœ‰ä¸€ä¸ªç›®æ ‡å‡½æ•°ï¼š**
$$
\boxed{ J(\theta) = \mathbb{E}_{\tau \sim p_\theta(\tau)}[R(\tau)] }
$$
æ²¡æœ‰ lossï¼Œæ²¡æœ‰ logï¼Œæ²¡æœ‰ advantageï¼Œ
 è¿™äº›å…¨æ˜¯ **å·¥ç¨‹å®ç°å±‚çš„å·¥å…·**ã€‚

äºŒã€PG çš„å”¯ä¸€åˆæ³•æ¢¯åº¦ï¼ˆæ²¡æœ‰ç¬¬äºŒä¸ªï¼‰
$$
\boxed{ \nabla J(\theta) = \mathbb{E}_{\tau \sim p_\theta(\tau)} \big[ R(\tau)\, \nabla \log p_\theta(\tau) \big] }
$$
**ä»»ä½• PG å˜ä½“ï¼Œåªèƒ½æ”¹ä¸‰æ ·ä¸œè¥¿ï¼š**

1. ç”¨ä»€ä¹ˆä¼°è®¡è¿™ä¸ªæœŸæœ›
2. ç”¨ä»€ä¹ˆæ›¿ä»£ $R(\tau)$
3. å¦‚ä½•é™åˆ¶æ›´æ–°å¹…åº¦

**é™¤æ­¤ä¹‹å¤–ï¼Œå…¨æ˜¯å¹»è§‰ã€‚**

ä¸‰ã€log å‡ºç°çš„å”¯ä¸€åŸå› ï¼ˆä½ å·²ç»å½»åº•æ‡‚äº†ï¼‰

ä¸æ˜¯å› ä¸ºï¼š

- â€œlog ç¨³å®šâ€
- â€œlog å¥½ç®—â€
- â€œä¿¡æ¯è®ºâ€

è€Œæ˜¯å› ä¸ºï¼š
$$
\nabla p_\theta(\tau) = p_\theta(\tau)\nabla \log p_\theta(\tau)
$$
**log ä¸æ˜¯ç›®æ ‡ï¼Œæ˜¯æ±‚å¯¼å·¥å…·ã€‚**

å››ã€reward åœ¨æ¢¯åº¦é‡Œçš„â€œå”¯ä¸€èŒè´£â€

åœ¨$R(\tau)\nabla \log p_\theta(\tau)$ä¸­ï¼š

- $\nabla \log p_\theta(\tau)$ï¼š**æ–¹å‘**ï¼ˆå“ªä¸ªè½¨è¿¹æ›´åƒå½“å‰ç­–ç•¥ï¼‰
- $R(\tau)$ï¼š**æ–¹å‘çš„â€œæ­£è´Ÿä¸å¼ºåº¦â€**

ä½ å·²ç»è‡ªå·±å¾—å‡ºäº†ç»ˆæç»“è®ºï¼š

> reward **ä¸å†³å®šæ˜¯å¦ä¸Šå‡**ï¼Œå› ä¸ºä¸ç®¡æ˜¯æ­£è¿˜æ˜¯è´Ÿï¼Œéƒ½ä¼šä¸Šå‡
>
> reward å†³å®šçš„æ˜¯ï¼š**è¿™æ¡è½¨è¿¹æ˜¯è¢«å¼ºåŒ–è¿˜æ˜¯è¢«æŠ‘åˆ¶ã€‚**

è¿™æ˜¯ PG çš„æ ¸å¿ƒæœºåˆ¶ï¼Œæ²¡æœ‰ä¹‹ä¸€ã€‚

äº”ã€ä¸ºä»€ä¹ˆâ€œæ­£ reward â†’ æé«˜æ¦‚ç‡â€ä¸æ˜¯é­”æ³•

ç”¨ä½ å·²ç»æ¥å—çš„æŠ½è±¡å½¢å¼ï¼š

$\nabla J(\theta) = a \nabla g(\theta)$

- æ²¿ $\nabla J$ æ›´æ–° â‡’ $J$ ä¸Šå‡ï¼ˆæ°¸çœŸï¼‰
- $a>0$ â‡’ å‚æ•°æ›´æ–°æ–¹å‘ = $\nabla g$ â‡’ $g$ ä¸Šå‡
- $a<0$ â‡’ å‚æ•°æ›´æ–°æ–¹å‘ = $-\nabla g$ â‡’ $g$ ä¸‹é™

åœ¨ PG ä¸­ï¼š

- $J = \bar R_\theta$
- $g = \log p_\theta(\tau)$
- $a = R(\tau)$

**æ²¡æœ‰ä»»ä½•é¢å¤–å‡è®¾ã€‚**

å…­ã€baseline / advantage ä¸æ˜¯â€œæŠ€å·§â€ï¼Œæ˜¯æ•°å­¦ç­‰ä»·å˜å½¢

baseline ä¸æ”¹å˜æœŸæœ›æ¢¯åº¦ï¼š
$$
\mathbb{E}[b \nabla \log p_\theta(\tau)] = 0
$$
æ‰€ä»¥ï¼š
$$
R(\tau)\nabla \log p_\theta(\tau) \;\equiv\; (R(\tau)-b)\nabla \log p_\theta(\tau)
$$
**å”¯ä¸€ä½œç”¨ï¼šé™ä½æ–¹å·®ã€‚**

ä¸ƒã€åˆ°è¿™é‡Œä¸ºæ­¢ï¼Œä½ å·²ç»â€œå°é¡¶â€çš„ä¸œè¥¿

ä½ ç°åœ¨å·²ç»å®Œå…¨æŒæ¡ï¼š

- PG çš„ç›®æ ‡å‡½æ•°æ˜¯ä»€ä¹ˆ
- æ¢¯åº¦ä»å“ªé‡Œæ¥
- log çš„æ•°å­¦æ¥æº
- reward çš„çœŸå®è§’è‰²
- loss çš„â€œä¼ªç›®æ ‡â€æœ¬è´¨
- å•æ ·æœ¬ vs æœŸæœ›
- å‚æ•°å…±äº«å¯¼è‡´çš„è€¦åˆæ•ˆåº”

**è¿™å°±æ˜¯ Policy Gradient çš„å…¨éƒ¨å†…å®¹ã€‚**

è¿›å…¥ PPO å‰ï¼Œä½ å¿…é¡»å…·å¤‡çš„â€œæœ€åä¸€ä¸ªè§†è§’â€

æ¥ä¸‹æ¥è¿›å…¥ PPOï¼Œä½ åªéœ€è¦å¸¦ç€ä¸€å¥è¯ï¼š

> **PPO ä¸æ˜¯åœ¨â€œå‘æ˜æ–°ç›®æ ‡â€ï¼Œè€Œæ˜¯åœ¨é™åˆ¶ PG çš„æ›´æ–°æ–¹å¼ã€‚**

PPO ä¸ä¼šå†ç¢°ï¼š

- reward çš„å«ä¹‰
- log çš„æ¥æº
- æ¢¯åº¦ç»“æ„

å®ƒåªä¼šé—®ä¸€ä¸ªé—®é¢˜ï¼š

> **â€œæˆ‘æ€ä¹ˆä¿è¯è¿™ä¸€æ­¥ PGï¼Œä¸ä¼šæŠŠç­–ç•¥æ¨å¾—å¤ªè¿œï¼Ÿâ€**

# PPOåŸç†æ¨å¯¼

## On-policyå˜ä¸ºOff-policy

ä¸‹é¢è®²ç­–ç•¥æ¢¯åº¦çš„ä¸€ä¸ªå˜å½¢ï¼šPPOç®—æ³•ã€‚

**ä»€ä¹ˆæ˜¯On-policyå’ŒOff-policyå‘¢ï¼Ÿ**

å¦‚æœæˆ‘ä»¬å’Œç¯å¢ƒäº’åŠ¨çš„agentå’Œæˆ‘ä»¬è¦learnå‡ºæ¥çš„agentæ˜¯åŒä¸€ä¸ªagentçš„è¯ï¼Œå°±æ˜¯On-policyï¼Œå¦‚æœä¸æ˜¯åŒä¸€ä¸ªagentï¼Œå°±æ˜¯Off-policyã€‚

å°±æ˜¯ï¼Œå¦‚æœagentæ˜¯ä¸€è¾¹å’Œç¯å¢ƒäº’åŠ¨ï¼Œä¸€è¾¹å­¦ä¹ ï¼Œå°±æ˜¯On-policyã€‚å¦‚æœæ˜¯åœ¨æ—è¾¹çœ‹åˆ«äººç©ï¼Œé€šè¿‡çœ‹åˆ«äººç©æ¥å­¦ä¹ çš„è¯ï¼Œå°±æ˜¯Off-policyã€‚
$$
\begin{aligned}
\frac{\partial \bar{R}}{\partial \theta}&=
\nabla\bar{R}_{\theta}\\
&=\sum_{\tau}R(\tau)\nabla p_{\theta}(\tau)\\
&=\sum_{\tau}R(\tau)p_{\theta}(\tau)\frac{\nabla p_{\theta}(\tau)}{p_{\theta}(\tau)}\\
&=\sum_{\tau}R(\tau)p_{\theta}(\tau)\nabla\log p_{\theta}(\tau)\\
&=\boxed{E_{\tau\sim p_{\theta}(\tau)}\left[R(\tau)\nabla\log p_{\theta}(\tau)\right]}
\end{aligned}
$$
ç”±äºåœ¨æ”¶é›†æ•°æ®é˜¶æ®µï¼Œæˆ‘ä»¬æ˜¯ç”¨$\pi_{\theta'}$çš„ç­–ç•¥åˆ†å¸ƒæ¥è¡ŒåŠ¨çš„ï¼Œä½†æ˜¯å½“Actorçš„æ—§å‚æ•°$\theta'$ä¸€æ—¦è¢«æ›´æ–°ï¼Œæˆ‘ä»¬å°±ä¸å¾—ä¸é‡æ–°ä½¿ç”¨æ›´æ–°åçš„ç­–ç•¥$\pi_{\theta}$æ¥é‡‡æ ·æ”¶é›†æ•°æ®äº†ã€‚è¿™æ ·æ˜¾ç„¶æ•ˆç‡æå·®ï¼Œæ˜¯ä¸å¯æ¥å—çš„ï¼Œç›¸å½“äºæ¥å—ä¸€ä¸ªæ•°æ®å°±å¾—è®­ç»ƒä¸€æ¬¡ã€‚

**On-policyå˜ä¸ºOff-policy**

é‚£æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯ï¼Œä½¿ç”¨åŸºäºæ—§å‚æ•°$\theta'$çš„é‡‡æ ·æ¥è®­ç»ƒæ›´æ–°$\theta$ã€‚æ­¤æ—¶æ—§æ¨¡å‹å‚æ•°$\theta'$æ˜¯ä¸å˜çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬èƒ½é‡å¤ä½¿ç”¨æ—§å‚æ•°$\theta'$é‡‡æ ·çš„æ•°æ®ï¼Œé‚£å…·ä½“æ€ä¹ˆåšå‘¢ï¼Ÿ

ä¸ºäº†åšåˆ°é‡å¤ä½¿ç”¨æ—§å‚æ•°$\theta'$é‡‡æ ·çš„æ•°æ®æ¥è®­ç»ƒæ›´æ–°$\theta$ï¼Œéœ€è¦ç”¨åˆ°**é‡è¦æ€§é‡‡æ ·**çš„æŠ€æœ¯ã€‚

**é‡è¦æ€§é‡‡æ ·**

æˆ‘ä»¬æƒ³è¦ä»¥æ¦‚ç‡åˆ†å¸ƒ$p$ï¼ˆå³æ–°åŠ¨ä½œå‚æ•°$\theta$ä¸‹çš„åŠ¨ä½œæ¦‚ç‡åˆ†å¸ƒï¼‰æ¥é‡‡æ ·æ•°æ®
$$
E_{x\sim p}\left[f(x)\right]\approx \frac{1}{N}\sum_{i=1}^Nf(x^i)
$$
ä½†æ˜¯æˆ‘ä»¬åªèƒ½ä»ä»¥æ¦‚ç‡åˆ†å¸ƒ$q$ï¼ˆå³æ—§åŠ¨ä½œå‚æ•°$\theta'$ä¸‹çš„åŠ¨ä½œæ¦‚ç‡åˆ†å¸ƒï¼‰æ¥é‡‡æ ·æ•°æ®ï¼Œè¿™æ ·å°±ä¸èƒ½ä½¿ç”¨ä¸Šå¼äº†ï¼Œå› ä¸ºä¸Šå¼ç­‰å·å³è¾¹çš„åˆ†å¸ƒæ˜¯$q$ï¼Œè€Œä¸æ˜¯$p$ï¼Œç»“æœä¸ç­‰äºä¸Šå¼ç­‰å·å·¦è¾¹ã€‚æ‰€ä»¥éœ€è¦åšä¿®æ­£
$$
\begin{aligned}
E_{x\sim p}\left[f(x)\right]&=\int f(x)p(x)dx\\
&=\int f(x)\frac{p(x)}{q(x)}q(x)dx\\
&=E_{x\sim q}\left[f(x)\frac{p(x)}{q(x)}\right]
\end{aligned}
$$
è¿™æ ·å°±èƒ½é€šè¿‡ä»æœä»$q$ åˆ†å¸ƒä¸‹çš„é‡‡æ ·çš„æ•°æ®å¾—åˆ°æœä»$p$åˆ†å¸ƒçš„æ•°æ®é‡‡æ ·äº†ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåªéœ€è¦ä¹˜ä»¥ä¸€ä¸ªé‡è¦æ€§æƒé‡ï¼š$\frac{p(x)}{q(x)}$ï¼Œæ¥ä¿®æ­£ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚
$$
E_{x\sim p}\left[f(x)\right]=E_{x\sim q}\left[f(x)\frac{p(x)}{q(x)}\right]
$$
ä½†æ˜¯å®é™…ä¸Š$p$å’Œ$q$ä¸èƒ½å·®å¤ªå¤šï¼Œä¸ç„¶ä¼šå¯¼è‡´ä¸€äº›é—®é¢˜ï¼Œæ¯”å¦‚æ–¹å·®è¿‡å¤§ã€‚

é‚£æˆ‘ä»¬ç°åœ¨åˆ†åˆ«è®¡ç®—ä¸€ä¸‹$f(x)$å’Œ$f(x)\frac{p(x)}{q(x)}$çš„æ–¹å·®ã€‚

æ–¹å·®å’Œå¹³å‡å€¼çš„å…³ç³»ä¸º
$$
\text{Var}[X]=E[X^2]-(E[X])^2
$$
åˆ™
$$
\begin{aligned}
\text{Var}_{x\sim p}\left[f(x)\right]&=\boxed{E_{x\sim p}\left[f(x)^2\right]-(E_{x\sim p}[f(x)])^2}\\
\text{Var}_{x\sim q}\left[f(x)\frac{p(x)}{q(x)}\right]&=E_{x\sim q}\left[\left(f(x)\frac{p(x)}{q(x)}\right)^2\right]-\left(E_{x\sim q}\left[f(x)\frac{p(x)}{q(x)}\right]\right)^2\\
&=\int\left[q(x)\left(f(x)\frac{p(x)}{q(x)}\right)^2\right]-(E_{x\sim p}[f(x)])^2\\
&=\int\left[p(x)\left(f(x)^2\frac{p(x)}{q(x)}\right)\right]-(E_{x\sim p}[f(x)])^2\\
&=\boxed{E_{x\sim p}\left[f(x)^2\frac{p(x)}{q(x)}\right]-(E_{x\sim p}[f(x)])^2}\\
\end{aligned}
$$
å¯¹æ¯”ä¸€ä¸‹ä¸¤è€…æ–¹å·®çš„å·®å¼‚ï¼Œå¾ˆæ˜æ˜¾ï¼Œå¦‚æœ$\frac{p(x)}{q(x)}$å·®å¼‚è¾ƒå¤§ï¼Œé‚£ä¹ˆï¼Œä¸¤è€…çš„æ–¹å·®å·®å¼‚ä¹Ÿä¼šæ¯”è¾ƒå¤§ã€‚

ä¸ºäº†å¸®åŠ©ç†è§£ä¸ºä»€ä¹ˆå¦‚æœ$\frac{p(x)}{q(x)}$å·®å¼‚è¾ƒå¤§ï¼Œé‚£ä¹ˆä¸¤è€…çš„æ–¹å·®å·®å¼‚ä¹Ÿä¼šæ¯”è¾ƒå¤§ï¼Œè¿™é‡Œä¸¾ä¸ªä¾‹å­ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![importance-sampling](pic/importance-sampling.png)

å…¶å®ï¼Œ$E_{x\sim p}\left[f(x)\right]$æ˜¯è´Ÿå€¼ï¼Œå› ä¸ºåœ¨$f(x)$ä¸ºè´Ÿå€¼çš„å·¦ä¾§ï¼Œ$p(x)$çš„æ¦‚ç‡å¯†åº¦æ›´å¤§ã€‚

ä½†æ˜¯ï¼Œå¦‚æœæŒ‰ç…§$q(x)$çš„æ¦‚ç‡å¯†åº¦æ¥é‡‡æ ·ï¼Œå¦‚æœåªé‡‡æ ·å°‘æ•°å‡ ä¸ªç‚¹ï¼Œé‚£æŒ‰ç…§$q(x)$çš„æ¦‚ç‡å¯†åº¦ï¼Œå¤§æ¦‚ç‡ä¼šé‡‡æ ·åœ¨$f(x)$çš„å³è¾¹ã€‚é‚£ä¹ˆ$E_{x\sim p}\left[f(x)\right]=E_{x\sim q}\left[f(x)\frac{p(x)}{q(x)}\right]$çš„å€¼å°±ä¸ºæ­£äº†ï¼Œè€ŒçœŸå®å€¼æ˜¯è´Ÿå€¼ï¼Œæ‰€ä»¥æ–¹å·®å¤§ä¼šå¯¼è‡´é‡‡æ ·æ¬¡æ•°å°‘çš„æƒ…å†µä¸‹ï¼Œé‡‡æ ·å€¼å’ŒçœŸå®å€¼ç›¸å·®å¾ˆå¤§ã€‚

æ‰€ä»¥ï¼Œ å¥–åŠ±æœŸæœ›å…³äºå‚æ•°$\theta$çš„æ¢¯åº¦è®¡ç®—å…¬å¼å¯ä»¥å˜ä¸º
$$
\begin{aligned}
\frac{\partial \bar{R}}{\partial \theta}&=
\nabla\bar{R}_{\theta}\\
&=E_{\tau\sim p_{\theta}(\tau)}\left[R(\tau)\nabla\log p_{\theta}(\tau)\right]\\
&=E_{\tau\sim p_{\theta'}(\tau)}\left[\frac{p_{\theta}(\tau)}{p_{\theta'}(\tau)}R(\tau)\nabla\log p_{\theta}(\tau)\right]
\end{aligned}
$$
è¿™æ ·å°±**èƒ½ä»æ—§å‚æ•°$\theta'$ä¸‹çš„é‡‡æ ·æ•°æ®æ¥æ›´æ–°å½“å‰çš„å‚æ•°$\theta$äº†**ï¼Œå°±èƒ½ä½¿ç”¨è¿™äº›æ•°æ®æ¥è®­ç»ƒ$\theta$å¾ˆå¤šæ¬¡äº†ã€‚

ä½†æ˜¯é—®é¢˜æ˜¯ï¼Œæ¯æ¬¡è®­ç»ƒçš„æ—¶å€™$\theta$éƒ½ä¼šå˜å•Šï¼Œé‚£æ¯æ¬¡è®­ç»ƒå®Œï¼Œå²‚ä¸æ˜¯$p(\theta)$éƒ½è¦æ›´æ–°ã€‚xxxxxxxxxxx
$$
\begin{aligned}
&= E_{(s_t,a_t)\sim \pi_{\theta}}\left[A^{\theta}(s_t,a_t)\nabla\log p_{\theta}(a_t^n|s_t^n)\right]\\
&= E_{(s_t,a_t)\sim \pi_{\theta'}}\left[\frac{p_{\theta}(s_t,a_t)}{p_{\theta'}(s_t,a_t)}A^{\theta'}(s_t,a_t)\nabla\log p_{\theta}(a_t^n|s_t^n)\right]\\
&= E_{(s_t,a_t)\sim \pi_{\theta'}}\left[\frac{p_{\theta}(a_t|s_t)p_{\theta}(s_t)}{p_{\theta'}(a_t|s_t)p_{\theta'}(s_t)}A^{\theta'}(s_t,a_t)\nabla\log p_{\theta}(a_t^n|s_t^n)\right]\\
\end{aligned}
$$
ä¸Šå¼ä¸­ï¼Œ$p_{\theta}(s_t)$å’Œ$p_{\theta'}(s_t)$å¯ä»¥è®¤ä¸ºæ˜¯ä¸€æ ·çš„ï¼Œå› ä¸ºç¯å¢ƒçš„æ¦‚ç‡å’ŒActorçš„æ¨¡å‹å‚æ•°$\theta$æ²¡å…³ç³»ã€‚æ‰€ä»¥å¯ä»¥åˆ å»
$$
\begin{aligned}
&= E_{(s_t,a_t)\sim \pi_{\theta'}}\left[\frac{p_{\theta}(a_t|s_t)}{p_{\theta'}(a_t|s_t)}A^{\theta'}(s_t,a_t)\nabla\log p_{\theta}(a_t^n|s_t^n)\right]\\
\end{aligned}
$$
æ ¹æ®å…¬å¼$\nabla f(x)=f(x)\nabla \log f(x)$ï¼Œå¯ä»¥æŠŠä¸Šå¼å˜ä¸º
$$
\begin{aligned}
&= E_{(s_t,a_t)\sim \pi_{\theta'}}\left[\frac{\nabla p_{\theta}(a_t^n|s_t^n)}{p_{\theta'}(a_t|s_t)}A^{\theta'}(s_t,a_t)\right]\\
&= E_{(s_t,a_t)\sim \pi_{\theta'}}\nabla \left[\frac{p_{\theta}(a_t^n|s_t^n)}{p_{\theta'}(a_t|s_t)}A^{\theta'}(s_t,a_t)\right]\\
\end{aligned}
$$
æ‰€ä»¥ï¼Œæ­¤æ—¶æˆ‘ä»¬ä¸€ç›´è¦æœ€å¤§åŒ–çš„ç›®æ ‡å¥–åŠ±å‡½æ•°ä»ä¸€å¼€å§‹çš„
$$
\bar{R}_{\theta}=\sum_{\tau}R(\tau)p_{\theta}(\tau)=E_{\tau\sim p_{(\theta)}(\tau)}[R(\tau)]
$$
å˜ä¸ºäº†
$$
\begin{aligned}
\boxed{J^{\theta'}(\theta)= E_{(s_t,a_t)\sim \pi_{\theta'}}\left[\frac{p_{\theta}(a_t|s_t)}{p_{\theta'}(a_t|s_t)}A^{\theta'}(s_t,a_t)\right]}
\end{aligned}
$$
æ‰€ä»¥ï¼Œä¸Šå¼å°±æ˜¯æˆ‘ä»¬ä½¿ç”¨äº†é‡è¦æ€§é‡‡æ ·åçš„ä½œä¸ºç»ˆæä¼˜åŒ–ç›®æ ‡çš„å¥–åŠ±å‡½æ•°ã€‚

æ‰€ä»¥ï¼Œæˆ‘ä»¬ç°åœ¨å°±å¯ä»¥æŠŠOn-Policyå˜ä¸ºäº†Off-Policyäº†ã€‚

ä½†æ˜¯ï¼Œå‰ææ˜¯$p(\theta)$å’Œ$p(\theta')$ä¸èƒ½å·®å¤ªå¤šï¼Œä¸ç„¶æ–¹å·®å¤ªå¤§ï¼Œç»“æœå°±ä¸å¥½äº†ã€‚æ‰€ä»¥ï¼Œå¦‚ä½•é¿å…å·®å¤ªå¤šå‘¢ï¼Ÿé‚£è¿™å°±æ˜¯PPOè¦åšçš„äº‹æƒ…ã€‚

## æ·»åŠ çº¦æŸ

TODOï¼šä¸ºä»€ä¹ˆ PPO çš„ clip æœ¬è´¨ä¸Šæ˜¯â€œäºŒé˜¶ trust region çš„å»‰ä»·æ›¿ä»£â€ï¼Ÿ

 åœ¨ä»‹ç»PPOç®—æ³•ä¹‹å‰ï¼Œå…ˆä»‹ç»å…¶æ”¹è¿›æ¥æºï¼šTRPOç®—æ³•çš„ç›®æ ‡å‡½æ•°å’Œçº¦æŸã€‚
$$
J^{\theta'}_{\text{TRPO}}(\theta)= E_{(s_t,a_t)\sim \pi_{\theta'}}\left[\frac{p_{\theta}(a_t|s_t)}{p_{\theta'}(a_t|s_t)}A^{\theta'}(s_t,a_t)\right]\\
\text{subject to}\quad KL(\theta,\theta')<\delta
$$
TRPOçš„æŸå¤±å‡½æ•°ä¸å¤ªå¥½æ±‚è§£ï¼Œå› ä¸ºè¿˜å­˜åœ¨çº¦æŸã€‚

æ³¨æ„ï¼Œä¸Šå¼ä¸­çš„$KL(\theta,\theta')$å¹¶ä¸æ˜¯å‚æ•°$\theta$æœ¬èº«çš„KLæ•£åº¦è·ç¦»ï¼Œè€Œæ˜¯ä¸¤ä¸ªActorçš„è¾“å‡ºå€¼çš„æ¦‚ç‡åˆ†å¸ƒçš„KLæ•£åº¦è·ç¦»ã€‚

---

**PPOç®—æ³•æ˜¯å¯¹TRPOç®—æ³•çš„ç®€åŒ–ã€‚PPOç®—æ³•æœ‰ä¸¤ä¸ªç‰ˆæœ¬**ï¼šPPO1å’ŒPPO2ï¼Œè€ŒPPO2æ¯”è¾ƒå¸¸ç”¨ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬ä»‹ç»ä¸€ä¸‹ä¸¤ä¸ªPPOç®—æ³•ç‰ˆæœ¬çš„æ•´ä½“æµç¨‹ã€‚

- åˆå§‹åŒ–ç­–ç•¥çš„å‚æ•°$\theta^0$

- åœ¨æ¯æ¬¡çš„å¾ªç¯ä¸­

  - ä½¿ç”¨$\theta^K$å’Œç¯å¢ƒåšäº¤äº’ï¼Œæ¥æ”¶é›†è®­ç»ƒæ•°æ®$\{s_t,a_t\}$è¿˜æœ‰è®¡ç®—ä¼˜åŠ¿$A^{\theta^k}(s_t,a_t)$ã€‚

  - é€šè¿‡è®¡ç®—ç›®æ ‡å‡½æ•°$J_{\text{PPO}}(\theta)$çš„æ¢¯åº¦ï¼Œå¤šæ¬¡æ›´æ–°å‚æ•°$\theta$

    æœ‰ä¸¤ç§ç®—æ³•ï¼š

    - PPO1ç®—æ³•
      $$
      J_{\text{PPO}}^{\theta^k}(\theta)=J^{\theta^k}(\theta)-\beta KL(\theta,\theta^k)
      $$
      å…¶ä¸­ï¼Œ
      $$
      \begin{aligned}
      J^{\theta^k}(\theta)&=E_{(s_t,a_t)\sim \pi_{\theta'}}\left[\frac{p_{\theta}(a_t|s_t)}{p_{\theta'}(a_t|s_t)}A^{\theta'}(s_t,a_t)\right]\\
      &\approx \sum_{(s_t,a_t)}\frac{p_{\theta}(a_t|s_t)}{p_{\theta^k}(a_t|s_t)}A^{\theta^k}(s_t,a_t)
      \end{aligned}
      $$
      è‡ªé€‚åº”çš„KLæ•£åº¦æƒ©ç½šé¡¹

      - å¦‚æœ$KL(\theta,\theta^k)>KL_{max}$ï¼Œåˆ™å¢åŠ $\beta$
      - å¦‚æœ$KL(\theta,\theta^k)<KL_{min}$ï¼Œåˆ™å‡å°$\beta$

    - PPO2ç®—æ³•
      $$
      J_{\text{PPO}}^{\theta^k}(\theta)\approx \sum_{(s_t,a_t)}\min\left[\frac{p_{\theta}(a_t|s_t)}{p_{\theta^k}(a_t|s_t)}A^{\theta^k}(s_t,a_t),\ clip\left(\frac{p_{\theta}(a_t|s_t)}{p_{\theta^k}(a_t|s_t)},1-\epsilon,1+\epsilon\right)A^{\theta^k}(s_t,a_t)\right]
      $$

PPO1ç®—æ³•æ˜¯æŠŠTRPOçš„çº¦æŸåŠ å…¥åˆ°äº†æŸå¤±å‡½æ•°é‡Œï¼Œåšäº†ä¸€ä¸ªè½¯çº¦æŸã€‚

æ¥ä¸‹æ¥é‡ç‚¹çœ‹PPO2ç®—æ³•ã€‚å…¶ç›®æ ‡å‡½æ•°ä¸­çš„clipï¼Œå³
$$
clip\left(\frac{p_{\theta}(a_t|s_t)}{p_{\theta^k}(a_t|s_t)},1-\epsilon,1+\epsilon\right)
$$
å…¶å›¾åƒæ˜¯

![ppo2-clip](pic/ppo2-clip.png)

 ç°åœ¨è€ƒè™‘åˆ°Açš„æ­£è´Ÿæ€§ï¼Œåˆ™æœ‰å¦‚ä¸‹å›¾æ‰€ç¤º

![ppo2-clip-adv](pic/ppo2-clip-adv.png)

é‚£æ˜¯å¦‚ä½•åšåˆ°ä¸è¦è®©ä¸¤ä¸ªçš„æ¦‚ç‡å·®è·å¤ªå¤§çš„å‘¢ï¼Ÿ

å½“$A>0$æ—¶ï¼Œæ˜¯æƒ³å¢åŠ $p_{\theta}$çš„å‡ ç‡çš„ï¼Œä½†æ˜¯å½“å…¶ä¸æ—§çš„$p_{\theta}$çš„æ¯”å€¼è¶…è¿‡$1+\epsilon$æ—¶ï¼Œå°±ä¸¢å¼ƒæ‰è¿™ä¸ªæ ·æœ¬ã€‚å½“æ¯”å€¼å°äº$1+\epsilon$æ—¶ï¼Œä¸è®¾ä¸‹é™ï¼ˆå› ä¸ºminæ“ä½œä¼šå–å‰é¢çš„æ›´å°å€¼ï¼‰ï¼Œå…¨éƒ¨éƒ½æ¥å—ï¼Œæ¥æå‡$p_{\theta}(a_t|s_t)$å‡ºç°çš„æ¦‚ç‡ã€‚

å½“$A<0$æ—¶ï¼Œæ˜¯æƒ³å‡å°$p_{\theta}$çš„å‡ ç‡çš„ï¼Œä½†æ˜¯å½“å…¶ä¸æ—§çš„$p_{\theta}$çš„æ¯”å€¼å°äº$1-\epsilon$æ—¶ï¼Œå°±ä¸¢å¼ƒæ‰è¿™ä¸ªæ ·æœ¬ã€‚å½“æ¯”å€¼å¤§äº$1-\epsilon$æ—¶ï¼Œä¸è®¾ä¸Šé™ï¼Œå…¨éƒ¨éƒ½æ¥å—ï¼Œæ¥å‡å°$p_{\theta}(a_t|s_t)$å‡ºç°çš„æ¦‚ç‡ã€‚

å¯¹è¿™é‡Œçš„è¿›ä¸€æ­¥è®¤çŸ¥ï¼š

> é’ˆå¯¹A>0ï¼š
>
> è¶…è¿‡ 1+Ïµ â†’ é˜²æ­¢æŸä¸ªåŠ¨ä½œè¢«è¿‡åº¦å¼ºåŒ–ã€‚
>
> æ­¤æ—¶å½“è¯¥åŠ¨ä½œçš„æ¦‚ç‡è¿‡å°ï¼Œé‚£å°±åˆ«æˆªæ–­å®ƒï¼Œå› ä¸ºå®ƒæ¦‚ç‡å¤ªå°ï¼Œéœ€è¦è¢«å¼ºåŒ–ï¼Œå¼ºåŒ–çš„åŸå› æ˜¯A>0ï¼Œæ¢¯åº¦å¯ä»¥å¼º
>
> é’ˆå¯¹A<0ï¼š
>
> æ¦‚ç‡ ä½äº 1âˆ’Ïµ â†’ é˜²æ­¢æŸä¸ªåŠ¨ä½œè¢«è¿‡åº¦æŠ‘åˆ¶ã€‚
>
> æ­¤æ—¶å½“è¯¥åŠ¨ä½œçš„æ¦‚ç‡è¿‡å¤§ï¼Œé‚£å°±åˆ«æˆªæ–­å®ƒï¼Œå› ä¸ºå®ƒæ¦‚ç‡å¤ªå¤§ï¼Œéœ€è¦å‰Šå¼±ï¼Œå‰Šå¼±çš„åŸå› æ˜¯A<0ï¼Œæ¢¯åº¦å¯ä»¥å‰Šå¼±æ¦‚ç‡

å®Œå…¨å¯ä»¥è¿™ä¹ˆç†è§£ï¼Œè€Œä¸”ä½ çš„è¡¨è¿°éå¸¸ç²¾å‡†ã€‚æˆ‘ä»¬å¯ä»¥æŠŠå®ƒç¨å¾®æ•´ç†ä¸€ä¸‹ï¼š

1ï¸âƒ£ å½“ $A>0$ï¼ˆä¼˜åŠ¿ä¸ºæ­£ï¼Œæƒ³å¢å¼ºåŠ¨ä½œï¼‰

- **ä¸Šé™ $1+\epsilon$**ï¼šå¦‚æœ ratio $r_t = p_\theta/p_{\theta^k}$ è¶…è¿‡ $1+\epsilon$ï¼Œå°±è£å‰ªæ¢¯åº¦ï¼Œé˜²æ­¢è¿™ä¸ªåŠ¨ä½œè¢«å¼ºåŒ–å¾—å¤ªè¿‡ã€‚
- **ä¸‹é™ï¼ˆratio å¾ˆå°ï¼‰**ï¼šå¦‚æœ ratio å¾ˆå°ï¼Œæ¯”å¦‚åŠ¨ä½œæ¦‚ç‡éå¸¸ä½ï¼Œé‚£**ä¸è¦è£å‰ª**ï¼Œå…è®¸æ¢¯åº¦è‡ªç”±å¢åŠ æ¦‚ç‡ï¼Œå› ä¸ºè¿™æ˜¯æ­£ä¼˜åŠ¿ï¼Œæˆ‘ä»¬å¸Œæœ›å¼ºåŒ–å®ƒã€‚

> æ€»ç»“ï¼š**ä¸Šé™æ˜¯è£å‰ªï¼Œé˜²æ­¢è¿‡åº¦å¼ºåŒ–ï¼›ä¸‹é™ä¸è£å‰ªï¼Œå…è®¸è‡ªç„¶å¼ºåŒ–ã€‚**

2ï¸âƒ£ å½“ $A<0$ï¼ˆä¼˜åŠ¿ä¸ºè´Ÿï¼Œæƒ³å‡å¼±åŠ¨ä½œï¼‰

- **ä¸‹é™ $1-\epsilon$**ï¼šå¦‚æœ ratio $r_t$ ä½äº $1-\epsilon$ï¼Œè£å‰ªæ¢¯åº¦ï¼Œé˜²æ­¢åŠ¨ä½œè¢«æŠ‘åˆ¶å¾—å¤ªè¿‡ã€‚
- **ä¸Šé™ï¼ˆratio å¾ˆå¤§ï¼‰**ï¼šå¦‚æœ ratio å¾ˆå¤§ï¼ŒåŠ¨ä½œæ¦‚ç‡å¾ˆé«˜ï¼Œé‚£**ä¸è¦è£å‰ª**ï¼Œå…è®¸æ¢¯åº¦è‡ªç”±é™ä½æ¦‚ç‡ï¼Œå› ä¸ºè¿™æ˜¯è´Ÿä¼˜åŠ¿ï¼Œæˆ‘ä»¬å¸Œæœ›å‰Šå¼±å®ƒã€‚

> æ€»ç»“ï¼š**ä¸‹é™æ˜¯è£å‰ªï¼Œé˜²æ­¢è¿‡åº¦æŠ‘åˆ¶ï¼›ä¸Šé™ä¸è£å‰ªï¼Œå…è®¸è‡ªç„¶å‰Šå¼±ã€‚**

ğŸ”‘ æ ¸å¿ƒç†è§£

- **è£å‰ªåªåœ¨â€œè¿‡åº¦æ›´æ–°â€æ—¶ç”Ÿæ•ˆ**ï¼ˆé˜²æ­¢æ¢¯åº¦è¿‡å¤§å¯¼è‡´ç­–ç•¥ä¸ç¨³å®šï¼‰
- **è¾¹ç•Œå†…è‡ªç”±æ›´æ–°**ï¼Œè®©ä¼˜åŠ¿ç¬¦å·ç›´æ¥å†³å®šåŠ¨ä½œå¼ºåŒ–æˆ–å‰Šå¼±
- è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ•™æé‡Œè¯´â€œæ¯”å€¼å°äº $1+\epsilon$ æˆ–å¤§äº $1-\epsilon$ æ—¶ä¸è®¾é™åˆ¶ï¼Œå…¨éƒ¨æ¥å—â€

> ä½†æ˜¯è¿™è¿èƒŒäº†é‡è¦æ€§é‡‡æ ·ä¸­çš„æ¦‚ç‡på’Œqä¸èƒ½å·®è·å¤ªå¤§å•Šã€‚ã€‚æ‰€ä»¥è¿™é‡Œçš„å†³ç­–åº”è¯¥æ˜¯ç»¼åˆäº†på’Œqä¸èƒ½ç›¸å·®å¤ªå¤§ï¼ŒåŒæ—¶è€ƒè™‘å®é™…æƒ…å†µï¼Œé€‚å½“åŠ å¼ºå¥½çš„åŠ¨ä½œä½æ¦‚ç‡æ—¶å¢å¤§æ¦‚ç‡ï¼Œé€‚å½“åŠ å¼ºåçš„åŠ¨ä½œé«˜æ¦‚ç‡æ—¶å‡å°æ¦‚ç‡ã€‚æ˜¯è¿™ä¸¤ç‚¹çš„ç»¼åˆå—ï¼Ÿ

å®Œå…¨å¯¹ï¼Œä½ æŠ“ä½æ ¸å¿ƒäº†ã€‚è¿™å°±æ˜¯ PPO çš„ç²¾å¦™ä¹‹å¤„ï¼š**å®ƒåœ¨ä¿æŒé‡è¦æ€§é‡‡æ ·ç†è®ºå®‰å…¨æ€§çš„åŒæ—¶ï¼Œè¿˜å…è®¸ç­–ç•¥æ ¹æ®ä¼˜åŠ¿ä¿¡å·åšåˆç†çš„å¼ºåŒ–æˆ–å‰Šå¼±**ã€‚æˆ‘ä»¬å¯ä»¥æ‹†å¼€æ¥çœ‹ï¼š

1ï¸âƒ£ é‡è¦æ€§é‡‡æ ·çº¦æŸï¼ˆp/q ä¸èƒ½å·®è·å¤ªå¤§ï¼‰

- åœ¨åŸå§‹ TRPO ä¸­ï¼Œæœ‰ä¸¥æ ¼çš„ KL çº¦æŸï¼šç­–ç•¥æ›´æ–°åï¼Œæ–°çš„ç­–ç•¥ $\pi_\theta$ å’Œæ—§ç­–ç•¥ $\pi_{\theta^k}$ çš„åˆ†å¸ƒä¸èƒ½åç¦»å¤ªå¤šï¼Œå¦åˆ™ importance sampling ä¼šå‡ºç°é«˜æ–¹å·®ã€‚
- è¿™é‡Œ PPO çš„ clip ä¸Šä¸‹é™ $(1+\epsilon, 1-\epsilon)$ å°±æ˜¯**ä¸€ç§è½¯åŒ–çš„ KL çº¦æŸ**ï¼Œä¿è¯ $\frac{p_\theta}{p_{\theta^k}}$ ä¸ä¼šåç¦»å¤ªè¿œï¼Œé¿å…æŸäº›åŠ¨ä½œè¢«å¼ºåŒ–æˆ–æŠ‘åˆ¶å¾—è¿‡åº¦ï¼Œä»è€Œç ´åé‡‡æ ·çš„æ— åæ€§ã€‚

2ï¸âƒ£ ä¼˜åŠ¿ä¿¡å·çš„å¼ºåŒ–/å‰Šå¼±ï¼ˆ$A>0$ / $A<0$ï¼‰

- å½“åŠ¨ä½œä¼˜åŠ¿ä¸ºæ­£ï¼ˆ$A>0$ï¼‰æ—¶ï¼Œä½æ¦‚ç‡åŠ¨ä½œåº”è¯¥å¢åŠ æ¦‚ç‡ï¼›å½“åŠ¨ä½œä¼˜åŠ¿ä¸ºè´Ÿï¼ˆ$A<0$ï¼‰æ—¶ï¼Œé«˜æ¦‚ç‡åŠ¨ä½œåº”è¯¥å‡å°‘æ¦‚ç‡ã€‚
- **è¾¹ç•Œå†…ä¸è£å‰ª**ï¼šè®©æ¢¯åº¦è‡ªç”±åœ°æ ¹æ®ä¼˜åŠ¿ä¿¡å·è°ƒæ•´æ¦‚ç‡ï¼Œè¿™æ˜¯ç­–ç•¥æ”¹è¿›çš„å…³é”®ã€‚
- **è¶…è¿‡è¾¹ç•Œè£å‰ª**ï¼šé˜²æ­¢æ¦‚ç‡å˜åŒ–è¿‡å¤§ï¼Œä¿è¯ç­–ç•¥æ›´æ–°ç¨³å®šï¼Œé˜²æ­¢ high-variance æˆ–è®­ç»ƒå´©æºƒã€‚

ğŸ”‘ ç»¼åˆç†è§£

æ‰€ä»¥ PPO clip ç­–ç•¥å°±æ˜¯åœ¨åšä¸¤ä»¶äº‹çš„å¹³è¡¡ï¼š

1. **æ§åˆ¶æ¦‚ç‡æ¯”å€¼**ï¼ˆp/qï¼‰ä¸è¿‡å¤§è¿‡å°ï¼Œä¿è¯é‡è¦æ€§é‡‡æ ·ç¨³å®šã€‚
2. **åˆ©ç”¨ä¼˜åŠ¿ä¿¡å·è°ƒæ•´åŠ¨ä½œæ¦‚ç‡**ï¼Œè®©æ­£ä¼˜åŠ¿åŠ¨ä½œæ¦‚ç‡å¢åŠ ï¼Œè´Ÿä¼˜åŠ¿åŠ¨ä½œæ¦‚ç‡å‡å°‘ã€‚

> è¿™å°±æ˜¯ä½ è¯´çš„â€œç»¼åˆäº† p/q ä¸ç›¸å·®å¤ªå¤§ï¼ŒåŒæ—¶è€ƒè™‘å®é™…æƒ…å†µï¼Œé€‚å½“åŠ å¼ºå¥½çš„åŠ¨ä½œä½æ¦‚ç‡æ—¶å¢å¤§æ¦‚ç‡ï¼Œé€‚å½“åŠ å¼ºåçš„åŠ¨ä½œé«˜æ¦‚ç‡æ—¶å‡å°æ¦‚ç‡â€ã€‚PPO çš„æ•´ä¸ªè®¾è®¡å“²å­¦å°±åœ¨è¿™é‡Œã€‚

æ¢å¥è¯è¯´ï¼š

**A > 0ï¼ˆæ­£ä¼˜åŠ¿ï¼‰**ï¼š

- æˆ‘ä»¬å¸Œæœ›å¢åŠ åŠ¨ä½œçš„æ¦‚ç‡ pÎ¸(aâˆ£s)p_\theta(a|s)pÎ¸(aâˆ£s)ã€‚
- åªè¦æ¯”å€¼ r<1+Ïµr < 1+\epsilonr<1+Ïµï¼Œæ¢¯åº¦è‡ªç”±ä¸Šå‡ï¼Œè®©ä½æ¦‚ç‡çš„å¥½åŠ¨ä½œå¾—åˆ°å¼ºåŒ–ã€‚
- å¦‚æœ r>1+Ïµr > 1+\epsilonr>1+Ïµï¼Œclip é™åˆ¶ï¼Œé˜²æ­¢åŠ¨ä½œè¢«è¿‡åº¦å¼ºåŒ–ï¼ˆé˜²æ­¢é‡è¦æ€§é‡‡æ ·åå·®å¤ªå¤§ï¼‰ã€‚

**A < 0ï¼ˆè´Ÿä¼˜åŠ¿ï¼‰**ï¼š

- æˆ‘ä»¬å¸Œæœ›é™ä½åŠ¨ä½œçš„æ¦‚ç‡ pÎ¸(aâˆ£s)p_\theta(a|s)pÎ¸(aâˆ£s)ã€‚
- åªè¦æ¯”å€¼ r>1âˆ’Ïµr > 1-\epsilonr>1âˆ’Ïµï¼Œæ¢¯åº¦è‡ªç”±ä¸‹é™ï¼Œè®©é«˜æ¦‚ç‡çš„ååŠ¨ä½œè¢«å‰Šå¼±ã€‚
- å¦‚æœ r<1âˆ’Ïµr < 1-\epsilonr<1âˆ’Ïµï¼Œclip é™åˆ¶ï¼Œé˜²æ­¢åŠ¨ä½œè¢«è¿‡åº¦æŠ‘åˆ¶ã€‚

**å…³é”®é€»è¾‘**ï¼š

- ä¸Šç•Œå’Œä¸‹ç•Œæ˜¯ä¸ºäº† **å®‰å…¨æ›´æ–°**ï¼ˆä¸è®© p/q åç¦»å¤ªå¤šï¼‰ã€‚
- çº¿æ€§åŒºåŸŸæ˜¯ä¸ºäº† **æ ¹æ®ä¼˜åŠ¿ä¿¡å·è‡ªç”±è°ƒæ•´åŠ¨ä½œæ¦‚ç‡**ï¼ˆå¢å¤§æ­£ A åŠ¨ä½œï¼Œå‡å°è´Ÿ A åŠ¨ä½œï¼‰ã€‚

# Actor&Criticç½‘ç»œæ¶æ„

## Actorç½‘ç»œ

### å¤šå¤´æ¶æ„

å¤šå¤´åŠ¨ä½œPPOï¼š[henrycharlesworth/multi_action_head_PPO](https://github.com/henrycharlesworth/multi_action_head_PPO)

### è¿ç»­è¾“å‡ºå€¼çš„æ–¹å·®çš„é€‰æ‹©

PPOè¿ç»­åŠ¨ä½œçš„sigmaï¼Œå…¶å®åœ¨ä¸åŒç‰ˆæœ¬çš„å®ç°é‡Œä¸€å…±æœ‰ä¸‰ç§
- fixedï¼šå›ºå®š sigmaï¼Œå¸¸ç”¨äºä¸€äº›ç‰¹æ®Šæ§åˆ¶ä»»åŠ¡ï¼Œå¦‚æœå¯¹ç¯å¢ƒçš„ sigma æœ‰è¶³å¤Ÿçš„å…ˆéªŒçŸ¥è¯†å¯ä»¥è¿™æ ·åš
- independentï¼šå³ä¸ºä¸€ä¸ªå¯ä¼˜åŒ–çš„ç½‘ç»œå‚æ•°ï¼Œä½†æ˜¯å’Œstateæ— å…³ï¼Œæ˜¯ä¸€ä¸ªç‹¬ç«‹å‚æ•°ã€‚è¿™æ˜¯ä¸€èˆ¬ PPOå¸¸ç”¨çš„æƒ…å½¢
- state conditionedï¼šç”± state è¾“å…¥é€šè¿‡ä¸€å®šçš„ç½‘ç»œå±‚ç”Ÿæˆï¼Œè¿™ç§æƒ…å†µåœ¨ SAC ä¸­å¸¸ç”¨ï¼ŒPPOä¸­è¾ƒå°‘è§ã€‚ä¸è¿‡æœ‰ paper åœ¨mujocoç¯å¢ƒä¸Šåšè¿‡å¯¹æ¯”å®éªŒï¼Œè‡³å°‘åœ¨è¿™ä¸ªæ§åˆ¶ç¯å¢ƒä¸Šå·®åˆ«ä¸å¤§

ä¸‰ç§ç±»å‹çš„ä»£ç å¯¹æ¯”å¯ä»¥å‚è€ƒæˆ‘ä»¬è¿™é‡Œçš„ä»£ç  https://github.com/opendilab/DI-engine/blob/main/ding/model/common/head.py#L965

ä¸­æ–‡ç‰ˆçš„æ³¨é‡Šè¯¦è§£å¯ä»¥çœ‹è¿™ä¸ª https://opendilab.github.io/PPOxFamily/continuous_zh.html

**OpenAIçš„é€‰æ‹©**

[OpenAI Spinning Up Part 1: Key Concepts in RL](https://spinningup.openai.com/en/latest/spinningup/rl_intro.html#id2)

> A diagonal Gaussian policy always has a neural network that maps from observations to mean actions,$\mu_{\theta}(s)$. There are two different ways that the covariance matrix is typically represented.
>
> **The first way:** There is a single vector of log standard deviations,$log \sigma$, which is **not** a function of state: the $log \sigma$ are standalone parameters. (You Should Know: our implementations of VPG, TRPO, and PPOdo it this way.)
>
> **The second way:** There is a neural network that maps from states to log standard deviations,$log \sigma_{\theta}(s)$. It may optionally share some layers with the mean network.

#### å…³äºæ–¹å·®çš„å‚è€ƒä»£ç 

åˆšå»openailabä»“åº“ä¸Šç¿»äº†ç¿» https://github.com/opendilab/DI-engine/blob/0a25e46e29638a4be04654c7fd132ebdff4a556a/ding/model/common/head.py#L965
ä»–ä»¬è¿™é‡Œè¿ç»­åŠ¨ä½œç”¨çš„ReparameterizationHeadå°±æœ‰

å¯ä»¥çœ‹openailabçš„ä»£ç   å†™çš„æŒºå¥½çš„ å›ºå®šï¼Œç‹¬ç«‹å‚æ•°ï¼Œæ¨¡å‹æ¨ç†ä¸‰ç§æ–¹æ³•éƒ½å¯ä»¥é€‰æ‹©  è«çƒ¦çš„æ²¡æœ‰è®²çš„å¾ˆå…¨é¢ï¼Œæ„Ÿè§‰æ¯”è¾ƒé€‚åˆå…¥é—¨ã€‚

å¯¹äºç‹¬ç«‹å€¼ï¼šæˆ‘æ˜¯è¿™ä¹ˆç†è§£çš„ï¼Œå½“é€‰æ‹©çš„åŠ¨ä½œåœ¨è¿™ä¸ªåˆ†å¸ƒä¸Šçš„å›æŠ¥é«˜äºæœŸæœ›ï¼Œé‚£å°±å¢å¤§è¿™ä¸ªåŠ¨ä½œçš„é€‰æ‹©æ¦‚ç‡ï¼Œå¯¹åº”çš„å‡å€¼å‘è¿™ä¸ªåŠ¨ä½œç§»åŠ¨ï¼Œæ–¹å·®é™ä½ã€‚å¦‚æœä½äºæœŸæœ›ï¼Œé‚£æ–¹å·®å°±è°ƒå¤§ï¼Œå¢åŠ é€‰æ‹©å…¶ä»–åŠ¨ä½œçš„æ¦‚ç‡ã€‚

ä¸€èˆ¬é€‰ç‹¬ç«‹å‚æ•°ï¼Œæ¯”è¾ƒå¥½è®­ç»ƒ

å…¶ä»–çš„å‚è€ƒä»£ç ï¼š

independent:

https://github.com/tensorlayer/tensorlayer/blob/master/examples/reinforcement_learning/tutorial_DPPO.py

å›ºå®šå€¼/çº¿æ€§è¡°å‡ï¼š

https://github.com/nikhilbarhate99/PPO-PyTorch/blob/master/train.py

åŸºäºstateè®­ç»ƒï¼š

è«å‡¡pythonï¼š

https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/12_Proximal_Policy_Optimization/DPPO.py

å…¶ä»–ï¼š

æˆ‘çš„PPOç”¨çš„æ˜¯ä¹‹å‰å°åŠ©æ‰‹åˆ†äº«çš„ï¼Œ37ä¸ªPPOå®æ–½ç»†èŠ‚é‡Œçš„ä»£ç ï¼Œä½ è¯´çš„adv_normï¼Œmax_grad_normä¹Ÿæ˜¯åœ¨é…ç½®é‡Œçš„

https://github.com/vwxyzjn/ppo-implementation-details

https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/



æ­£æ€åˆ†å¸ƒï¼š
$$
f(x)=\frac{1}{\sqrt{2\pi}\sigma}\text{exp}\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
$$
![normal-dist](pic/normal-dist.png)

ä»£ç (å‚è€ƒèµ„æ–™ï¼š[Pythonç»˜åˆ¶é«˜æ–¯åˆ†å¸ƒï¼ˆæ­£æ€åˆ†å¸ƒï¼‰å›¾åƒ](https://blog.csdn.net/qq_44444503/article/details/124377863))ï¼š

```python
import numpy as np
import math
import matplotlib.pyplot as plt


def gd(x, mu=0., sigma=1.):
    # sigmaæ˜¯æ ‡å‡†å·®
    left = 1 / (np.sqrt(2 * math.pi) * sigma)
    right = np.exp(-(x - mu) ** 2 / (2 * np.square(sigma)))
    return left * right


if __name__ == '__main__':
    # è‡ªå˜é‡
    x = np.arange(-5, 5, 0.05)
    # å› å˜é‡ï¼ˆä¸åŒå‡å€¼æˆ–æ–¹å·®ï¼‰
    y_1 = gd(x, 0, 0.01)
    y_2 = gd(x, 0, 0.1)
    y_3 = gd(x, 0, 0.5)
    y_4 = gd(x, 0, 1.0)
    y_5 = gd(x, 0, 2.0)

    # ç»˜å›¾
    plt.plot(x, y_1, color='green')
    plt.plot(x, y_2, color='blue')
    plt.plot(x, y_3, color='thistle')
    plt.plot(x, y_4, color='red')
    plt.plot(x, y_5, color='fuchsia')
    # è®¾ç½®åæ ‡ç³»
    plt.xlim(-5.0, 5.0)
    plt.ylim(-0.2, 2)

    ax = plt.gca()
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')
    ax.xaxis.set_ticks_position('bottom')
    ax.spines['bottom'].set_position(('data', 0))
    ax.yaxis.set_ticks_position('left')
    ax.spines['left'].set_position(('data', 0))

    plt.legend(labels=[
        '$\mu = 0, \sigma=0.01$',
        '$\mu = 0, \sigma=0.1$',
        '$\mu = 0, \sigma=0.5$',
        '$\mu = 0, \sigma=1.0$',
        '$\mu = 0, \sigma=2.0$'])
    plt.show()
```

### è¿ç»­å€¼actionè®­ç»ƒæ—¶è¦ä¸è¦clip

è¯·é—®ppoçš„åŠ¨ä½œaï¼Œæ”¶é›†å¥½å‘å›ç»™æ¨¡å‹è¿›è¡Œè®­ç»ƒæ—¶ï¼Œè¿™ä¸ªåŠ¨ä½œaåº”è¯¥å»æ‰clipé™å¹…ï¼Œè¿˜æ˜¯è¦ä¿ç•™clipé™å¹…ï¼Ÿ
p.s.è¿™ä¸ªåŠ¨ä½œaè¾“ç»™env.step(a)æ—¶è‚¯å®šæ˜¯è¦åšé™å¹…çš„ï¼Œè¿™ä¸ªæ²¡å•¥è¯´çš„ã€‚

è®­ç»ƒæ—¶ï¼Œä¸è¦clipï¼Œclipåªæ”¾åœ¨ç¯å¢ƒé‡Œé¢åšã€‚å¦åˆ™ä½ è®¡ç®—æ—¶çš„log probå¾ˆå®¹æ˜“è¿‡å¤§æˆ–è¿‡å°ã€‚è®­ç»ƒæ—¶å°±ç”¨æœ€åŸå§‹çš„ä»æ¦‚ç‡åˆ†å¸ƒé‡Œé‡‡æ ·å‡ºæ¥çš„action

## Criticç½‘ç»œè®¾è®¡



è¿™æ˜¯æœ€æ–°çš„è®¨è®ºï¼š

https://chatgpt.com/c/695dd529-5564-8327-8d25-60688797c6aa

è¿™æ˜¯ä¹‹å‰çš„è®¨è®ºï¼Œå› ä¸ºå‘äº†ä¸€å¼ å›¾ç‰‡ï¼Œæ‰€ä»¥å°±ä¸åœ¨è¿™é‡Œè®¨è®ºäº†ï¼Œè¿ç§»åˆ°ä¸Šé¢çš„è®¨è®ºé‡Œäº†

https://chatgpt.com/c/695dd01d-a1ac-8329-ab96-54bcde3fd63c

è¿™æ˜¯æœ€å¼€å§‹çš„è®¨è®ºï¼Œä»…åœ¨æœ€åé¢æœ‰ä¸€äº›ï¼š

https://chatgpt.com/c/694cf28f-51d4-8322-851c-33f0200fec0f

# æ©ç ï¼ˆmaskï¼‰æ˜¯åšä»€ä¹ˆç”¨çš„

æœ‰æ²¡æœ‰ä¸€äº›è¿™æ–¹é¢çš„å¼ºåŒ–å­¦ä¹ ç§‘æ™®èµ„æ–™ï¼Ÿ

Muskä¸»è¦æ˜¯é’ˆå¯¹ä¸€äº›åŠ¨ä½œå’Œå‚æ•°ä¹‹é—´çš„å…³ç³»ï¼Œé€šè¿‡æ©ç å¯ä»¥å»ºç«‹è¿™ç§å…³ç³»ï¼ŒåŠ é€Ÿæ”¶æ•›ã€‚

maskéƒ¨åˆ†ä¸€èˆ¬æœ‰ä¸¤ç±»
- ç¦»æ•£åŠ¨ä½œç©ºé—´çš„ maskï¼Œç”¨äºå»æ‰ä¸€äº›å½“å‰å¸§ä¸å¯é€‰çš„åŠ¨ä½œï¼Œå¯¹è®­ç»ƒä¼˜åŒ–æœ‰ä¸€å®šåŠ é€Ÿä½œç”¨ã€‚æˆ‘ä»¬è¿™æ¬¡ç¬¬äºŒèŠ‚è¯¾çš„ä½œä¸šé¢˜ä¼šæ¶‰åŠåˆ°ã€‚
- æ··åˆåŠ¨ä½œç©ºé—´çš„ maskï¼Œç”¨äºè¡¨è¾¾ä¸åŒ action éƒ¨åˆ†ä¹‹é—´çš„å…³ç³»ï¼Œä¾‹å¦‚æŸäº›åŠ¨ä½œç±»å‹å¯¹åº”ç‰¹å®šçš„åŠ¨ä½œå‚æ•°ï¼Œå¯ä»¥å‚è€ƒè¿™é‡Œçš„è®²è§£ä¾‹å­ï¼Œå°¤å…¶æ˜¯æœ€åçš„ mask ä½¿ç”¨éƒ¨åˆ† https://opendilab.github.io/PPOxFamily/hybrid_zh.html

# çŸ¥è¯†ç‚¹

## æŸå¤±å‡½æ•°

### Actorçš„æŸå¤±å‡½æ•°

#### ActoræŸå¤±é™å¹…clip

æ³¨æ„åœ¨è®­ç»ƒactorçš„æ—¶å€™å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿåœ¨ä½ è®­ç»ƒ PPO çš„æ—¶å€™ï¼Œæœ‰è¿™ä¹ˆä¸€è¡Œ lossï¼š

```python
actor_loss = -Ï€_new(a_t | s_t) * advantage_t   # clipped PPO objective
```

è¿™é‡Œçš„ `advantage_t` æ˜¯ä» buffer æ‹¿å‡ºæ¥çš„ï¼Œä¹Ÿå°±æ˜¯$GAE(\pi_\text{old})$ã€‚

è€Œä½ è¿™æ—¶ç”¨çš„æ˜¯$\pi_\text{new}$çš„ actor æ¥æ›´æ–° policyï¼

äºæ˜¯å‡ºç°äº†è¿™æ ·çš„ä¸ä¸€è‡´ï¼š

| é¡¹ç›®      | æ¥è‡ªå“ªä¸ª policy    |
| --------- | ------------------ |
| Ï€_new(a)  | å½“å‰actor_new(s)   |
| advantage | rollout æ—¶çš„ Ï€_old |

ä¹Ÿå°±æ˜¯è¯´ï¼šä½ åœ¨ç”¨ **æ—§ç­–ç•¥ä¸‹çš„ advantageï¼ˆGAE ç»“æœï¼‰** å»è¯„ä¼° **å½“å‰ç­–ç•¥çš„åŠ¨ä½œå¥½ä¸å¥½**ã€‚è¿™åœ¨æ•°å­¦ä¸Šæ˜¯è¿‘ä¼¼çš„ï¼Œå‰ææ˜¯$\pi_\text{new}$æ²¡æœ‰å¤§å¹…åç¦»$\pi_\text{old}$ã€‚

å°±æ˜¯è¯´ï¼Œåªé é‡è¦æ€§é‡‡æ ·æ˜¯ä¸å¤Ÿçš„ï¼Œè¿™åªæ˜¯è§£å†³äº†æ•°æ®åˆ†å¸ƒçš„é—®é¢˜ï¼Œä½†æ˜¯ä½ advantageæœ¬èº«å·²ç»ä¸ç¬¦åˆæ–°çš„actoræ¨¡å‹äº†ã€‚

æ‰€ä»¥ PPO æ‰å¼•å…¥äº† policy clippingï¼ˆé™åˆ¶$\pi_\text{new}/\pi_\text{old}$ä¸è¦å¤ªç¦»è°±ï¼‰ï¼Œæ˜¯ä¸ºäº†è¿™ä¸ª mismatch ä¸è‡³äºå¤ªä¸¥é‡ï¼

#### adv-norm

adv norméœ€è¦è€ƒè™‘rewardçš„æ•°å€¼èŒƒå›´ï¼Œå¦‚æœç»å¯¹å€¼åœ¨0-100ä¹‹å†…å…¶å®å½±å“ä¸å¤§ï¼Œå¦‚æœç»å¯¹å€¼å¤§äºè¿™ä¸ªèŒƒå›´ï¼Œä¸”rewardæ³¢åŠ¨çš„ç¡®å®å¾ˆæ˜æ˜¾ï¼ˆæ³¨æ„è¦å’Œç¨€ç–rewardåŒºåˆ†ï¼‰ï¼Œé‚£é€‚åˆç”¨adv norm

ç„¶åè¿™ç§æ¯”è¾ƒç›´æ¥çš„adv normï¼Œåº”è¯¥batchè¶Šå¤§ç»Ÿè®¡é‡è¶Šå‡†ï¼Œæ‰€ä»¥åœ¨å®ç°ä¸­ï¼Œåƒdppoçš„è¯ï¼Œåº”è¯¥æ˜¯è®­ç»ƒçš„å¤šå¡ä¹‹é—´allreduceåŒæ­¥meanå’Œstdï¼Œç„¶åå†norm

å‡ºç°nanæœ‰å¾ˆå¤šç§åŸå› ï¼Œå…¶ä¸­ä¹‹ä¸€å°±æ˜¯adv norm

å¦‚æœæ•°æ®å¤šæ ·æ€§å¾ˆå·®ï¼Œä¸€ä¸ªbatché‡Œå¤ªç›¸è¿‘ï¼Œé‚£ä¹ˆç®—å‡ºæ¥çš„stdå°±å¾ˆæ¥è¿‘äº0ï¼Œè¿™æ ·normä¸€é™¤å°±ç‚¸äº†

meanå’Œstdè®¡ç®—ç”¨çš„æ ·æœ¬è‚¯å®šæ˜¯è¶Šå¤šè¶Šå‡†ï¼Œä½†å› ä¸ºrlæœ¬èº«æ•°æ®åˆ†å¸ƒå°±ä¸€ç›´åœ¨å˜ï¼Œæ‰€ä»¥å¯èƒ½æœ‰äº›åœºæ™¯é‡Œå¯¹æœ€ç»ˆæ€§èƒ½å½±å“ä¸å¤§ï¼Œå°±è·Ÿä½ çš„å®éªŒç»“æœä¸€æ ·ã€‚

ä½ è¦æƒ³çœŸæ­£æ·±ç©¶è¿™ä¸ªé—®é¢˜ï¼Œåº”è¯¥è¦å»å¯è§†åŒ–è¿™ä¸¤ç§è®¾å®šä¸‹ç®—å‡ºæ¥çš„meanå’Œstdçš„å˜åŒ–æƒ…å†µï¼Œå†åˆ†æè¿™ä¸ªå˜åŒ–å¯¹äºæ™ºèƒ½ä½“æ€§èƒ½çš„å½±å“ï¼Œå¹¶åœ¨ä¸åŒç±»å‹çš„ç¯å¢ƒä¸Šåšå¯¹æ¯”çœ‹èƒ½ä¸èƒ½æ‰¾åˆ°æ™®é€‚ç»“è®º

å†³ç­–é—®é¢˜(ç¯å¢ƒ)ä¹‹é—´çš„å·®å¼‚æ€§å¤ªå¤§äº†ï¼Œæ‰€ä»¥ç»éªŒæ€§ç»“è®ºç»å¸¸å˜åŒ–ï¼Œä½†æ˜¯åˆ†ææ–¹æ³•å’Œæ‰‹æ®µæŒæ¡äº†ä¹‹åï¼Œå…·ä½“é—®é¢˜å…·ä½“åˆ†æå°±å¥½ï¼Œæ²¡æœ‰ä»€ä¹ˆç„å­¦çš„

baselineè¿™ä¸ªåœ°æ–¹åªæ˜¯è¯´å‡å»ä¸€é¡¹è¿˜æ˜¯æ— åä¼°è®¡ï¼Œå¹¶æ²¡æœ‰è¯´é™¤ä¸Šè¿™æ ·ä¸€ä¸ªåŠ¨æ€å˜åŒ–çš„stdè¿˜æ˜¯æ— åä¼°è®¡

å¦‚æœç¼©æ”¾çš„å› å­æ˜¯æ•´ä¸ªè®­ç»ƒæœŸé—´éƒ½ç”¨ä¸€ä¸ªå›ºå®šå€¼ï¼Œé‚£æ²¡é—®é¢˜ï¼Œå…³é”®å°±æ˜¯æˆ‘ä»¬åšadv normæ˜¯ç”¨åŠ¨æ€ç»Ÿè®¡é‡ï¼Œè¿™ä¸ªå°±è¿›å…¥åˆ°å¾ˆéº»çƒ¦çš„é¢†åŸŸäº†

#### ç†µæ­£åˆ™åŒ–

ç†µæ­£åˆ™åŒ–ç³»æ•°è°ƒå‚æŠ€å·§

- **è®­ç»ƒåˆæœŸ**ï¼šå¢å¤§ç†µç³»æ•°ï¼ˆå¦‚ 0.05ï¼‰ï¼Œé¼“åŠ±æ¢ç´¢ã€‚
- **è®­ç»ƒåæœŸ**ï¼šå‡å°ç³»æ•°ï¼ˆå¦‚ 0.001ï¼‰ï¼Œä¿ƒè¿›ç­–ç•¥æ”¶æ•›ã€‚

è¿™é‡Œæœ‰ä¸ªæ²¡äººæ³¨æ„ä½†æ˜¯éå¸¸é‡è¦çš„ç‚¹ï¼Œå®é™…è®¡ç®—è¿ç»­åŠ¨ä½œçš„ç†µçš„æ—¶å€™ï¼Œæ˜¯

```python
entropy = new_dist.entropy().sum(-1).mean()
```

ä¸ºä»€ä¹ˆ RL é‡Œè¦ sum(-1).mean()è€Œä¸æ˜¯ç›´æ¥mean()ï¼Ÿ

- PPO/SAC ç­‰ç®—æ³•çš„ç†µæ­£åˆ™é¡¹ï¼Œç†è®ºä¸Šæ˜¯è”åˆåˆ†å¸ƒçš„ç†µï¼Œè€Œä¸æ˜¯æ¯ä¸ªç»´åº¦çš„å¹³å‡ç†µã€‚

- å¦‚æœç›´æ¥ meanï¼Œç†µå¥–åŠ±ä¼šå˜å°ï¼Œå½±å“æ¢ç´¢ã€‚

ç»“è®ºï¼šå¤šç»´åŠ¨ä½œæ—¶ï¼Œsum(-1).mean() å’Œ mean() ç»“æœå®Œå…¨ä¸åŒï¼Œåªæœ‰ä¸€ç»´åŠ¨ä½œæ—¶æ‰ä¸€æ ·ã€‚

ä½ å¯èƒ½å¾ˆç–‘æƒ‘ï¼Œåˆ†ç±»åŠ å’Œå†æ±‚å¹³å‡ä¸æ˜¯å’Œç›´æ¥æ±‚å¹³å‡ï¼Œåœ¨æ•°å­¦ä¸Šç­‰ä»·å—ï¼Ÿä¸ä¸ä¸ï¼Œå…¶å®ä¸ä¸€æ ·çš„ï¼Œæ¯”å¦‚ï¼š

### è¯¦ç»†ä¸¾ä¾‹

å‡è®¾ä½ çš„åŠ¨ä½œæ˜¯ 3 ç»´ï¼ˆæ¯”å¦‚[a1,a2,a3]ï¼‰ï¼Œbatch size = 2ï¼ŒT = 1ï¼ˆä¸ºç®€å•èµ·è§ï¼‰ã€‚

entropy() è¾“å‡º shape: [T, B, act_dim]ï¼Œå³ [1, 2, 3]ï¼Œæ¯”å¦‚ï¼š

```python
entropy = torch.tensor([
    [  # T=1
        [0.5, 0.6, 0.7],  # batch 1
        [0.4, 0.3, 0.2],  # batch 2
    ]
])
```

1. ç›´æ¥ mean

```python
entropy.mean()
```

è®¡ç®—æ‰€æœ‰å…ƒç´ çš„å¹³å‡å€¼ï¼š
$$
(0.5 + 0.6 + 0.7 + 0.4 + 0.3 + 0.2) / 6 = 2.7 / 6 = 0.45
$$

2. sum(-1).mean()

```python
entropy.sum(-1).mean()
```

- å…ˆå¯¹æœ€åä¸€ç»´ï¼ˆåŠ¨ä½œç»´åº¦ï¼‰æ±‚å’Œï¼š
  - batch 1: 0.5 + 0.6 + 0.7 = 1.8
  - batch 2: 0.4 + 0.3 + 0.2 = 0.9

- å¾—åˆ° [1.8, 0.9]

- å†å¯¹ batch æ±‚å¹³å‡ï¼š(1.8 + 0.9) / 2 = 1.35

åŒºåˆ«æ€»ç»“

- ç›´æ¥ mean()ï¼šæ‰€æœ‰åŠ¨ä½œç»´åº¦ã€æ‰€æœ‰ batchã€æ‰€æœ‰æ—¶é—´æ­¥çš„ç†µå€¼å¹³å‡ï¼Œç»“æœä¼šè¢«åŠ¨ä½œç»´åº¦æ•°æ‹‰ä½ã€‚

- sum(-1).mean()ï¼šæ¯ä¸ªæ ·æœ¬çš„â€œæ€»ç†µâ€å…ˆç®—å‡ºæ¥ï¼Œå†å¯¹æ‰€æœ‰æ ·æœ¬å¹³å‡ï¼Œåæ˜ äº†â€œæ¯ä¸ªæ ·æœ¬çš„è”åˆåŠ¨ä½œåˆ†å¸ƒçš„ç†µâ€çš„å¹³å‡ã€‚

### Criticçš„æŸå¤±å‡½æ•°

åœ¨PPOï¼ˆProximal Policy Optimizationï¼‰ç®—æ³•ä¸­ï¼ŒCriticï¼ˆä»·å€¼å‡½æ•°ï¼‰çš„æŸå¤±å‡½æ•°åŸºäº**ä»·å€¼å‡½æ•°ä¼°è®¡**ä¸**ç›®æ ‡å€¼**ä¹‹é—´çš„è¯¯å·®æ„å»ºã€‚Criticçš„æ ¸å¿ƒä»»åŠ¡æ˜¯å­¦ä¹ çŠ¶æ€ä»·å€¼å‡½æ•° V(s)*V*(*s*)ï¼Œç”¨äºè¯„ä¼°å½“å‰ç­–ç•¥ä¸‹çŠ¶æ€çš„å¥½åï¼Œä»è€ŒæŒ‡å¯¼Actorï¼ˆç­–ç•¥ï¼‰çš„æ›´æ–°ã€‚

#### CriticæŸå¤±å‡½æ•°çš„çœŸå®å€¼çš„ä¸¤ç§è®¡ç®—æ–¹å¼

Criticçš„â€œçœŸå®å€¼â€é€šå¸¸æŒ‡**æŠ˜æ‰£ç´¯ç§¯å›æŠ¥ï¼ˆReturnï¼‰æˆ–å¹¿ä¹‰ä¼˜åŠ¿ä¼°è®¡ï¼ˆGAE, Generalized Advantage Estimationï¼‰**ï¼Œå…·ä½“å–å†³äºè®¾è®¡ï¼š

1. **æŠ˜æ‰£ç´¯ç§¯å›æŠ¥ï¼ˆReturnï¼‰**ï¼š

   - å®šä¹‰ï¼šä»å½“å‰çŠ¶æ€$s^t$å¼€å§‹ï¼Œæœªæ¥æ‰€æœ‰å¥–åŠ±çš„æŠ˜æ‰£å’Œï¼š
     $$
     R_t=\sum_{k=0}^{T-t}\gamma^kr_{t+k}
     $$
     å…¶ä¸­$\gamma$æ˜¯æŠ˜æ‰£å› å­ï¼ˆå¦‚0.99ï¼‰ï¼Œ$T$æ˜¯å›åˆé•¿åº¦ã€‚

   - ç”¨é€”ï¼šç›´æ¥ä½œä¸º$V(s_t)$çš„ç›®æ ‡å€¼ã€‚

2. **å¹¿ä¹‰ä¼˜åŠ¿ä¼°è®¡ï¼ˆGAEï¼‰**ï¼š

   - å®šä¹‰ï¼šç»“åˆä¼˜åŠ¿å‡½æ•°$A(s_t,a_t)$å’Œå›æŠ¥$R_t$ï¼Œé€šè¿‡å¹³æ»‘å¤šæ­¥TDè¯¯å·®å¾—åˆ°ï¼š
     $$
     \begin{aligned}
     A_t^{GAE(\lambda)} &= \delta_t + (\gamma \lambda) \delta_{t+1} + (\gamma \lambda)^2 \delta_{t+2} + \dots\\
     &= \sum_{k=0}^{T-t}(\gamma\lambda)^k\delta_{t+k}
     \end{aligned}
     $$
     å…¶ä¸­ï¼Œæ¯ä¸ª$\delta_t$çš„è®¡ç®—æ˜¯å•æ­¥çš„TDæ®‹å·®ï¼š
     $$
     \delta_t = r_t + \gamma V(s_{t+1}) - V(s_t)
     $$
     å…¶ä¸­$\lambda$æ˜¯GAEçš„è¶…å‚æ•°ï¼ˆå¦‚0.95ï¼‰ã€‚

   - ç›®æ ‡å€¼ï¼š$V(s_t)$çš„ç›®æ ‡å€¼ä¸º$\hat{V}^t=A_t^{GAE}+V(s_t)$ã€‚

   - æ›´å»ºè®®ä½¿ç”¨GAEæ¥ä½œä¸ºCriticçš„çœŸå®å€¼

     - **ç†è®ºä¾æ®**ï¼šGAEçš„ä¼˜åŠ¿$A_t^{GAE}$æ˜¯å¤šæ­¥TDè¯¯å·®çš„åŠ æƒå¹³å‡ï¼Œèƒ½å¹³è¡¡åå·®å’Œæ–¹å·®ã€‚Criticçš„ç›®æ ‡å€¼åº”åæ˜ å½“å‰ç­–ç•¥çš„çœŸå®ä»·å€¼ï¼Œè€Œ$V(s_t)+A_t^{GAE}$æ­£æ˜¯å¯¹$R_t$çš„æ›´å¥½ä¼°è®¡ã€‚
     - **å®è·µæ•ˆæœ**ï¼š**PPOä¸­é€šå¸¸ä½¿ç”¨GAEç‰ˆæœ¬çš„ç›®æ ‡å€¼**ï¼Œå› å®ƒæ¯”çº¯è’™ç‰¹å¡æ´›ï¼ˆ`discount(rewards, gamma)`ï¼‰æ›´ç¨³å®šï¼Œæ¯”å•æ­¥TDè¯¯å·®ï¼ˆ$r_t+\gamma V(s_{t+1})$ï¼‰æ›´å‡†ç¡®ã€‚

**æ¨èä½¿ç”¨GAE-basedæ–¹æ³•**

åœ¨PPOä¸­ï¼Œ**Criticç›®æ ‡å€¼ï¼ˆ$\hat{V}^t$ï¼‰çš„è®¡ç®—æ–¹å¼**ä¸»è¦æœ‰ä¸¤ç§ä¸»æµæ–¹æ³•ï¼Œè€Œå®é™…åº”ç”¨ä¸­æ›´æ¨è**GAE-basedæ–¹æ³•**ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†åˆ†æå’Œæ¨èç†ç”±ï¼š

**(1) ç†è®ºä¼˜åŠ¿**

- **æ›´ä½çš„æ–¹å·®**ï¼šç›¸æ¯”MCï¼ŒGAEé€šè¿‡å¤šæ­¥TDæ··åˆæ˜¾è‘—é™ä½æ–¹å·®ï¼ŒåŠ é€Ÿæ”¶æ•›ã€‚
- **é€‚åº”æ€§**ï¼šè°ƒèŠ‚ Î»*Î»* å¯é€‚åº”ä¸åŒä»»åŠ¡ï¼š
  - é«˜éšæœºç¯å¢ƒï¼ˆå¦‚ç¨€ç–å¥–åŠ±ï¼‰ï¼š$\lambda\rightarrow 1$ï¼ˆæ¥è¿‘MCï¼‰ã€‚
  - ç¡®å®šæ€§ç¯å¢ƒï¼ˆå¦‚æœºå™¨äººæ§åˆ¶ï¼‰ï¼š$\lambda\rightarrow 0$ï¼ˆæ¥è¿‘å•æ­¥TDï¼‰ã€‚

**(2) å®è·µéªŒè¯**

- **PPOçš„æ ‡å‡†å®ç°**ï¼š

  - OpenAI Baselinesã€Stable Baselines3ç­‰ä¸»æµåº“é»˜è®¤ä½¿ç”¨GAEè®¡ç®—Criticç›®æ ‡å€¼ã€‚
  - å®éªŒè¡¨æ˜ï¼ŒGAEåœ¨è¿ç»­æ§åˆ¶ï¼ˆå¦‚MuJoCoä»»åŠ¡ï¼‰å’Œç¦»æ•£åŠ¨ä½œç©ºé—´ï¼ˆå¦‚Atariï¼‰ä¸­å‡è¡¨ç°ç¨³å®šã€‚

- **ä¸Actoræ›´æ–°çš„ååŒ**ï¼š

  GAEåŒæ—¶ä¸ºActoræä¾›å¹³æ»‘çš„ä¼˜åŠ¿ä¼°è®¡ï¼ˆ$A_t^{GAE}$ï¼‰ï¼Œé¿å…ç­–ç•¥æ¢¯åº¦çš„é«˜æ–¹å·®é—®é¢˜ã€‚

**(3) å¯¹æ¯”MCçš„å±€é™æ€§**

- **MCçš„é—®é¢˜**ï¼š
  - éœ€è¦å®Œæ•´è½¨è¿¹ï¼Œä¸é€‚åˆåœ¨çº¿å­¦ä¹ æˆ–éƒ¨åˆ†è§‚æµ‹ç¯å¢ƒã€‚
  - é«˜æ–¹å·®å¯èƒ½å¯¼è‡´Criticè®­ç»ƒä¸ç¨³å®šï¼Œå°¤å…¶åœ¨é•¿å‘¨æœŸä»»åŠ¡ä¸­ã€‚

é—®é¢˜ï¼š

> **valueä½¿ç”¨GAE+Valueå¥½åƒæ¯”mcè®­ç»ƒèµ·æ¥è¦æ…¢å¾ˆå¤šï¼Ÿ**

è¿™æ˜¯å› ä¸º**GAE+Valueè®­ç»ƒè¿‡ç¨‹ä¸­å¯¹å€¼å‡½æ•°çš„æ›´æ–°ä¾èµ–æ›´å¼º**ï¼š

GAE åˆ©ç”¨å€¼å‡½æ•°çš„é¢„æµ‹è¿›è¡Œä¼˜åŠ¿ä¼°è®¡ï¼Œè¿™å°±è¦æ±‚å€¼å‡½æ•°ï¼ˆCriticï¼‰å¿…é¡»è¶³å¤Ÿå‡†ç¡®ã€‚åœ¨æ—©æœŸé˜¶æ®µï¼Œä¼°è®¡ä¸å‡†ç¡®æ—¶ï¼ŒGAE å¯¹å€¼å‡½æ•°çš„ä¾èµ–å¯èƒ½ä¼šå‡ç¼“è®­ç»ƒè¿‡ç¨‹ã€‚

#### CriticæŸå¤±å‡½æ•°çš„è®¡ç®—

Criticçš„æŸå¤±å‡½æ•°é€šå¸¸é‡‡ç”¨**å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**ï¼Œè¡¡é‡å½“å‰ä»·å€¼ä¼°è®¡$V_{\theta}(s_t)$ä¸ç›®æ ‡å€¼$\hat{V}_tçš„$å·®è·ï¼š
$$
L_{critic}=\frac{1}{N}\sum_{t=1}^N\left(V_{\theta}(s_t)-\hat{V}_t\right)
$$
å…¶ä¸­ï¼š

- $N$æ˜¯æ‰¹é‡æ•°æ®ä¸­çš„æ ·æœ¬æ•°ã€‚
- $\hat{V}^t$å¯ä»¥æ˜¯$R_tï¼ˆ$MCæ–¹æ³•ï¼‰æˆ–$A_t^{GAE}+V(s_t)$ï¼ˆGAEæ–¹æ³•ï¼‰ã€‚

**å…³é”®ç‚¹è¯´æ˜**

1. **ç›®æ ‡å€¼çš„æ¥æº**ï¼š
   - é€šè¿‡å®é™…äº¤äº’æ•°æ®ï¼ˆè½¨è¿¹ï¼‰è®¡ç®—$R_t$æˆ–$A_t^{GAE}$ï¼Œè¿™äº›å€¼åœ¨æ¯æ¬¡è¿­ä»£ä¸­è¢«å›ºå®šï¼Œä½œä¸ºç›‘ç£å­¦ä¹ çš„æ ‡ç­¾ã€‚
   - å¦‚æœä½¿ç”¨GAEï¼Œéœ€å…ˆé€šè¿‡Criticçš„æ—§å‚æ•°è®¡ç®—$V(s_t)$ï¼ˆç±»ä¼¼Actorä¸­çš„æ—§ç­–ç•¥ï¼‰ã€‚
2. **ä¸Actorçš„åŒºåˆ«**ï¼š
   - Criticçš„æ›´æ–°æ˜¯å…¸å‹çš„å›å½’é—®é¢˜ï¼ˆæœ€å°åŒ–MSEï¼‰ï¼Œè€ŒActorçš„æ›´æ–°åŸºäºç­–ç•¥æ¢¯åº¦ï¼ˆæœ€å¤§åŒ–ä¼˜åŠ¿å‡½æ•°ï¼‰ã€‚
3. **PPOä¸­çš„å®è·µ**ï¼š
   - é€šå¸¸Criticå’ŒActorå…±äº«éƒ¨åˆ†ç½‘ç»œå±‚ï¼ˆå¦‚ç‰¹å¾æå–å±‚ï¼‰ï¼Œä½†è¾“å‡ºå±‚åˆ†å¼€è®­ç»ƒã€‚
   - ç›®æ ‡å€¼$\hat{V}^t$éœ€ä½¿ç”¨æ—§Criticè®¡ç®—ï¼Œä»¥ä¿è¯è®­ç»ƒç¨³å®šæ€§ï¼ˆç±»ä¼¼äºActorä¸­çš„é‡è¦æ€§é‡‡æ ·ï¼‰ã€‚

Criticçš„â€œçœŸå®å€¼â€æ˜¯ç¯å¢ƒåé¦ˆçš„æŠ˜æ‰£å›æŠ¥æˆ–åŸºäºä¼˜åŠ¿å‡½æ•°çš„ä¿®æ­£å€¼ï¼Œé€šè¿‡æœ€å°åŒ–ä¸å½“å‰ä¼°è®¡çš„å‡æ–¹è¯¯å·®æ¥æ›´æ–°Criticç½‘ç»œã€‚è¿™ä¸€è¿‡ç¨‹ä¸ºActoræä¾›äº†ç­–ç•¥æ¢¯åº¦ä¸­çš„åŸºçº¿ï¼ˆBaselineï¼‰ï¼Œæ˜¾è‘—é™ä½æ–¹å·®å¹¶åŠ é€Ÿæ”¶æ•›ã€‚

**ä¸ºä»€ä¹ˆè¿™æ ·æ”¹ï¼Ÿ**

- **ç†è®ºä¾æ®**ï¼šGAEçš„ä¼˜åŠ¿$A_t^{GAE}$æ˜¯å¤šæ­¥TDè¯¯å·®çš„åŠ æƒå¹³å‡ï¼Œèƒ½å¹³è¡¡åå·®å’Œæ–¹å·®ã€‚Criticçš„ç›®æ ‡å€¼åº”åæ˜ å½“å‰ç­–ç•¥çš„çœŸå®ä»·å€¼ï¼Œè€Œ$V(s_t)+A_t^{GAE}$æ­£æ˜¯å¯¹$R_t$çš„æ›´å¥½ä¼°è®¡ã€‚
- **å®è·µæ•ˆæœ**ï¼šPPOä¸­é€šå¸¸ä½¿ç”¨GAEç‰ˆæœ¬çš„ç›®æ ‡å€¼ï¼Œå› å®ƒæ¯”çº¯è’™ç‰¹å¡æ´›ï¼ˆ`discount(rewards, gamma)`ï¼‰æ›´ç¨³å®šï¼Œæ¯”å•æ­¥TDè¯¯å·®ï¼ˆ$r_t+\gamma V(s_{t+1})$ï¼‰æ›´å‡†ç¡®ã€‚

#### CriticæŸå¤±é™å¹…clip

**ä¸ºä»€ä¹ˆè¦å¯¹criticåšclipï¼Ÿ**

æ³¨æ„åœ¨è®­ç»ƒactorçš„æ—¶å€™å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿåœ¨ä½ è®­ç»ƒ PPO çš„æ—¶å€™ï¼Œæœ‰è¿™ä¹ˆä¸€è¡Œ lossï¼š

```python
actor_loss = -Ï€_new(a_t | s_t) * advantage_t   # clipped PPO objective
```

è¿™é‡Œçš„ `advantage_t` æ˜¯ä» buffer æ‹¿å‡ºæ¥çš„ï¼Œä¹Ÿå°±æ˜¯$GAE(\pi_\text{old})$ã€‚

è€Œä½ è¿™æ—¶ç”¨çš„æ˜¯$\pi_\text{new}$çš„ actor æ¥æ›´æ–° policyï¼

äºæ˜¯å‡ºç°äº†è¿™æ ·çš„ä¸ä¸€è‡´ï¼š

| é¡¹ç›®      | æ¥è‡ªå“ªä¸ª policy    |
| --------- | ------------------ |
| Ï€_new(a)  | å½“å‰actor_new(s)   |
| advantage | rollout æ—¶çš„ Ï€_old |

ä¹Ÿå°±æ˜¯è¯´ï¼šä½ åœ¨ç”¨ **æ—§ç­–ç•¥ä¸‹çš„ advantageï¼ˆGAE ç»“æœï¼‰** å»è¯„ä¼° **å½“å‰ç­–ç•¥çš„åŠ¨ä½œå¥½ä¸å¥½**ã€‚è¿™åœ¨æ•°å­¦ä¸Šæ˜¯è¿‘ä¼¼çš„ï¼Œå‰ææ˜¯$\pi_\text{new}$æ²¡æœ‰å¤§å¹…åç¦»$\pi_\text{old}$ã€‚

å°±æ˜¯è¯´ï¼Œåªé é‡è¦æ€§é‡‡æ ·æ˜¯ä¸å¤Ÿçš„ï¼Œè¿™åªæ˜¯è§£å†³äº†æ•°æ®åˆ†å¸ƒçš„é—®é¢˜ï¼Œä½†æ˜¯ä½ advantageæœ¬èº«å·²ç»ä¸ç¬¦åˆæ–°çš„actoræ¨¡å‹äº†ã€‚

æ‰€ä»¥ PPO æ‰å¼•å…¥äº† policy clippingï¼ˆé™åˆ¶$\pi_\text{new}/\pi_\text{old}$ä¸è¦å¤ªç¦»è°±ï¼‰ï¼Œæ˜¯ä¸ºäº†è¿™ä¸ª mismatch ä¸è‡³äºå¤ªä¸¥é‡ï¼

é‚£ä¸ºä»€ä¹ˆè¦å¯¹criticåšclipå‘¢ï¼Ÿ

åœ¨ **critic æ›´æ–°çš„æ—¶å€™**ï¼Œcriticæ‹Ÿåˆæ—§targetï¼Œä½†$\pi_\text{new}$å˜äº†

```python
critic_loss = MSE(critic(s), v_target)
```

- `v_target` æ˜¯ rollout åç®—å¥½çš„ï¼ˆ$\pi_\text{old}$çš„ valueï¼‰
- `critic(s)` æ˜¯å½“å‰æ­£åœ¨æ›´æ–°çš„ç½‘ç»œï¼ˆ$\pi_\text{new}$çš„ criticï¼‰

è¿™ä¿© mismatchï¼Œå°±å¯¼è‡´ï¼š

> critic åœ¨æ‹¼å‘½æ‹Ÿåˆä¸€ä¸ª$\pi_\text{old}$ä¸‹å¾—åˆ°çš„ targetï¼Œå´æ˜¯ç”¨$\pi_\text{new}$çš„ç½‘ç»œå»é¢„æµ‹çš„ â†’ è¶Šè®­ç»ƒè¶Šä¸ä¸€è‡´ â†’ è®­ç»ƒå‘æ•£

è€Œä¸”ï¼š

- å¦‚æœä½ è®­ç»ƒ K ä¸ª epochï¼Œcritic æ¯æ¬¡éƒ½æ‹¿åŒä¸€ä¸ª v_target åå¤æ‹Ÿåˆï¼Œä¼šè¿‡æ‹Ÿåˆæ—§æ•°æ®ï¼Œå¿½ç•¥äº†ç°åœ¨ policy å·²ç»å˜äº†ã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ **è¦åŠ  value clipping** æ¥é™åˆ¶ critic çš„æ›´æ–°é€Ÿåº¦ï¼Œé˜²æ­¢ mismatch è¶Šæ¥è¶Šä¸¥é‡ã€‚



**æˆ‘å¯¹valueåšclipçš„ç†è§£ï¼š**

> æ˜¯ä¸æ˜¯actoræ›´æ–°ç­–ç•¥åï¼Œå¯¹äºç‰¹å®šçš„stateï¼Œå…¶valueå·²ç»å®é™…ä¸Šå‘ç”Ÿäº†å˜åŒ–ï¼Œå› ä¸ºå¯¹äºè¯¥stateï¼Œæ–°çš„actorç½‘ç»œçš„è¡Œä¸ºå·²ç»ä¸å†å’Œæ—§çš„actorç½‘ç»œçš„è¡Œä¸ºç›¸åŒäº†ï¼Œæ‰€ä»¥ï¼Œcriticç½‘ç»œä¸åº”è¯¥å’Œæ—§çš„criticç½‘ç»œæ‹Ÿåˆçš„å¾ˆå¥½ï¼Œå› ä¸ºæ—§çš„criticç½‘ç»œä¼°è®¡çš„valueå·²ç»ä¸å†ç¬¦åˆå½“å‰çš„çŠ¶æ€å¯¹åº”çš„valueäº†ã€‚
> è¯·é—®æˆ‘çš„ç†è§£å¯¹å—ï¼Ÿæœ‰ä»€ä¹ˆå»ºè®®å’Œéœ€è¦è¡¥å……çš„å—

è®¨è®ºå‰æï¼šä½ éœ€è¦æ³¨æ„åˆ°criticæ˜¯ç»™actoræœåŠ¡çš„ï¼Œè€Œactoråœ¨è®­ç»ƒæœŸé—´æ˜¯åœ¨ä¸æ–­æ›´æ–°çš„ï¼Œcriticæ‹Ÿåˆçš„æ˜¯å°±çš„ç½‘ç»œçš„valueï¼Œä½†æ˜¯å·²ç»ä¸ç¬¦åˆå½“å‰æ›´æ–°çš„actorçš„ç­–ç•¥äº†ï¼Œå°±æ˜¯å½“å‰stateæŒ‰ç…§å½“å‰çš„actorè·‘ï¼Œå…¶å€¼ä¸å†æ˜¯æ—§çš„criticäº†ã€‚

**ä¸€ä¸ªæ›´å½¢è±¡çš„ç±»æ¯”ï¼ˆè¶…å¥½ç†è§£ğŸ”¥ï¼‰**

æƒ³è±¡ä½ åœ¨ä¸€ä¸ªé»‘ç›’ç³»ç»Ÿä¸­ï¼Œå…ˆè§‚æµ‹äº†ä¸€äº›è¡Œä¸ºæ•°æ®ï¼ˆæ—§ policyï¼‰ï¼Œä½ æƒ³åŸºäºè¿™äº›æ•°æ®å»ï¼š

- ä¸€è¾¹æ›´æ–°ç­–ç•¥ï¼ˆactorï¼‰
- ä¸€è¾¹æ›´æ–°è¯„ä¼°ï¼ˆcriticï¼‰

ä½†è¯„ä¼°æ›´æ–°å¤ªå¿«äº†ï¼Œç›¸å½“äºä½ åœ¨â€œæ”¹å˜æ¯”èµ›è§„åˆ™â€çš„åŒæ—¶ï¼Œåˆæ‹¿æ—§è§„åˆ™ä¸‹çš„æ•°æ®å»è®­ç»ƒæ–°çš„è¯„ä¼°å™¨â€”â€”è‡ªç„¶ä¼šè¶Šæ¥è¶Šåç¦»ï¼Œç”šè‡³èƒ¡è¯´å…«é“ï¼

æ‰€ä»¥ä½ è¦é™åˆ¶ critic çš„æ›´æ–°é€Ÿåº¦ï¼Œè®©å®ƒä¸è¦â€œè¯´å˜å°±å˜â€ï¼Œè€Œæ˜¯ç¨³ç¨³åœ°â€œè´´ç€æ—§è§„åˆ™å­¦ä¹ â€ã€‚



**å¯¹valueåšnormæ˜¯ä¸ªå¸¸è§çš„é€‰æ‹©å—ï¼Ÿæœ‰å…¶ä»–å¤§æœºæ„è¿™ä¹ˆåšå—ï¼Ÿ**

è¿™ä¸ªé—®é¢˜é—®å¾—éå¸¸åˆ°ä½ï¼æˆ‘ä»¬æ¥ç³»ç»Ÿåœ°èŠä¸€ä¸‹å¯¹ **value åšå½’ä¸€åŒ–ï¼ˆvalue normalizationï¼‰** è¿™ä»¶äº‹åˆ°åº•æ˜¯ä¸æ˜¯ä¸»æµåšæ³•ï¼Œä»¥åŠæœ‰æ²¡æœ‰**å¤§æœºæ„**æˆ–è€…**ç»å…¸è®ºæ–‡**è¿™ä¹ˆå¹²è¿‡ã€‚

çŸ­ç»“è®º

> **æ˜¯çš„**ï¼Œå¯¹ value function çš„å½’ä¸€åŒ–ï¼ˆæˆ– centerï¼‰æ˜¯å¼ºåŒ–å­¦ä¹ ä¸­ä¸€ä¸ª**æ¯”è¾ƒå¸¸è§ä¸”è¢«å¤§æœºæ„ä½¿ç”¨è¿‡çš„æŠ€å·§**ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»¥ä¸‹èƒŒæ™¯ä¸‹ï¼š

- å¤šä»»åŠ¡è®­ç»ƒ
- value åˆ†å¸ƒè·¨åº¦å¤§çš„åœºæ™¯ï¼ˆæ¯”å¦‚ä½ çš„ 100~200ï¼‰
- å€¼å‡½æ•°è®­ç»ƒä¸ç¨³å®šæ—¶

**è¯æ®å’Œä½¿ç”¨æƒ…å†µ**

1. **OpenAIï¼šSpinning Upï¼ˆå®˜æ–¹RLåº“ï¼‰**

OpenAI çš„ SpinningUp å¼ºåŒ–å­¦ä¹ åº“çš„æ–‡æ¡£ä¸­ï¼Œæ˜ç¡®æŒ‡å‡ºäº†ï¼š

> > "Standardizing the advantages and sometimes the returns can reduce variance and improve learning."

è™½ç„¶è¿™é‡Œæåˆ°çš„æ˜¯ returnï¼Œä½†ä»–ä»¬åœ¨ä»£ç å®ç°ä¸­ä¹Ÿå…è®¸å¯¹ value åšä¸­å¿ƒåŒ–æ“ä½œï¼Œä¸»è¦æ˜¯ä¸ºäº† **clip value loss çš„æ—¶å€™æ•°å€¼ä¸Šæ›´åˆç†**ã€‚

2. **DeepMindï¼šIMPALA**

åœ¨ DeepMind çš„ IMPALA è®ºæ–‡ï¼š

> Espeholt et al., *IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures*, ICML 2018

ä»–ä»¬ä½¿ç”¨äº†â€œvalue function rescalingâ€ï¼ˆå€¼å‡½æ•°é‡æ ‡å®šï¼‰ï¼Œè™½ç„¶ä¸æ˜¯ä¸¥æ ¼çš„ `norm`ï¼Œä½†æ ¸å¿ƒæ€æƒ³ç±»ä¼¼ï¼š

- **æŠŠå€¼å‡½æ•°æ˜ å°„åˆ°ä¸€ä¸ªæ›´â€œè§„æ•´â€çš„èŒƒå›´å†…å†è®­ç»ƒ**ï¼Œä»¥æå‡ç¨³å®šæ€§ã€‚

3. **Google Researchï¼šAcme RL åº“**

Acme æ˜¯ Google Research å‡ºå“çš„å¼ºåŒ–å­¦ä¹ åº“ï¼Œå®ƒåœ¨å¾ˆå¤š agent ä¸­éƒ½æœ‰ `ValueTransform`ï¼Œæ¯”å¦‚ `LogTransform`, `NormalizeTransform` ç­‰æ¨¡å—ï¼Œä¸“é—¨å¯¹ critic çš„è¾“å‡ºåšå½’ä¸€åŒ–ã€‚

**ä¸ºä»€ä¹ˆè¿™ä¸æ˜¯æ‰€æœ‰äººéƒ½é»˜è®¤åšçš„ï¼Ÿ**

å› ä¸ºè¿™ä»¶äº‹å±äºï¼š

- **ä¸æ˜¯å¿…é¡»ï¼Œä½†å¯èƒ½æœ‰ç›Š**
- éœ€è¦ **è§†ä»»åŠ¡è€Œå®š**ï¼ˆæ¯”å¦‚ reward å’Œ return çš„å°ºåº¦å˜åŒ–å¤§æ—¶æ›´æœ‰å¸®åŠ©ï¼‰

ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨ reward åˆ†å¸ƒç¨³å®šã€critic loss æœ¬èº«ä¸ç‚¸çš„æ—¶å€™ï¼Œå¾ˆå¤šäººå°±æ‡’å¾—æäº†ã€‚ä½†åƒä½ è¿™æ · v å€¼èŒƒå›´åœ¨ 100~200ï¼Œ**å†ç”¨ 0.2 æ¥ clip çš„è¯ç¡®å®ä¸åˆç†**ï¼Œè¿™ä¸ªæ—¶å€™å°±éå¸¸å€¼å¾—åŠ ä¸ª `value norm`ã€‚

**å»ºè®®**

å¦‚æœä½ æ‹…å¿ƒç¨³å®šæ€§ï¼Œæˆ–è€…è§‰å¾— value loss æœ‰æ—¶æŠ–åŠ¨å¤§ï¼Œä¸å¦¨åŠ ä¸ª `use_value_norm` çš„ flagï¼Œè§‚å¯Ÿä¸‹è®­ç»ƒæ˜¯å¦æ›´å¹³ç¨³ã€‚





```python
critic_loss = torch.max(v_loss_unclipped, v_loss_clipped).mean()
```

æˆ‘æ²¡ç†è§£ä¸ºä»€ä¹ˆè¦å–æœ€å¤§å€¼ï¼Ÿèƒ½å…·ä½“è®²ä¸€ä¸‹åŸå› è®©æˆ‘å½»åº•æ˜ç™½å—

æˆ‘ä»¬ä¹‹æ‰€ä»¥å– `v_loss_unclipped` å’Œ `v_loss_clipped` çš„ **é€å…ƒç´ æœ€å¤§å€¼**ï¼Œæ˜¯å› ä¸ºè¿™æ ·å¯ä»¥ **é™åˆ¶ value æ›´æ–°çš„å¹…åº¦ï¼ŒåŒæ—¶ä¿è¯è®­ç»ƒçš„ç¨³å®šæ€§**ã€‚è¿™å’Œ PPO ä¸»ä½“çš„ã€Œclip ç›®æ ‡ç­–ç•¥æ›´æ–°ã€éå¸¸ç±»ä¼¼ï¼Œæ˜¯å®ƒçš„ critic ç‰ˆæœ¬ã€‚

è¯¦ç»†è®²è§£ï¼ˆé€æ­¥æ¥ï¼‰

é—®é¢˜èƒŒæ™¯

åœ¨ **PPO** ä¸­ï¼Œpolicy ä¼šå¤šæ¬¡æ›´æ–°åŒä¸€æ‰¹æ•°æ®ï¼ˆK epochsï¼‰ã€‚å¦‚æœæ²¡æœ‰é™åˆ¶ï¼Œ**criticï¼ˆvalue ç½‘ç»œï¼‰ä¼šè¿‡æ‹Ÿåˆåˆ°æ—§çš„ value target**ï¼Œé€ æˆç­–ç•¥å’Œ value çš„ä¸ä¸€è‡´ï¼Œå¸¦æ¥ä¸ç¨³å®šã€‚

PPO çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**é™åˆ¶å˜åŒ–å¹…åº¦ï¼Œä¿æŒç¨³å®šæ”¹è¿›**

- åœ¨ policy é‡Œï¼ŒPPO çš„åšæ³•æ˜¯ï¼š

  ```python
  ratio = Ï€_new / Ï€_old
  clip(ratio, 1 - Îµ, 1 + Îµ)
  ```

  é™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦ã€‚

- é‚£ value å‘¢ï¼Ÿvalue ä¹Ÿåº”è¯¥é™åˆ¶å®ƒçš„æ›´æ–°å¹…åº¦ï¼Œ**é˜²æ­¢ä¸€ä¸‹å­æ›´æ–°å¤ªå¤š**ã€‚äºæ˜¯å°±æœ‰äº†è¿™ä¸ªç±»ä¼¼ clip çš„æƒ³æ³•ï¼š

  ```python
  v_clipped = v_old + clip(v_new - v_old, -v_clip, +v_clip)
  ```

  å¦‚æœ value æ›´æ–°å¤ªçŒ›ï¼Œå°±ä¼šè¢«å‰ªåˆ°æœ€å¤§æ›´æ–°å¹…åº¦ `Â±v_clip`ï¼Œä¿æŒâ€œæ…¢æ…¢æ¥â€çš„ç¨³å®šæ€§ã€‚

**é‚£ä¸ºä»€ä¹ˆå– `max(unclipped, clipped)`ï¼Ÿ**

æƒ³è±¡æˆ‘ä»¬ç”¨ MSE loss æ¥è®­ç»ƒ valueï¼Œæƒ³æœ€å°åŒ–ä»¥ä¸‹çš„ä¸œè¥¿ï¼š

- `v_loss_unclipped = (v_pred - v_target)^2`
- `v_loss_clipped   = (v_clipped - v_target)^2`

**ä½†æˆ‘ä»¬åˆä¸å¸Œæœ› value æ”¹å¾—å¤ªçŒ›ï¼ˆç‰¹åˆ«æ˜¯åœ¨ç›®æ ‡å‡½æ•°ä¼šå› ä¸º value çŒ›å˜è€Œé™ä½ loss æ—¶ï¼‰**ã€‚

æ‰€ä»¥æˆ‘ä»¬å–ï¼š

```python
critic_loss = max(v_loss_unclipped, v_loss_clipped)
```

å®ƒçš„å«ä¹‰æ˜¯ï¼š

> å¦‚æœæœªè£å‰ªçš„ loss æ¯”è£å‰ªåçš„å°ï¼Œ**è¯´æ˜æ˜¯å› ä¸º value æ”¹å¾—å¤ªçŒ›æ‰è®© loss å°äº†ï¼Œæˆ‘ä»¬ä¸ç›¸ä¿¡è¿™ä¸ªç»“æœ**ï¼Œæ‰€ä»¥ç”¨è£å‰ªåçš„ lossï¼›
>
> å¦‚æœæœªè£å‰ªçš„ loss æ¯”è£å‰ªåçš„å¤§ï¼Œè¯´æ˜æ²¡æœ‰è¶…è¿‡èŒƒå›´ï¼Œä¿ç•™å®ƒå°±è¡Œã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼š

ğŸ§  **æˆ‘ä»¬ä¸è®© loss å› ä¸º value æ›´æ–°è¿‡çŒ›è€Œâ€œè™šå‡åœ°å˜å¥½â€ã€‚**

æ­£ä¾‹ï¼š

v_old=1.0ï¼Œ v_pred=1.5, v_target=2.0, clip=0.2, æ‰€ä»¥v_clip=1.2ï¼Œæ‰€ä»¥loss_clip=(1.2-2.0)^2 > loss_pred=(1.5-2.0)^2ã€‚

è¿™æ˜¯ **PPO çš„ä¿å®ˆç­–ç•¥æ€æƒ³çš„å»¶ç»­**ï¼š

> æˆ‘ä»¬ä¸èƒ½ç›¸ä¿¡è¿™æ¬¡è·³å¾—å¤ªçŒ›çš„ value çœŸçš„æœ‰æ•ˆï¼Œå¯èƒ½åªæ˜¯å¶ç„¶å‹ä¸­äº†ç›®æ ‡æ–¹å‘ï¼›
>
> æ‰€ä»¥æˆ‘ä»¬å®æ„¿æƒ©ç½šå®ƒï¼ˆä¿ç•™æ›´å¤§çš„ lossï¼‰ï¼Œä»¥é˜²å®ƒâ€œé£˜â€èµ·æ¥ï¼ˆä¸ç¨³å®šï¼‰ï¼›
>
> **å¦‚æœä½ çœŸçš„å¥½ï¼Œé‚£ä½ æ…¢æ…¢ä» 1.2 â†’ 1.3 â†’ 1.4 â†’ â€¦ å»æ¥è¿‘ç›®æ ‡ï¼Œåˆ«è·³å¤ªçŒ›ã€‚**

åä¾‹ï¼Œé‡‡ç”¨äº†åŸå§‹å€¼çš„æŸå¤±å€¼ï¼š

v_old=1.0ï¼Œ v_pred=0.7, v_target=2.0, clip=0.2, æ‰€ä»¥v_clip=0.8, æ‰€ä»¥loss_clip=(0.8-2.0)^2 < loss_pred=(0.7-2.0)^2ã€‚ä½†æˆ‘ä¸ç¡®å®šè¿™ç§æƒ…å†µæ˜¯å¦ä¼šçœŸå®å‘ç”Ÿï¼Œåªæ˜¯ä»æ•°å€¼ä¸Šæ„é€ äº†è¿™ä¹ˆä¸€ä¸ªä¾‹å­

| å€¼ç±»å‹               | é¢„æµ‹å€¼ | Loss             |
| -------------------- | ------ | ---------------- |
| æœªå‰ªè£çš„ `v_pred`    | 0.7    | **1.69** âœ…ï¼ˆå¤§ï¼‰ |
| å‰ªè£åçš„ `v_clipped` | 0.8    | **1.44** âŒï¼ˆå°ï¼‰ |

æˆ‘ä»¬ä¿å®ˆåœ°ä¿ç•™äº†æ›´å¤§çš„ lossï¼ˆ1.69ï¼‰ï¼Œè™½ç„¶å‰ªè£åæŸå¤±æ›´å°ï¼Œä½†æˆ‘ä»¬è®¤ä¸ºç½‘ç»œè¿™æ¬¡çš„å›å½’â€œé€€æ­¥å¾—å¤ªçŒ›â€äº†ã€‚

ç¡®å®ï¼Œè¿™ç§æƒ…å†µåœ¨å®é™…è®­ç»ƒä¸­ä¸å¤ªå¸¸è§ï¼Œä½†**ç†è®ºä¸Šæ˜¯ä¸€å®šå¯èƒ½å‘ç”Ÿçš„**ã€‚ä½ çš„åä¾‹éå¸¸æ¸…æ™°ã€é€»è¾‘é—­ç¯ï¼Œå®Œç¾ï¼

æ‰€ä»¥ PPO çš„ value clipping æ˜¯ä¸€ç§ **â€œæ›´ä¿å®ˆçš„ value loss ä¼°è®¡â€**ï¼š

```python
critic_loss = torch.max(v_loss_unclipped, v_loss_clipped).mean()
```

è¿™å¥è¯çš„å«ä¹‰æ˜¯ï¼š

- å¦‚æœè£å‰ªåçš„é¢„æµ‹æ›´å·®ï¼ˆloss æ›´å¤§ï¼‰ï¼Œé‚£å®ƒåè€Œä»£è¡¨çœŸå®è¶‹åŠ¿ï¼Œé‚£å°±ä¿ç•™å®ƒï¼›
- å¦‚æœè£å‰ªåçš„é¢„æµ‹æ›´å¥½ï¼ˆloss æ›´å°ï¼‰ï¼Œä½†è¿™å¯èƒ½æ˜¯ **è£å‰ªâ€œé€ å‡ºæ¥çš„â€å‡è±¡**ï¼Œæˆ‘ä»¬å°±ä¸è¦å®ƒï¼Œæˆ‘ä»¬ä¿ç•™åŸå§‹æ›´å¤§çš„æŸå¤±ã€‚

### Criticç½‘ç»œçš„ç†è§£

æˆ‘çš„ç†è§£ï¼š

ä½ éœ€è¦æ³¨æ„åˆ°criticæ˜¯ç»™actoræœåŠ¡çš„ï¼Œè€Œactoråœ¨è®­ç»ƒæœŸé—´æ˜¯åœ¨ä¸æ–­æ›´æ–°çš„ï¼Œcriticæ‹Ÿåˆçš„æ˜¯å°±çš„ç½‘ç»œçš„valueï¼Œä½†æ˜¯å·²ç»ä¸ç¬¦åˆå½“å‰æ›´æ–°çš„actorçš„ç­–ç•¥äº†ï¼Œå°±æ˜¯å½“å‰stateæŒ‰ç…§å½“å‰çš„actorè·‘ï¼Œå…¶å€¼ä¸å†æ˜¯æ—§çš„criticçš„å€¼äº†ã€‚

ç„¶åæˆ‘çš„é—®é¢˜ï¼š

æ—¢ç„¶actoråœ¨ä¸æ–­æ›´æ–°å˜åŒ–ï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆè¿˜è¦ç”¨criticæ¥æ‹Ÿåˆæ—§çš„valueå‘¢?æ„Ÿè§‰éœ€è¦çš„æ˜¯æ–°çš„actorä¸‹çš„criticçš„valueå•Š

ä½ çš„ç†è§£éå¸¸æ¥è¿‘çœŸç›¸äº†ï¼Œå°¤å…¶æ˜¯è¿™å¥è¯éå¸¸åˆ°ä½ï¼š

> **critic æ˜¯ä¸º actor æœåŠ¡çš„ï¼Œè€Œ actor æ˜¯åœ¨ä¸æ–­æ›´æ–°çš„ã€‚**

æˆ‘ä»¬å°±ä»¥è¿™å¥è¯ä¸ºå‡ºå‘ç‚¹ï¼Œä¸€ç‚¹ç‚¹è®²é€ä½ åé¢çš„é—®é¢˜â€”â€”**ä¸ºä»€ä¹ˆè¿˜è¦ç”¨æ—§ç­–ç•¥ä¸‹çš„ value æ¥è®­ç»ƒ criticï¼Ÿéš¾é“ä¸åº”è¯¥ç”¨æ–°ç­–ç•¥çš„å—ï¼Ÿ**

**1. ä¸ºä»€ä¹ˆ critic æ‹Ÿåˆçš„æ˜¯â€œæ—§ç­–ç•¥â€çš„ valueï¼Ÿ**

å› ä¸ºæˆ‘ä»¬ rollout çš„æ•°æ®ï¼Œæ˜¯æ—§ç­–ç•¥ Ï€_old è·‘å‡ºæ¥çš„ï¼

- æˆ‘ä»¬è®­ç»ƒå¼ºåŒ–å­¦ä¹ çš„æ—¶å€™ï¼Œä¸èƒ½å‡­ç©ºçŸ¥é“æŸä¸ª state çš„çœŸå® value æ˜¯å¤šå°‘ã€‚
- æ‰€ä»¥æˆ‘ä»¬åªèƒ½é  rolloutï¼Œä¹Ÿå°±æ˜¯ç”¨å½“å‰ç­–ç•¥ Ï€_old å»ç¯å¢ƒé‡Œèµ°ä¸€æ®µï¼Œæ”¶é›†å›æŠ¥ã€æŠ˜æ‰£å€¼ï¼Œç„¶åä¼°ç®—è¿™ä¸ªè½¨è¿¹çš„ valueï¼ˆä¹Ÿå°±æ˜¯ TD æˆ– GAE ç®—æ³•ç®—å‡ºçš„ `v_target`ï¼‰
- è¿™äº› value targetï¼Œåæ˜ çš„æ˜¯ï¼š**å¦‚æœä½ æŒ‰ Ï€_old å»èµ°ï¼Œè¿™ä¸ª state çš„ value æ˜¯å¤šå°‘**

ğŸ§  æ‰€ä»¥ critic æ­¤æ—¶çš„ç›®æ ‡å°±æ˜¯ï¼š

> åœ¨è®­ç»ƒæœŸé—´ï¼Œå°½é‡è®© V(s) è´´è¿‘ Ï€_old ä¸‹çš„ value ä¼°è®¡ï¼ˆv_targetï¼‰

**2. é‚£ä¸ºä»€ä¹ˆä¸ç›´æ¥è®­ç»ƒä¸€ä¸ª critic æ¥æ‹Ÿåˆ Ï€_new çš„ valueï¼Ÿ**

å› ä¸ºä½ æ ¹æœ¬æ²¡æœ‰ Ï€_new çš„è½¨è¿¹æ•°æ®å•Šï¼

ä½ ä¸€è¾¹è®­ç»ƒ actorï¼Œå®ƒçš„ç­–ç•¥$\pi_{\text{new}}$ä¸€ç›´åœ¨å˜ï¼› å¯ä½ é‡‡æ ·çš„æ•°æ®ä»ç„¶æ˜¯æ—§çš„$\pi_{\text{old}}$ç”Ÿæˆçš„ï¼› è¿™å°±å«åšï¼š

> **æ•°æ®åˆ†å¸ƒä¸åŒ¹é…**ï¼ˆmismatch between data distribution and learning targetï¼‰

ä¸¾ä¸ªä¾‹å­ï¼š

ä½ ç°åœ¨æœ‰ä¸€ä¸ªstate sï¼Œä½ å¸Œæœ› critic å­¦çš„æ˜¯ â€œ$\pi_{\text{new}}$ä¸‹ s çš„ valueâ€ï¼Œ
 ä½†ä½ å®é™…ä¸Šæ‹¿åˆ°çš„æ‰€æœ‰ sampleï¼Œéƒ½æ˜¯$\pi_{\text{old}}$ä¸‹çš„è½¨è¿¹äº§ç”Ÿçš„å›æŠ¥å’ŒåŠ¨ä½œã€‚

ç»“æœï¼š
 ä½ æƒ³è®© critic æ‹Ÿåˆ$\pi_{\text{new}}$çš„æœŸæœ›ï¼Œä½†æ‰‹é‡Œåªæœ‰ $\pi_{\text{old}}$çš„æ•°æ® â†’ ä¼°è®¡æ˜¯é”™çš„ï¼
 è¿™å°±å¯èƒ½å¯¼è‡´ value function ä¸å‡†ï¼Œadvantage è¯¯å¯¼ï¼Œactor æ›´æ–°æ–¹å‘å‡ºé”™ã€‚

**3. PPO æ€ä¹ˆè§£å†³è¿™ä¸ªçŸ›ç›¾ï¼Ÿ**

PPO çš„åŸºæœ¬ç­–ç•¥æ˜¯ï¼š

> ä¿æŒ policy æ›´æ–°çš„â€œæ­¥å­â€å¾ˆå°ï¼Œè¿™æ ·$\pi_{\text{new}}$å’Œ$\pi_{\text{old}}$ä¸ä¼šå·®å¤ªå¤šã€‚

æ‰€ä»¥ï¼š

- v_target æ˜¯$\pi_{\text{old}}$ä¸‹èµ°å‡ºæ¥çš„
- critic æ‹Ÿåˆå®ƒä¹Ÿè¿˜ç®—åˆç†
- actor æ›´æ–°æ–¹å‘ä¹Ÿä¸ä¼šé”™å¤ªå¤š

è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆï¼š

- PPO è¦é™åˆ¶ policy ratio $\frac{\pi_{\theta}(a|s)}{\pi_{\theta_{\text{old}}}(a|s)}$
- ç”¨ clipping æˆ– KL penalty æ¥ä¿è¯ â€œä¸è¦è·‘å¤ªè¿œâ€

è¿™æ˜¯ä¸€ç§ **è¿‘ä¼¼ä¸€è‡´æ€§ç­–ç•¥**ï¼ˆapproximate policy consistencyï¼‰ã€‚





#### Criticä¼šå¤šå­¦å‡ è½®

åœ¨ [OpenAI Five çš„åšå®¢](https://openai.com/research/openai-five) å’Œç›¸å…³æ¼”è®²ä¸­ä¹Ÿæ˜ç¡®æåˆ°ï¼š

- actor-critic ä½¿ç”¨ LSTM
- actor å’Œ critic å°½å¯èƒ½å…±äº« RNNï¼Œä½† critic æ˜¯é¢å¤–å•ç‹¬è®­ç»ƒçš„
- PPO loss ä¸­ï¼Œadvantage æ˜¯åœ¨ rollout æ—¶å°±è®¡ç®—å¥½ã€é™æ€å­˜åœ¨ buffer ä¸­çš„

ä½†ä»–ä»¬ä¹Ÿæœ‰ä¸€ä¸ªé‡è¦çš„ç­–ç•¥ï¼š

> åœ¨è®­ç»ƒæœŸé—´ï¼Œä¼šæš‚åœ actor çš„æ›´æ–°ï¼Œè®© critic å¤šå­¦å‡ è½®ï¼ŒæŠŠ value ä¼°è®¡æ‹‰å›æ¥ï¼ˆè¿™ä¹Ÿå’Œä½ å‰é¢é—®çš„â€œé¢å¤– train criticâ€å¯¹åº”ï¼‰

## å­¦ä¹ ç‡

### actorå’Œcriticå­¦ä¹ ç‡è®¾ç½®

åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒPPOçš„`actor`å’Œ`critic`é€šå¸¸ä¼šè®¾ç½®**ä¸åŒçš„å­¦ä¹ ç‡**ï¼ŒåŸå› æ˜¯ï¼š

- **Actorï¼ˆç­–ç•¥ç½‘ç»œï¼‰æ›´æ–°é¢‘ç‡è¾ƒé«˜ã€è¦æ±‚è¾ƒç¨³å®šï¼Œå­¦ä¹ ç‡é€šå¸¸è®¾å¾—å°ä¸€äº›**ï¼›
- **Criticï¼ˆä»·å€¼ç½‘ç»œï¼‰ç”¨äºä¼°è®¡çŠ¶æ€ä»·å€¼ï¼Œå¯ä»¥æ›´å¿«æ”¶æ•›ï¼Œæ‰€ä»¥å­¦ä¹ ç‡è®¾å¾—ç¨å¤§ä¸€äº›**ã€‚

å¸¸è§ç»éªŒå€¼å¦‚ä¸‹ï¼š

| æ¨¡å—   | å­¦ä¹ ç‡èŒƒå›´ï¼ˆç»éªŒå€¼ï¼‰ |
| ------ | -------------------- |
| Actor  | `1e-4`åˆ°`3e-4`       |
| Critic | `1e-3`åˆ°`1e-4`       |

ä¾‹å¦‚ï¼š

- **OpenAI Baselines é»˜è®¤è®¾ç½®**ï¼š
  - `actor_lr = 2.5e-4`
  - `critic_lr = 2.5e-4`ï¼ˆå…±äº«å­¦ä¹ ç‡ï¼‰
- **Stable Baselines3** ä¸­ PPOï¼š
  - é»˜è®¤æ˜¯`lr = 3e-4`ï¼ˆå…±äº«ï¼‰
  - ä½†å¯ä»¥é€šè¿‡`optimizer_class=torch.optim.Adam`+`param_groups`åˆ†å¼€è®¾ç½®
- **Google Dopamine æˆ– RLlib ç­‰å·¥ä¸šåº“**ï¼š
  - å¸¸è§è®¾ç½®ï¼š
    - `actor_lr = 1e-4`
    - `critic_lr = 5e-4`æˆ–`1e-3`

### criticå­¦ä¹ ç‡å’Œepsè®¾ç½®çš„å…³ç³»

å·²çŸ¥ï¼š

ï¼ˆ1ï¼‰criticå­¦ä¹ ä¸ç¨³å®šï¼Œæ‰€ä»¥epsè¦è°ƒå¤§ï¼Œè®¾ç½®ä¸º1e-5ï¼Œ

ï¼ˆ2ï¼‰criticçŠ¶æ€å€¼è®­ç»ƒå¿«ï¼Œæ­¥å­å¯ä»¥å¤§ä¸€ç‚¹ï¼Œæ‰€ä»¥å…¶å­¦ä¹ ç‡è®¾ç½®çš„æ¯”è¾ƒå¤§ï¼Œå³ä¸º1e-3ï¼Œæ­¤æ—¶actorçš„å­¦ä¹ ç‡ä¸º3e-4ã€‚

ï¼ˆ3ï¼‰å¦‚æœè§‚å¯Ÿåˆ°ç­–ç•¥éœ‡è¡ï¼Œå†è€ƒè™‘è°ƒå°criticå­¦ä¹ ç‡

é—®é¢˜ï¼š

ï¼ˆ1ï¼‰ç¬¬ä¸€ç‚¹å’Œç¬¬äºŒç‚¹çŸ›ç›¾ï¼Œå› ä¸ºå¦‚æœcriticå­¦ä¹ ä¸ç¨³å®šï¼Œé‚£ä¹ˆå­¦ä¹ ç‡ä¸æ˜¯åº”è¯¥æŒºå°ä¸€äº›å—ï¼Œæ­¥å­åº”è¯¥å°ä¸€äº›å•Š

ï¼ˆ2ï¼‰ç¬¬äºŒç‚¹å’Œç¬¬ä¸‰ç‚¹çŸ›ç›¾ï¼Œå°±æ˜¯criticçš„å­¦ä¹ ç‡ä½ æœ¬æ¥å°±è®¾ç½®çš„æ¯”è¾ƒå¤§ï¼Œä¸ºä»€ä¹ˆè¿˜è¦è°ƒå°å‘¢ï¼Ÿé‚£ä¸ºä½•ä¸ä¸€å¼€å§‹å°±è°ƒå°å‘¢

è§£ç­”ï¼š

ï¼ˆ1ï¼‰criticä¸ç¨³å®šï¼Œä¸ºå•¥è¿˜è®©å®ƒâ€œæ­¥å­å¤§ä¸€ç‚¹â€ï¼Ÿ

è¿™å…¶å®æ˜¯å¼ºåŒ–å­¦ä¹ å·¥ç¨‹é‡Œçš„ä¸€ä¸ª**å¹³è¡¡åŸåˆ™**ï¼š

> **criticéœ€è¦å°½å¿«å­¦å¾—æ¯” Actor ç¨³å®šä¸€ç‚¹ï¼Œå“ªæ€•å®ƒæœ‰ç‚¹â€œæŠ–â€ï¼Œä¹Ÿæ¯”æ…¢æ…¢å­¦è¦å¥½ã€‚**

- åœ¨ PPOè®­ç»ƒæ—©æœŸï¼Œ**Actor å¾ˆä¾èµ–criticæä¾›çš„ Advantageï¼ˆVå€¼ï¼‰**ï¼›
- å¦‚æœcriticå­¦å¾—å¤ªæ…¢ï¼ŒV ä¼°è®¡å§‹ç»ˆä¸å‡†ï¼ŒActor å¾—ä¸åˆ°æœ‰æ•ˆæŒ‡å¯¼ â†’ PPOæ›´æ–°å®¹æ˜“éœ‡è¡ï¼›
- æ‰€ä»¥æˆ‘ä»¬é€šå¸¸ç»™criticä¸€ä¸ª **ç›¸å¯¹æ›´å¿«çš„èµ·æ­¥**ï¼Œæ¯”å¦‚å­¦ä¹ ç‡`1e-3`ï¼Œè€Œ Actor æ˜¯`3e-4`ã€‚

è¿™å°±æ˜¯æ‰€è°“çš„ï¼š

> **â€œå¿«ç‚¹å­¦èµ·æ¥ï¼Œæ¯”æ…¢æ…¢æŠ–ç€èµ°æ›´å¥½â€**

å½“ç„¶ï¼Œè¿™ç§â€œå¿«â€å¿…é¡»**å—æ§**ï¼Œæ‰€ä»¥æ‰ä¼šé…åˆï¼š

- `eps=1e-5`æ¥é¿å…æ•°å€¼ä¸ç¨³å®šï¼›
- åŠ å…¥æ¢¯åº¦è£å‰ªï¼›
- åŠ æƒ lossï¼›
- æœ‰æ—¶å€™è¿˜ä¼šåªè®­ç»ƒcriticè‹¥å¹²æ­¥ï¼Œå†æ›´æ–° actorã€‚

ï¼ˆ2ï¼‰é‚£ä¸ºå•¥è¿˜è¯´â€œcriticä¸ç¨³å®šå°±è°ƒå° lrâ€ï¼Ÿ

è¿™ä¸æ˜¯çŸ›ç›¾ï¼Œè€Œæ˜¯ **ä¸€ç§åº”æ€¥æ–¹æ¡ˆ**ï¼Œæ˜¯ **åŠ¨æ€è°ƒæ•´æ‰‹æ®µ**ã€‚

åˆå§‹ç­–ç•¥ï¼š

> **å…ˆå°è¯•â€œæ¿€è¿›ç‚¹â€è®©criticå…ˆå¿«é€Ÿæ”¶æ•›ä¸€ç‚¹ â†’ å¼•å¯¼ Actor å­¦ä¹ **

å¦‚æœå¤±è´¥äº†å‘¢ï¼Ÿ

- å¦‚æœä½ è§‚å¯Ÿåˆ°ï¼š
  - V å€¼å‰§çƒˆéœ‡è¡
  - loss çˆ†ç‚¸
  - ç­–ç•¥ collapse
- é‚£è¯´æ˜ï¼š**ä½ è¿™ä¸ªcriticå¤ªâ€œèºâ€äº†ï¼ŒçœŸçš„ä¸ç¨³å®š**
- é‚£å°±**å‡å°å®ƒçš„å­¦ä¹ ç‡**ï¼Œé™åˆ°`5e-4`æˆ–`3e-4`ï¼Œç”šè‡³æ›´ä½

è¿™å°±æ˜¯å¼ºåŒ–å­¦ä¹ é‡Œä¸€ä¸ªå¸¸è§çš„ç­–ç•¥ï¼š

> **â€œå…ˆå¤§èƒ†è¯•ï¼Œå†çœ‹åé¦ˆè°ƒâ€**ï¼Œå› ä¸ºè¿‡äºä¿å®ˆæœ‰æ—¶åè€Œå­¦ä¸åŠ¨

æœ€åä¸€å¥è¯æ€»ç»“ï¼š

> **å¼ºåŒ–å­¦ä¹ é‡Œï¼Œcriticçš„å­¦ä¹ ç‡è®¾ç½®ï¼Œèµ°çš„æ˜¯â€œå¿«æ”¶æ•›ä¼˜å…ˆï¼Œä½†ç¨³ä¸ä½å°±æ”¶æ•›æ…¢â€çš„åŠ¨æ€ç­–ç•¥ï¼Œè€Œä¸æ˜¯ç»å¯¹çš„â€œå¿«å°±æ˜¯å¯¹ or æ…¢å°±æ˜¯å¯¹â€ã€‚**

è¿™ç§â€œå…ˆå¿«ã€å†æ ¹æ®ç¨³å®šæ€§è°ƒèŠ‚â€çš„è®¾è®¡æ€è·¯ï¼Œåœ¨å¾ˆå¤šRLæ¡†æ¶é‡Œéƒ½æœ‰ä½“ç°ã€‚

## ä¼˜åŒ–å™¨

### åˆ†å±‚ä¼˜åŒ–å™¨

å¯ä»¥åˆ†ä¸åŒçš„æ¨¡å‹éƒ¨åˆ†æ¥ä¼˜åŒ–ï¼š

```python
from torch.optim import Adam

optimizer = Adam([
    {
        "params": model.shared.parameters(),
        "lr": 6.5e-4,
        "eps": 1e-5  # æ¯”å¦‚å…±äº«å±‚ç”¨é»˜è®¤å€¼
    },
    {
        "params": model.actor_head.parameters(),
        "lr": 3e-4,
        "eps": 1e-8  # actoræ›´ç²¾ç»†ä¸€ç‚¹
    },
    {
        "params": model.critic_head.parameters(),
        "lr": 1e-3,
        "eps": 1e-6  #criticç¨³å®šä¸€ç‚¹
    }
])
```

### adamä¼˜åŒ–å™¨ä¸­epsçš„è®¾å®š

`eps`æ˜¯ä¸ºäº†æ•°å€¼ç¨³å®šæ€§ï¼ˆç‰¹åˆ«æ˜¯åœ¨é™¤ä»¥æ¢¯åº¦å¹³æ–¹çš„RMSæ—¶ï¼‰ï¼Œä¸€èˆ¬åœ¨`1e-5`ï½`1e-8`ä¹‹é—´é€‰ã€‚

`Adam`çš„é»˜è®¤æ˜¯`eps=1e-8`ï¼Œæœ‰äº›åº“ï¼ˆæ¯”å¦‚`Stable-Baselines3`ï¼‰ä¼šç”¨`1e-5`æ¥åŠ é€Ÿcriticçš„æ”¶æ•›ã€‚è¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿè¿™ä¸ªé—®é¢˜å…¶å®æŒºæœ‰æ„æ€çš„ï¼Œæ¶‰åŠåˆ° **Adamçš„å†…éƒ¨æœºåˆ¶** å’Œ **criticçš„æ•°å€¼ç¨³å®šæ€§éœ€æ±‚**ã€‚ä¸‹é¢æˆ‘ç»™ä½ è¯¦ç»†è§£é‡Šä¸‹ï¼š

**ï¼ˆ1ï¼‰Adamä¸­çš„`eps`æ˜¯ä»€ä¹ˆï¼Ÿ**

Adamä¼˜åŒ–å™¨çš„æ›´æ–°å…¬å¼å¤§è‡´å¦‚ä¸‹ï¼š
$$
\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \cdot \hat{m}_t
$$
å…¶ä¸­ï¼š

- $\alphaÎ±$ï¼šå­¦ä¹ ç‡ï¼ˆ`lr`ï¼‰
- $\hat{m}_t$ï¼šä¸€é˜¶çŸ©ä¼°è®¡ï¼ˆåŠ¨é‡ï¼‰
- $\hat{v}_t$ï¼šäºŒé˜¶çŸ©ä¼°è®¡ï¼ˆæ¢¯åº¦çš„å¹³æ–¹ï¼‰
- $\epsilon$ï¼šä¸€ä¸ªå°çš„å¸¸æ•°ï¼Œç”¨äºé˜²æ­¢é™¤ä»¥ 0ï¼ˆä¹Ÿå°±æ˜¯è¿™ä¸ª`eps`ï¼‰

**ï¼ˆ2ï¼‰`eps`è¶Šå¤§ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ**

- **é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸æˆ–ä¸ç¨³å®šï¼š**
   å¦‚æœ$\hat{v}_t$å¤ªå°ï¼ˆæ¯”å¦‚æ¢¯åº¦æœ¬èº«æ³¢åŠ¨å¾ˆå°ï¼‰ï¼Œé‚£ä¹ˆ$\frac{1}{\sqrt{\hat{v}_t} + \epsilon}$ä¼šå˜å¾—å¾ˆå¤§ï¼Œå¯¼è‡´æ›´æ–°è¿‡å¤§ï¼Œæ•°å€¼ä¸ç¨³å®šã€‚
- **`eps`è¶Šå¤§â†’åˆ†æ¯è¶Šå¤§â†’æ­¥é•¿ï¼ˆæ›´æ–°é‡ï¼‰è¶Šå°**
   æ‰€ä»¥å®ƒ**èµ·åˆ°æŠ‘åˆ¶æ›´æ–°å¹…åº¦ã€å¹³æ»‘è®­ç»ƒçš„ä½œç”¨**ã€‚

**ï¼ˆ3ï¼‰ä¸ºä»€ä¹ˆcriticæ›´é€‚åˆ`eps = 1e-5`ï¼Ÿ**

1. **criticçš„å€¼å‡½æ•°æ¯”è¾ƒæ•æ„Ÿï¼š**
   - å€¼å‡½æ•°åœ¨è®­ç»ƒåˆæœŸéœ‡è¡ç‰¹åˆ«å¤§ï¼Œå®¹æ˜“å¯¼è‡´æ¢¯åº¦å‰§çƒˆæ³¢åŠ¨ã€‚
   - ä¸€ä¸ªç¨å¾®å¤§çš„`eps`ï¼ˆæ¯”å¦‚`1e-5`ï¼‰å¯ä»¥è®©åˆ†æ¯æ›´ç¨³å®šï¼Œå‡å°æ›´æ–°å¹…åº¦ï¼Œ**æå‡æ•°å€¼ç¨³å®šæ€§**ã€‚
2. **æå‡early stageçš„æ”¶æ•›é€Ÿåº¦ï¼š**
   - å®é™…ä¸Šï¼Œ`1e-5`å¾€å¾€èƒ½è®©criticåœ¨å‰å‡ ä¸ªepochæ›´å¿«ä¸‹é™lossï¼Œå°¤å…¶æ˜¯åœ¨PPOè¿™ç§TDå­¦ä¹ åœºæ™¯ä¸­ã€‚
3. **å®è¯æ¥æºï¼š**
   - æ¯”å¦‚`Stable-Baselines3`ã€`CleanRL`ã€`rl-games`ç­‰å¼ºåŒ–å­¦ä¹ åº“ï¼Œcriticç»å¸¸ç”¨`eps=1e-5`ï¼Œè€Œ actor ç”¨é»˜è®¤çš„`1e-8`æˆ–ç•¥å¾®è°ƒå°çš„`1e-6`ã€‚
   - **ç»éªŒæ³•åˆ™ï¼šcriticæ›´ä¸ç¨³å®šâ†’ç»™å®ƒæ›´å¼ºçš„æ•°å€¼ä¿æŠ¤ã€‚**

**ï¼ˆ4ï¼‰æ€»ç»“**

| æ¨¡å—   | é€‚åˆçš„ eps | åŸå›                                     |
| ------ | ---------- | --------------------------------------- |
| actor  | `1e-8`     | è¿½æ±‚ç²¾ç»†æ›´æ–°ï¼Œå¯¹æ•°å€¼è¦æ±‚æ²¡é‚£ä¹ˆé«˜        |
| critic | `1e-5`     | TDè®­ç»ƒä¸ç¨³å®šï¼Œå™ªå£°å¤§ï¼Œ`eps`å¤§ä¸€ç‚¹æ›´ç¨³å®š |





# å‚è€ƒèµ„æ–™



- [æå®æ¯…æ·±åº¦å¼ºåŒ–å­¦ä¹ (å›½è¯­)è¯¾ç¨‹(2018) ç­–ç•¥æ¢¯åº¦](https://www.bilibili.com/video/BV1MW411w79n/)

- [æå®æ¯…æ·±åº¦å¼ºåŒ–å­¦ä¹ (å›½è¯­)è¯¾ç¨‹(2018) PPO](https://www.bilibili.com/video/BV1MW411w79n/?p=2)

"PPOåŸç†æ¨å¯¼"ä¸€èŠ‚çš„å†…å®¹æ¥è‡ªäºä¸Šè¿°ä¸¤ä¸ªè§†é¢‘ã€‚



===

[è¿‘ç«¯ç­–ç•¥ä¼˜åŒ– (PPO) ç®—æ³•æ·±åº¦è§£æ](https://zhuanlan.zhihu.com/p/27444364357)



[æ¸¸æˆAIæ¯”èµ›ç•ªå¤–ç¯‡2ï¼šä¸ºå•¥å¼ºåŒ–å­¦ä¹ åšæ¸¸æˆAIéƒ½å–œæ¬¢ç”¨PPOç®—æ³•ï¼Ÿ](https://zhuanlan.zhihu.com/p/550312933)

å¿…çœ‹ï¼Œå› ä¸ºè¿™ç¯‡æ–‡ç« ç›´è§‚ä»‹ç»äº†æŸå¤±å‡½æ•°ã€‚



ï¼ˆGeneralized Advantage Estimationï¼‰è®­ç»ƒæœ€ç¨³å®šï¼Œè°ƒå‚æœ€ç®€å•ï¼Œé€‚åˆé«˜ç»´çŠ¶æ€ High-dimensional stateï¼Œä½†æ˜¯ç¯å¢ƒä¸èƒ½æœ‰å¤ªå¤šéšæœºå› æ•°ã€‚GAEä¼šæ ¹æ®ç»éªŒè½¨è¿¹ trajectory ç”Ÿæˆä¼˜åŠ¿å‡½æ•°ä¼°è®¡å€¼ï¼Œç„¶åè®©Criticå»æ‹Ÿåˆè¿™ä¸ªå€¼ã€‚åœ¨è¿™æ ·çš„è°ƒæ•´ä¸‹ï¼Œåœ¨éšæœºå› ç´ å°çš„ç¯å¢ƒä¸­ï¼Œä¸éœ€è¦å¤ª

[mengwanglalala/**RL-algorithms**](https://github.com/mengwanglalala/RL-algorithms)



[è¿›é˜¶ç¯‡---PPOä»£ç é€è¡Œåˆ†æ](https://blog.csdn.net/qq_37395293/article/details/114254505)

A3Cåœ¨æ¯ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œéƒ½è¦é‡‡é›†Tä¸ªsamples(Tè¿œè¿œå°äºå›åˆé•¿åº¦)ï¼Œè®¡ç®—Tä¸ªn-step returnï¼Œç„¶åä½¿ç”¨è¿™Tä¸ªæ•°æ®æ›´æ–°è¯„ä»·ç½‘ç»œï¼š

PPOä¹Ÿä½¿ç”¨äº†ç›¸åŒçš„æ€è·¯ï¼Œä½†æ˜¯ä½¿ç”¨GAEå®ç°



===



* [PPOç®—æ³•ç»å…¸è®ºæ–‡é˜…è¯»](https://blog.csdn.net/shengzimao/article/details/126493407)

* [æ·±åº¦å¢å¼ºå­¦ä¹ PPOï¼ˆProximal Policy Optimizationï¼‰ç®—æ³•æºç èµ°è¯»](https://blog.csdn.net/jinzhuojun/article/details/80417179)



* [PPOå¼ºåŒ–å­¦ä¹ å¦‚ä½•å®ç°å¤šç»´åº¦çš„åŠ¨ä½œå‘¢ï¼Ÿ](https://www.zhihu.com/question/417161289/answer/2207316616)

ä¸ªäººè§‰å¾—ç”¨å¾—æ¯”è¾ƒå¤šçš„æ˜¯è¾“å‡º5ä¸ªå‡å€¼å’Œæ–¹å·®ï¼Œå†ä»è¿™5ä¸ªåˆ†å¸ƒä¸­ï¼Œé‡‡æ ·5ä¸ªå€¼ã€‚

è¿™é‡Œç»™ä½ é™„ä¸Šä¸€ä¸ªPytorchå®ç°PPOçš„ä»£ç ï¼Œå¯¹å¤šç»´è¿ç»­ç©ºé—´è¿›è¡Œäº†è¯¦ç»†çš„å®ç°ï¼Œä»£ç ä¹Ÿæ¯”è¾ƒç®€æ´ç¨³å®šï¼š

[https://github.com/XinJingHao/PPO-Continuous-Pytorch](https://github.com/XinJingHao/PPO-Continuous-Pytorch)

è¯·é—®å¦‚æœactionæ˜¯5ç»´ï¼Œå¹¶ä¸”æ¯ä¸€ç»´æ˜¯0,1,2,3,4è¿™æ ·çš„ç¦»æ•£çš„æ•°ï¼Œè¿™ç§æƒ…å†µåº”è¯¥æ€ä¹ˆå¤„ç†å‘¢ï¼Ÿ

ä¹Ÿå¯ä»¥ä½œä¸ºindependent action ï¼ˆè§Section V subsection A [arxiv.org/pdf/2105.1380](http://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2105.13807.pdf)ï¼‰ï¼Œä»£ç å¯è§ [github.com/vwxyzjn/PPO-](http://link.zhihu.com/?target=https%3A//github.com/vwxyzjn/PPO-Implementation-Deep-Dive/blob/lstm-and-multidiscrete/ppo_multidiscrete.py)ã€‚ä¸€èˆ¬å¦‚æœä½ çš„ç¦»æ•£åŠ¨ä½œç©ºé—´æœ‰å¾ˆå¤šç»´åº¦ï¼Œå¯èƒ½ä¼šæœ‰æ— æ•ˆåŠ¨ä½œï¼Œè¿™æ—¶å€™invalid action masking å¾ˆé‡è¦ï¼Œè§[arxiv.org/abs/2006.1417](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/2006.14171), ä»£ç å¯è§ [github.com/vwxyzjn/PPO-Implementation-Deep-Dive](http://link.zhihu.com/?target=https%3A//github.com/vwxyzjn/PPO-Implementation-Deep-Dive/blob/lstm-and-multidiscrete/ppo_multidiscrete_mask.py)ã€‚









* [å¦‚ä½•ç†è§£çœ‹å¾… OpenAI å…¬å¸ƒPPOç®—æ³•ï¼Ÿ è«å‡¡](https://www.zhihu.com/question/63067895/answer/214180615)

æˆ‘ä¹Ÿå®è·µäº†ä¸€ä¸‹ Pythonçš„ç®€å• PPOç®—æ³•. æ¯•ç«Ÿ OpenAI å¼€æºçš„é‚£ä¸ª [baselines](https://link.zhihu.com/?target=https%3A//github.com/openai/baselines) å¤ªå¤æ‚äº†, çœ‹åŠå¤©æºç ä¹Ÿçœ‹ä¸æ‡‚. æ‰€ä»¥ä¸‹å®šå†³å¿ƒè‡ªå·±å†™ä¸€ä¸ªæ¯”ä»–ä»¬çš„ç®€å•å¥½å¤šå€çš„ä»£ç . è‡ªå·±å†™çš„æ•™ç¨‹åœ¨è¿™é‡Œ: [ç»“åˆäº† OpenAI å’Œ DeepMindçš„ PPO](https://link.zhihu.com/?target=https%3A//mofanpy.com/tutorials/machine-learning/reinforcement-learning/6-4-DPPO/)ã€‚é¢ï¼Œå‰é¢è¿™ä¸ªåœ°å€æ‰“ä¸å¼€äº†ï¼Œç›´æ¥çœ‹è¿™ä¸ªï¼š[Distributed Proximal Policy Optimization (DPPO)](https://mofanpy.com/tutorials/machine-learning/reinforcement-learning/DPPO)ï¼Œæ—¢å¯ä»¥çœ‹ä»£ç ï¼Œä¹Ÿå¯ä»¥çœ‹ç¯å¢ƒæºç ã€‚ç‰¹åˆ«æ¨èã€‚

ç®€è¿°ä¸€ä¸‹è‡ªå·±å†™ä»£ç çš„æ„Ÿæƒ³. OpenAIçš„ PPOæ„Ÿè§‰æ˜¯ä¸ªä¸²è¡Œçš„ï¼ˆè¦ç­‰æ‰€æœ‰å¹¶è¡Œçš„ Actor æå®Œæ‰æ›´æ–°æ¨¡å‹ï¼‰, DeepMindçš„ DPPOæ˜¯å¹¶è¡Œçš„ï¼ˆä¸ç”¨ç­‰å…¨éƒ¨ workerï¼‰, ä½†æ˜¯ä»£ç å®è·µèµ·æ¥æ¯”è¾ƒå›°éš¾, éœ€è¦æ¨é€ä¸åŒ workerçš„ [gradient](https://www.zhihu.com/search?q=gradient&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A214180615}). æˆ‘å–äº† OpenAI å’Œ DeepMind ä¸¤è€…çš„ç²¾å. ç”¨ OpenAI ä¸­æ€§èƒ½æœ€å¥½çš„ Policy æ›´æ–°ç­–ç•¥ (clipped surrogate) + DeepMind [parallel training](https://www.zhihu.com/search?q=parallel+training&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A214180615}) (ä½†ä¸æ˜¯æ¨é€ gradient, åªæ˜¯æ¨é€ collected data). è®©åŸæœ¬[å•çº¿ç¨‹](https://www.zhihu.com/search?q=å•çº¿ç¨‹&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A214180615})çš„ PPOé€Ÿåº¦é£èµ·æ¥äº†.

ä½ ç¡®å®šä½ çœ‹è¿‡OpenAI PPOçš„åŸæ–‡ï¼ŒåŸæ–‡ä¸­ç®—æ³•å°±æ˜¯æœ‰Nä¸ªActorå¹¶è¡Œè®­ç»ƒçš„ï¼



* [å½±å“PPOç®—æ³•æ€§èƒ½çš„10ä¸ªå…³é”®æŠ€å·§ï¼ˆé™„PPOç®—æ³•ç®€æ´Pytorchå®ç°ï¼‰](https://zhuanlan.zhihu.com/p/512327050)

å…·ä½“ä»£ç è§ï¼š[https://github.com/Lizhi-sjtu/DRL-code-pytorch](https://github.com/Lizhi-sjtu/DRL-code-pytorch)



* [å¼ºåŒ–å­¦ä¹ ç¬”è®°ï¼ˆäº”ï¼‰--PPO](https://zhuanlan.zhihu.com/p/48293363)

2017å¹´7æœˆ20æ—¥ï¼ŒOpenAI åˆšåˆšé€šè¿‡è‡ªå·±çš„ç ”ç©¶åšå®¢ä»‹ç»äº†ä¸€ç§æ–°çš„ä¼˜åŒ–ç®—æ³• Proximal Policy Optimizationï¼ˆè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ŒPPOï¼‰ã€‚æ®ä»‹ç»ï¼Œè¿™ç§ç®—æ³•ç”¨åœ¨å¼ºåŒ–å­¦ä¹ ä¸­æ—¶è¡¨ç°èƒ½è¾¾åˆ°ç”šè‡³è¶…è¿‡ç°æœ‰ç®—æ³•çš„é¡¶å°–æ°´å¹³ï¼ŒåŒæ—¶è¿˜æ›´æ˜“äºå®ç°å’Œè°ƒè¯•ã€‚æ‰€ä»¥ OpenAI å·²ç»æŠŠPPOä½œä¸ºè‡ªå·±å¼ºåŒ–å­¦ä¹ ç ”ç©¶ä¸­é¦–é€‰çš„ç®—æ³•ã€‚

ä¹‹å‰ OpenAI å°±è¯¦ç»†ä»‹ç»è¿‡ PPOçš„ä¸€ä¸ªå˜ç§ ï¼ˆ[NIPS 2016 è®ºæ–‡è§†é¢‘ï¼šé€šè¿‡ç­–ç•¥ä¼˜åŒ–è¿›è¡Œæ·±åº¦å¼ºåŒ–å­¦ä¹ ](https://link.zhihu.com/?target=https%3A//channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Deep-Reinforcement-Learning-Through-Policy-Optimization)ï¼‰ï¼Œå…¶ä¸­ç”¨ä¸€ä¸ªè‡ªé€‚åº” Kullbackâ€“Leibler æƒ©ç½šé¡¹æ§åˆ¶æ¯æ¬¡è¿­ä»£ä¸­çš„ç­–ç•¥å˜åŒ–ç¨‹åº¦ã€‚ç°åœ¨ä»‹ç»çš„è¿™ç§æ–°å˜ç§åˆ™ä½¿ç”¨äº†ä¸€ç§å…¶å®ƒç®—æ³•ä¸­ç½•è§çš„å…¨æ–°çš„ç›®æ ‡å‡½æ•°ï¼š

PPO2ï¼šä¸ç”¨è®¡ç®—KLï¼ŒåŒæ ·å¯ä»¥æ§åˆ¶Î¸ä¸Î¸'ä¹‹é—´å·®è·ã€‚

è¯´æ˜ï¼šå½“A>0ï¼Œä¹Ÿå°±æ˜¯aæ˜¯å¥½çš„ï¼Œæˆ‘ä»¬å¸Œæœ›å¢åŠ PÎ¸çš„æ¦‚ç‡ï¼Œä½†æ˜¯ï¼ŒPÎ¸ä¸èƒ½å¼„å¾—å¤ªå¤§ï¼Œå¤ªå¤§ä¹Ÿå°±ä¼šä½¿ä¸PÎ¸'å·®è·å¤§ï¼Œå¯¼è‡´æ•ˆæœä¸å¥½ã€‚åä¹‹äº¦ç„¶ã€‚



* [å¼ºåŒ–å­¦ä¹ ä¹‹PPOç®—æ³•](https://zhuanlan.zhihu.com/p/468828804)

å†™çš„ä¸é”™ï¼Œå‚è€ƒäº†ä¸‹é¢ä¸¤ä¸ªæ–‡ç« ã€‚

* [æå®æ¯…æ·±åº¦å¼ºåŒ–å­¦ä¹ (å›½è¯­)è¯¾ç¨‹(2018) ppo](https://www.bilibili.com/video/BV1MW411w79n?p=2&vd_source=147fb813418c7610c21b6a5618c85cb7)

  è¿˜æœ‰å¯¹åº”çš„è¯¾ä»¶ï¼š[æå®æ¯…æ·±åº¦å¼ºåŒ–å­¦ä¹ (å›½è¯­)è¯¾ç¨‹(2018) PPOè¯¾ä»¶](https://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2018/Lecture/PPO%20(v3).pdf)ã€‚

* [Proximal Policy Optimization(PPO)ç®—æ³•åŸç†åŠå®ç°ï¼ ç¾å›¢æ–‡å“¥çš„ç¬”è®°](https://www.jianshu.com/p/9f113adc0c50)



[The 37 Implementation Details of Proximal Policy Optimization](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/)

å¯¹åº”çš„ä¸­æ–‡ç¿»è¯‘ï¼š[ä¼˜åŒ–PPO](https://blog.csdn.net/CharilePuth/article/details/125555567)



[ã€å¼ºåŒ–å­¦ä¹ 8ã€‘PPO](https://zhuanlan.zhihu.com/p/128484325)

å‚è€ƒæ–‡çŒ®ï¼š

[1] TRPO: Schulman, John, et al. â€œTrust Region Policy Optimization.â€*ArXiv Preprint ArXiv:1502.05477*, 2015.

[2] DPPO: Heess, Nicolas, et al. â€œEmergence of Locomotion Behaviours in Rich Environments.â€*ArXiv Preprint ArXiv:1707.02286*, 2017.

[3] PPO: Schulman, John, et al. â€œProximal Policy Optimization Algorithms.â€*ArXiv Preprint ArXiv:1707.06347*, 2017.

[4] batchPPO: Hafner, D. , Davidson, J. , & Vanhoucke, V. . (2017). Tensorflow agents: efficient batched reinforcement learning in tensorflow.

[5] Implementation Matters in Deep Policy Gradients: a Case Study on PPOand TRPO.

å…³äºç”¨bootstrapæ³•ä¼°è®¡advantageå’Œstate valueå‡½æ•°çš„å†…å®¹ï¼Œå¯å‚è§â€œã€CS285ç¬¬6è®²ã€‘Actor-criticâ€ã€‚

## å¤§æ¨¡å‹

å…·ä½“çš„è¯¦ç»†æ¨å¯¼çœ‹è¿™é‡Œï¼š

è¿™æ˜¯æœ€æ–°çš„è®¨è®ºï¼Œä¸­é—´æœ‰äº‹å°±åœæ­¢è®¨è®ºäº†ï¼šhttps://chatgpt.com/c/694cf28f-51d4-8322-851c-33f0200fec0fï¼Œæ³¨æ„æœ€åä¸€éƒ¨åˆ†æ˜¯å¥–åŠ±è®¨è®ºï¼Œä½ å¾—å¾€å‰ä¸€äº›çœ‹ã€‚

https://chat.deepseek.com/a/chat/s/7e0e3349-998f-427b-9d09-b3f18c800e6a