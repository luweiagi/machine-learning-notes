# ONNX

- [è¿”å›ä¸Šå±‚ç›®å½•](../model-deployment-practice.md)
- [æ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼](#æ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼)
- [æ¨¡å‹æ¨ç†](#æ¨¡å‹æ¨ç†)
  - [Pythonç«¯æ¨ç†](#Pythonç«¯æ¨ç†)
  - [C++ç«¯CPUæ¨ç†](#C++ç«¯CPUæ¨ç†)



# æ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼

å†™ä¸€ä¸ªåŒ…è£…æ¨¡å‹ç±»ï¼ŒæŠŠ `act()` å˜æˆ `forward()`

```python
class ModelWrapper(nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model

    def forward(self, x):
        return self.model.act(x)  # æ³¨æ„è¿™é‡Œæ˜¯è°ƒç”¨ act è€Œä¸æ˜¯ forward
```

ç„¶åè¿™æ ·å¯¼å‡ºï¼š

```python
model = Module()
model.eval()
wrapped_model = ModelWrapper(model)

dummy_input = torch.randn(1, 5)
torch.onnx.export(model, dummy_input, "model.onnx",
                  input_names=["input"], output_names=["a1", "a2", "param"],
                  opset_version=11,
                  dynamic_axes={  # åŠ ä¸Šè¿™ä¸ªå°±ä¼šå˜ä¸ºbatch_sizeå˜ä¸ºåŠ¨æ€çš„
                      "input": {0: "batch_size"},  # è®©ç¬¬0ç»´ï¼ˆbatchï¼‰æ˜¯åŠ¨æ€çš„
                      "a1": {0: "batch_size"},
                      "a2": {0: "batch_size"},
                      "param": {0: "batch_size"}
                  })
```

å¦‚ä½•æŸ¥çœ‹ ONNX æ¨¡å‹çš„è¾“å‡ºåå­—ï¼Ÿ

ä½ å¯ä»¥ç”¨ Python è„šæœ¬å¿«é€ŸæŸ¥çœ‹ï¼š

```python
import onnx

model = onnx.load("your_model.onnx")
for output in model.graph.output:
    print(output.name)
```

# æ¨¡å‹æ¨ç†

## Pythonç«¯æ¨ç†

```python
ort_session = ort.InferenceSession("model.onnx")
input_tensor = np.random.randn(2, 5).astype(np.float32)
outputs = ort_session.run(None, {"input": input_tensor})
print(outputs)
# [array([2, 2], dtype=int64),
#  array([1, 1], dtype=int64),
#  array([[-0.09347501, 0.10457519, 0.09422486, -0.24867839],
#         [-0.09440675, 0.10584655, 0.08844154, -0.24860077]], dtype=float32)
# ]
a1, a2, param = outputs
print(a1)
# [2 2]
print(a2)
# [1 1]
print(param)
# [[-0.09347501  0.10457519  0.09422486 -0.24867839]
#  [-0.09440675  0.10584655  0.08844154 -0.24860077]]
```

## C++ç«¯CPUæ¨ç†

ä½¿ç”¨ ONNX Runtime C++ APIï¼ˆCPUï¼‰

### ä¸‹è½½ONNX-Runtime-C++é¢„ç¼–è¯‘åŒ…

ä½ å¯ä»¥ä»å®˜æ–¹å‘å¸ƒé¡µä¸‹è½½ C++ é™æ€/åŠ¨æ€åº“ï¼š

- å®˜æ–¹ Release é¡µï¼š[onnxruntime](https://github.com/microsoft/onnxruntime/releases)

é€‰æ‹©ä¸€ä¸ªé€‚åˆä½ å¹³å°çš„åŒ…ï¼Œä¾‹å¦‚ï¼š

```shell
onnxruntime-linux-x64-<version>.tgz
```

ä½ å¯ä»¥åœ¨ Linux ä¸­ä½¿ç”¨ `tar` å‘½ä»¤æ¥è§£å‹ç¼©è¿™ä¸ª `.tgz` æ–‡ä»¶ã€‚`.tgz` æ˜¯ `.tar.gz` çš„ç¼©å†™å½¢å¼ï¼Œè¡¨ç¤ºç»è¿‡ tar æ‰“åŒ…ååˆç”¨ gzip å‹ç¼©çš„æ–‡ä»¶ã€‚

```shell
tar -xzf onnxruntime-linux-x64-1.22.0.tgz
```

è§£å‹åï¼Œä¼šçœ‹åˆ°ï¼š

```makefile
include/        # C++ å¤´æ–‡ä»¶
lib/            # é™æ€åº“æˆ–åŠ¨æ€åº“
bin/            # å·¥å…·
```

å¦‚æœæ˜¯åœ¨windowsä¸‹ï¼Œå¯èƒ½æœ€æ–°çš„releaseç‰ˆæœ¬é‡Œä¸åŒ…å«win-x64çš„ç‰ˆæœ¬ï¼Œéœ€è¦åœ¨æ²¡é‚£ä¹ˆæœ€æ–°çš„ç‰ˆæœ¬é‡Œæ‰¾ï¼Œæ¯”å¦‚ï¼š

[ONNX Runtime v1.20.1](https://github.com/microsoft/onnxruntime/releases/tag/v1.20.1) ä¸­çš„ `onnxruntime-win-x64-1.20.1.zip`

### é¡¹ç›®ç›®å½•ç»“æ„

```shell
your_project/
â”œâ”€â”€ onnxruntime-linux-x64-1.22.0/  # è§£å‹åçš„ ONNX Runtime æ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ include/
â”‚   â””â”€â”€ lib/
â”œâ”€â”€ source
â”‚   â””â”€â”€ main.cpp                   # ä½ çš„ä¸»ç¨‹åº
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.onnx                 # ä½ çš„æ¨¡å‹æ–‡ä»¶
â””â”€â”€ CMakeLists.txt                 # æ„å»ºæ–‡ä»¶ï¼ˆæˆ– Makefileï¼‰
â”‚
â””â”€â”€ build/                         # ä¸­é—´äº§ç‰©
â”‚   â”œâ”€â”€ Makefile
â”‚   â””â”€â”€ CMakeCache.txt
â”‚   â””â”€â”€ CMakeFiles/
â”‚   â””â”€â”€ main                       # å¦‚æœä½ æœ€ç»ˆç¼–è¯‘çš„ç¨‹åºåå«main
â”‚   â””â”€â”€ bin/
â”‚       â””â”€â”€ infer                  # å¯æ‰§è¡Œç¨‹åºï¼Œç°åœ¨è¢«æ”¾åˆ°äº†bin/å­ç›®å½•ä¸­
```

### ç¼–å†™ C++ æ¨ç†ä»£ç 

ä¸‹é¢æ˜¯å®Œæ•´ C++ ONNX Runtime æ¨ç†ä»£ç ç¤ºä¾‹ï¼Œ**é€‚é…ä½ çš„æ¨¡å‹è¾“å…¥ä¸º float32[batch_size, 5]ï¼Œè¾“å‡ºä¸ºä¸‰ä¸ªå¼ é‡**ï¼š

- `"a1"`ï¼š`int64[batch_size]`
- `"a2"`ï¼š`int64[batch_size]`
- `"param"`ï¼š`float32[batch_size, 4]`

```c++
int main1() {
    // è®¾ç½®æ¨¡å‹è·¯å¾„
    const char* model_path = "model.onnx";

    // åˆ›å»º ONNX Runtime ç¯å¢ƒ
    Ort::Env env(ORT_LOGGING_LEVEL_WARNING, "infer");

    // Session é€‰é¡¹
    Ort::SessionOptions session_options;
    session_options.SetIntraOpNumThreads(4);  // å¤šçº¿ç¨‹æ¨ç†
    session_options.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_ALL);

    // åˆ›å»º Session
    Ort::Session session(env, model_path, session_options);

    // è¾“å…¥ä¿¡æ¯
    const char* input_name = "input";
    size_t batch_size = 1;
    std::vector<float> input_tensor_values(batch_size * 5, 1.0f);  // æ¯ä¸ªæ ·æœ¬5ç»´ï¼Œbatchä¸ªæ ·æœ¬
    std::vector<int64_t> input_dims = {static_cast<int64_t>(batch_size), 5};

    // åˆ›å»ºè¾“å…¥å¼ é‡
    Ort::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(OrtDeviceAllocator, OrtMemTypeCPU);
    Ort::Value input_tensor = Ort::Value::CreateTensor<float>(
        memory_info, input_tensor_values.data(), input_tensor_values.size(),
        input_dims.data(), input_dims.size());

    // è¾“å‡ºä¿¡æ¯
    std::vector<const char*> output_names = {
        "a1",
        "a2",
        "param"
    };

    // æ¨ç†
    auto output_tensors = session.Run(
        Ort::RunOptions{nullptr},
        &input_name, &input_tensor, 1,
        output_names.data(), output_names.size()
    );

    // è§£æè¾“å‡º
    // 1. a1: int64[batch_size]
    int64_t* a1 = output_tensors[0].GetTensorMutableData<int64_t>();
    std::cout << "a1: ";
    for (size_t i = 0; i < batch_size; ++i) {
        std::cout << a1[i] << " ";
    }
    std::cout << std::endl;

    // 2. a2: int64[batch_size]
    int64_t* a2 = output_tensors[1].GetTensorMutableData<int64_t>();
    std::cout << "a2: ";
    for (size_t i = 0; i < batch_size; ++i) {
        std::cout << a2[i] << " ";
    }
    std::cout << std::endl;

    // 3. param: float32[batch_size, 4]
    float* param_mean = output_tensors[2].GetTensorMutableData<float>();
    std::cout << "param: " << std::endl;
    for (size_t i = 0; i < batch_size; ++i) {
        std::cout << "  [";
        for (size_t j = 0; j < 4; ++j) {
            std::cout << param_mean[i * 4 + j];
            if (j < 3) std::cout << ", ";
        }
        std::cout << "]" << std::endl;
    }

    return 0;
}
```

#### å¤šçº¿ç¨‹æ¨ç†

å¦‚æœä½ æƒ³ç”¨å¤šçº¿ç¨‹æ¨ç†ï¼Œå¯ä»¥ç”¨`session_options.SetIntraOpNumThreads(n)`ã€‚

`session_options.SetIntraOpNumThreads(n)` æ˜¯ä»€ä¹ˆï¼Ÿ

è¿™æ˜¯ ONNX Runtime çš„ä¸€ä¸ª **çº¿ç¨‹æ§åˆ¶æ¥å£**ï¼Œç”¨äºæ§åˆ¶**å•ä¸ªæ“ä½œç¬¦ï¼ˆOPï¼‰å†…éƒ¨çš„å¹¶è¡Œçº¿ç¨‹æ•°**ï¼Œä¹Ÿå« **intra-op parallelism**ï¼ˆæ“ä½œå†…å¹¶è¡Œåº¦ï¼‰ã€‚

ğŸŒ± ä¸¾ä¸ªä¾‹å­æ›´å¥½ç†è§£ï¼š

æ¯”å¦‚æ¨¡å‹ä¸­æœ‰ä¸€ä¸ª `MatMul`ï¼ˆçŸ©é˜µä¹˜æ³•ï¼‰æ“ä½œï¼Œå®ƒæœ¬èº«æ˜¯å¯ä»¥å¹¶è¡Œæ‰§è¡Œçš„ï¼š

```
[MatMul]
   â””â”€â”€-> åœ¨ä¸€ä¸ªå¤§çŸ©é˜µé‡Œåˆ†å—åšå¹¶è¡Œè®¡ç®—
```

å½“ä½ è®¾ç½®ï¼š

```c++
session_options.SetIntraOpNumThreads(4);
```

æ„æ€æ˜¯ï¼šONNX Runtime åœ¨æ‰§è¡Œ **ä¸€ä¸ªæ“ä½œï¼ˆå¦‚ MatMulï¼‰æ—¶å¯ä»¥åŒæ—¶ç”¨ 4 ä¸ªçº¿ç¨‹** æ¥åŠ é€Ÿå®ƒã€‚

âš™ï¸ å’Œ `SetInterOpNumThreads` çš„åŒºåˆ«ï¼Ÿ

| æ¥å£å                    | å«ä¹‰                         | æ§åˆ¶èŒƒå›´               |
| ------------------------- | ---------------------------- | ---------------------- |
| `SetIntraOpNumThreads(n)` | ä¸€ä¸ª OP å†…éƒ¨èƒ½ç”¨å¤šå°‘çº¿ç¨‹     | æ§åˆ¶å•ä¸ªæ“ä½œçš„å¹¶è¡Œæ€§   |
| `SetInterOpNumThreads(n)` | å¤šä¸ª OP æ˜¯å¦å¯ä»¥åŒæ—¶å¹¶å‘æ‰§è¡Œ | æ§åˆ¶æ“ä½œä¹‹é—´çš„å¹¶è¡Œæ‰§è¡Œ |

ä½ å½“å‰çš„æ¨¡å‹ï¼Œå¦‚æœæ˜¯å…¸å‹çš„æ¨ç†æ¨¡å‹ï¼ˆéè®¡ç®—å›¾éå¸¸å¤æ‚çš„é‚£ç§ï¼‰ï¼Œ**é‡ç‚¹åœ¨äº SetIntraOpNumThreads**ã€‚

ğŸ§  è®¾ç½®å¤šå°‘åˆé€‚ï¼Ÿ

| åœºæ™¯                   | æ¨èè®¾ç½®                   |
| ---------------------- | -------------------------- |
| CPU æ ¸å¿ƒæ•°ä¸º 4         | `SetIntraOpNumThreads(4)`  |
| ä½ è¦æ‰¹é‡æ¨ç†å¤šä¸ªæ ·æœ¬   | å¯ä»¥é€‚åº¦æå‡çº¿ç¨‹æ•°æé«˜åå |
| å•ä¸ªçº¿ç¨‹å¤Ÿå¿«ã€èµ„æºç´§å¼  | è®¾ç½®ä¸º 1ï¼Œé¿å…èµ„æºç«äº‰     |

> âš ï¸ æ³¨æ„ï¼šå¦‚æœä½ è‡ªå·±å†™å¤šçº¿ç¨‹è°ƒç”¨ ONNX æ¨ç†ï¼ˆæ¯”å¦‚å¤šçº¿ç¨‹å¹¶å‘ Session.Runï¼‰ï¼Œé‚£æœ€å¥½æŠŠ `SetIntraOpNumThreads` è®¾å°ä¸€ç‚¹ï¼Œé¿å…çº¿ç¨‹å¤ªå¤šæ‰“æ¶ã€‚

### æ„å»ºCMakeListsç¼–è¯‘

ç¤ºä¾‹ `CMakeLists.txt`

```cmake
cmake_minimum_required(VERSION 3.10)
project(onnx_cpp_infer)

set(CMAKE_CXX_STANDARD 14)

# è®¾ç½®å¯æ‰§è¡Œæ–‡ä»¶è¾“å‡ºè·¯å¾„ï¼ˆæ”¾åœ¨ add_executable ä¹‹å‰ï¼‰
set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)
# è®¾ç½® ONNX Runtime å®‰è£…è·¯å¾„
set(ORT_DIR "./onnxruntime-linux-x64-1.22.0")
# å¦‚æœ ORT_DIR æ˜¯ç›¸å¯¹è·¯å¾„ï¼ŒCMake åœ¨æŸäº›å¹³å°
# ï¼ˆå°¤å…¶æ˜¯ macOS æˆ–ä½¿ç”¨ install å‘½ä»¤æ—¶ï¼‰è§£æ RPATH æ—¶å¯èƒ½å¤±è´¥æˆ–ç”Ÿæˆé”™è¯¯è·¯å¾„ã€‚
get_filename_component(ORT_DIR ${ORT_DIR} ABSOLUTE)

# ONNX Runtime å¤´æ–‡ä»¶è·¯å¾„
include_directories(${ORT_DIR}/include)
# ONNX Runtime åº“æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºé“¾æ¥ï¼‰
link_directories(${ORT_DIR}/lib)

# æ·»åŠ å¯æ‰§è¡Œæ–‡ä»¶
add_executable(infer source/main.cpp)

# é“¾æ¥ ONNX Runtime åŠ¨æ€åº“
target_link_libraries(infer onnxruntime)

# âœ… æ˜¾å¼è®¾ç½®è¿è¡Œæ—¶åº“æŸ¥æ‰¾è·¯å¾„ (RPATH)
set_target_properties(infer PROPERTIES
  BUILD_RPATH "${ORT_DIR}/lib;$ORIGIN"  # å¼€å‘æ—¶æŸ¥æ‰¾ ORT_DIR
  INSTALL_RPATH "$ORIGIN"  # å‘å¸ƒæ—¶æŸ¥æ‰¾å¯æ‰§è¡Œæ–‡ä»¶ç›®å½•ï¼ˆ$ORIGINï¼‰
)
# è®¾ç½® BUILD_RPATH ä¸ INSTALL_RPATH åˆ†ç¦»ï¼šåˆ©äºéƒ¨ç½²ä¸ä¾èµ–å¼€å‘è·¯å¾„ã€‚

# âœ… è‡ªåŠ¨å¤åˆ¶æ¨¡å‹æ–‡ä»¶åˆ° bin è·¯å¾„
configure_file(
  ${CMAKE_SOURCE_DIR}/models/model.onnx
  ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/model.onnx
  COPYONLY
)

# âœ… è‡ªåŠ¨å¤åˆ¶ onnxruntime çš„åŠ¨æ€åº“åˆ° bin ç›®å½•
file(GLOB ONNX_LIBS "${ORT_DIR}/lib/libonnxruntime.so*")
foreach(libfile ${ONNX_LIBS})
  configure_file(
    ${libfile}
    ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/
    COPYONLY
  )
endforeach()
```

ç¼–è¯‘å‘½ä»¤

```shell
cd your_project  # è¿›å…¥é¡¹ç›®ç›®å½•
cmake -S . -B build  # ç”Ÿæˆæ„å»ºé…ç½®
cmake --build build  # ç¼–è¯‘ä½ çš„ç¨‹åº
```

æˆ–è€…å†™æˆä¸€ä¸ªè„šæœ¬ï¼š

```
#!/bin/bash
# è‡ªåŠ¨æ„å»ºè„šæœ¬

set -e  # æœ‰é”™è¯¯å°±é€€å‡º

echo "[1] æ¸…ç†æ—§æ„å»º..."
rm -rf ./build/*

echo "[2] é…ç½®é¡¹ç›®..."
cmake -S . -B build

echo "[3] ç¼–è¯‘é¡¹ç›®..."
cmake --build build

echo "[âœ…] ç¼–è¯‘å®Œæˆï¼Œå¯æ‰§è¡Œæ–‡ä»¶åœ¨ build/bin ä¸­ï¼ˆå¦‚æœä½ è®¾ç½®äº†è¾“å‡ºè·¯å¾„ï¼‰"
```

ç¼–è¯‘ç»“æœï¼š

```
root@user:~/onnx_infer_cpu# . gen_exe.sh
[1] æ¸…ç†æ—§æ„å»º...
[2] é…ç½®é¡¹ç›®...
-- The C compiler identification is GNU 11.4.0
-- The CXX compiler identification is GNU 11.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Configuring done
-- Generating done
-- Build files have been written to: /root/onnx_infer_cpu/build
[3] ç¼–è¯‘é¡¹ç›®...
[ 33%] Building CXX object CMakeFiles/infer.dir/source/main.cpp.o
[ 66%] Building CXX object CMakeFiles/infer.dir/source/onnx_infer/onnx_infer.cpp.o
[100%] Linking CXX executable bin/infer
[100%] Built target infer
[âœ…] ç¼–è¯‘å®Œæˆï¼Œå¯æ‰§è¡Œæ–‡ä»¶åœ¨ build/bin ä¸­ï¼ˆå¦‚æœä½ è®¾ç½®äº†è¾“å‡ºè·¯å¾„ï¼‰
```

### è¿è¡Œ

```shell
cd build/bin
./infer
```

è¿è¡Œç»“æœï¼ˆç¤ºä¾‹ï¼‰

```
== a1 ==
2 1 0 3
== a2 ==
0 0 1 0
== param ==
[0.05, 0.21, 0.87, 0.33]
[...]
```

æ³¨æ„ï¼š

å¦‚æœä½ çš„æ¨¡å‹è¾“å…¥ shape ä¸åŒï¼Œæ¯”å¦‚ `{1, 4}`ï¼Œåªéœ€ä¿®æ”¹ `input_dims` å’Œæ•°æ®å¤§å°ã€‚

### ä¸ä½¿ç”¨cmakeç›´æ¥æ‰‹åŠ¨ç¼–è¯‘

æ–¹æ³•1ï¼š

```shell
g++ source/main.cpp -I./onnxruntime/include -L./onnxruntime/lib -lonnxruntime -o infer
```

 ç„¶åä»`/onnxruntime/lib`æŠŠ`libonnxruntime.o.1.22.0`å¤åˆ¶åˆ°ç¨‹åºæ ¹ç›®å½•ï¼Œæ”¹åæˆ–è€…è½¯è¿æ¥ä¸º`libonnxruntime.o.1`ï¼Œè¿è¡Œ

```shell
LD_LIBRARY_PATH=. ./infer
```

ç»“æœä¸ºï¼š

```shell
a1: 2 
a2: 1 
param: 
  [-0.098551, 0.107577, 0.0857024, -0.254746]
```

æ–¹æ³• 2ï¼šç›´æ¥åŠ  RPATHï¼ˆæ¨èï¼‰

å¦‚æœä½ ä¸æƒ³æ¯æ¬¡éƒ½ `LD_LIBRARY_PATH`ï¼Œå¯ä»¥ç›´æ¥è¿™æ ·ç¼–è¯‘ï¼š

```
g++ source/main.cpp -I./onnxruntime/include -L./onnxruntime/lib -Wl,-rpath='$ORIGIN' -lonnxruntime -o infer
```

å…¶ä¸­ï¼š

- `$ORIGIN` è¡¨ç¤ºç¨‹åºæ‰€åœ¨çš„ç›®å½•
- `-Wl,-rpath=...` æ˜¯å‘Šè¯‰ç¨‹åºâ€œå°†è¿™ä¸ªè·¯å¾„ä½œä¸ºè¿è¡Œæ—¶æŸ¥æ‰¾ `.so` çš„åœ°æ–¹â€

è¿è¡Œæ—¶è‡ªåŠ¨æ‰¾å½“å‰ç›®å½•çš„ `.so.1` æ–‡ä»¶ï¼Œå°±ä¸ä¼šæŠ¥é”™äº†ã€‚

