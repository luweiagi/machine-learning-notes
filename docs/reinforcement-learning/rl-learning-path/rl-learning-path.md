# 强化学习学习路径

* [返回上层目录](../reinforcement-learning.md)
* [最快速的强化学习入门路径](#最快速的强化学习入门路径)



# 最快速的强化学习入门路径

这是我个人总结的最快速的强化学习入门路径了，一共需要花费6天时间。

**（1）[白话强化学习：用大白话教会强化学习算法 by 张斯俊](https://www.zhihu.com/column/c_1215667894253830144)**：耗时2天

入门先看这个：[白话强化学习：用大白话教会强化学习算法 by 张斯俊](https://www.zhihu.com/column/c_1215667894253830144)，从最早的一直往前看。

当看完[番外篇 DuelingDQN为何那么强？(附代码及代码分析)](https://zhuanlan.zhihu.com/p/110807201)这一章后，它下一章[如何理解策略梯度（Policy Gradient）算法？（附代码及代码解释）](https://zhuanlan.zhihu.com/p/110881517)讲的不是很清楚，就先暂停看该系列。

**（2）[李宏毅深度强化学习(国语)课程(2018)](https://www.bilibili.com/video/BV1MW411w79n)**：耗时0.5天

此时可以看李宏毅讲强化学习的课程[李宏毅深度强化学习(国语)课程(2018)](https://www.bilibili.com/video/BV1MW411w79n)，先只需要看其中的前两节：

* [策略梯度：Policy Gradient](https://www.bilibili.com/video/BV1MW411w79n?p=1)
* [PPO：Proximal Policy Optimization](https://www.bilibili.com/video/BV1MW411w79n?p=2)

**（3）[白话强化学习：用大白话教会强化学习算法 by 张斯俊](https://www.zhihu.com/column/c_1215667894253830144)**：耗时2天

然后看完这个，再返回头去看[白话强化学习：用大白话教会强化学习算法 by 张斯俊](https://www.zhihu.com/column/c_1215667894253830144)，从[如何理解策略梯度（Policy Gradient）算法？（附代码及代码解释）](https://zhuanlan.zhihu.com/p/110881517)一直看到[你有一份强化学习线路图，请查收。(原题：看我如何一文从马可洛夫怼到DPPO)](https://zhuanlan.zhihu.com/p/111869532)。

**（4）[莫凡Python：Distributed Proximal Policy Optimization (DPPO)](https://mofanpy.com/tutorials/machine-learning/reinforcement-learning/DPPO)**：耗时1天

看莫凡Python的DPPO的教程[莫凡Python：Distributed Proximal Policy Optimization (DPPO)](https://mofanpy.com/tutorials/machine-learning/reinforcement-learning/DPPO)，里面讲了如何用gym环境自己写一个双臂机器人的环境[从头开始做一个机器手臂1 搭建结构](https://mofanpy.com/tutorials/machine-learning/ML-practice/RL-build-arm-from-scratch1)，以及对应的DPPO算法（输出两个连续控制量）[Reinforcement-learning-with-tensorflow/experiments/Robot_arm](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/tree/master/experiments/Robot_arm)。

